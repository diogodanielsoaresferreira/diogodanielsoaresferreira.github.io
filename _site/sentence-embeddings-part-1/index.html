<!DOCTYPE html> <!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]--> <!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8"><![endif]--> <!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9"><![endif]--> <!--[if gt IE 8]><!--> <html class="no-js"><!--<![endif]--> <head> <!-- Global site tag (gtag.js) - Google Analytics --> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-146324263-1"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-146324263-1'); </script> <!-- Default Statcounter code for Diogo Ferreira Website https://diogodanielsoaresferreira.github.io/ --> <script type="text/javascript"> var sc_project=12072454; var sc_invisible=1; var sc_security="1b683c07"; </script> <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script> <noscript><div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img class="statcounter" src="https://c.statcounter.com/12072454/0/1b683c07/1/" alt="Web Analytics"></a></div></noscript> <!-- End of Statcounter Code --> <meta charset="UTF-8"> <meta content="text/html; charset=UTF-8" http-equiv="Content-Type"> <meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"> <title>From Word Embeddings to Sentence Embeddings - Part 1/3 &#8211; Diogo Ferreira webpage</title> <meta name="description" content="Diogo Ferreira personal webpage."> <meta name="keywords" content="word embeddings, sentence embeddings, TF-IDF, NLP, data science"> <!-- Twitter Cards --> <meta name="twitter:card" content="summary"> <meta name="twitter:image" content="http://localhost:4000/assets/img/me.jpg"> <meta name="twitter:title" content="From Word Embeddings to Sentence Embeddings - Part 1/3"> <meta name="twitter:description" content="What are Sentence Embeddings and explanation of TF-IDF to generate Sentence Representations"> <!-- Open Graph --> <meta property="og:locale" content="en_US"> <meta property="og:type" content="article"> <meta property="og:title" content="From Word Embeddings to Sentence Embeddings - Part 1/3"> <meta property="og:description" content="What are Sentence Embeddings and explanation of TF-IDF to generate Sentence Representations"> <meta property="og:url" content="http://localhost:4000/sentence-embeddings-part-1/"> <meta property="og:site_name" content="Diogo Ferreira webpage"> <meta property="og:image" content="http://localhost:4000/assets/img/me.jpg"> <link rel="canonical" href="http://localhost:4000/sentence-embeddings-part-1/"> <link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Diogo Ferreira webpage Feed"> <!-- Handheld --> <meta name="HandheldFriendly" content="True"> <meta name="MobileOptimized" content="320"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <!-- CSS --> <link rel="stylesheet" href="http://localhost:4000/assets/css/main.css"> <!-- JS --> <script src="http://localhost:4000/assets/js/modernizr-3.3.1.custom.min.js"></script> <!-- Favicons --> <link rel="apple-touch-icon" sizes="180x180" href="http://localhost:4000/assets/img/favicons/apple-touch-icon.png"> <link rel="icon" type="image/png" sizes="32x32" href="http://localhost:4000/assets/img/favicons/favicon-32x32.png"> <link rel="icon" type="image/png" sizes="16x16" href="http://localhost:4000/assets/img/favicons/favicon-16x16.png"> <link rel="shortcut icon" type="image/png" href="http://localhost:4000/favicon.png" /> <link rel="shortcut icon" href="http://localhost:4000/favicon.ico" /> <link rel="manifest" href="/site.webmanifest"> <!-- <link rel="apple-touch-icon" href="http://localhost:4000/assets/img/favicons/apple-touch-icon.png"> <link rel="apple-touch-icon" sizes="72x72" href="http://localhost:4000/assets/img/favicons/apple-icon-72x72.png"> <link rel="apple-touch-icon" sizes="114x114" href="http://localhost:4000/assets/img/favicons/apple-icon-114x114.png"> <link rel="apple-touch-icon" sizes="144x144" href="http://localhost:4000/assets/img/favicons/apple-icon-144x144.png"> <link rel="shortcut icon" type="image/png" href="http://localhost:4000/favicon.png" /> <link rel="shortcut icon" href="http://localhost:4000/favicon.ico" /> --> <!-- Background Image --> <style type="text/css">body {background-image:url(http://localhost:4000/assets/img/ua2.jpeg); background-repeat: no-repeat; background-size: cover; }</style> <!-- Post Feature Image --> </head> <body> <nav id="dl-menu" class="dl-menuwrapper" role="navigation"> <button class="dl-trigger">Open Menu</button> <ul class="dl-menu"> <li><a href="http://localhost:4000/">Home</a></li> <!-- <li> <a href="#">About</a> <ul class="dl-submenu"> <li> <img src="http://localhost:4000/assets/img/me.jpg" alt="Diogo Ferreira webpage photo" class="author-photo"> <h4>Diogo Ferreira webpage</h4> <p>Diogo Ferreira personal webpage.</p> </li> <li><a href="http://localhost:4000/about/"><span class="btn btn-inverse">Learn More</span></a></li> <li> <a href="mailto:diogodsferreira@gmail.com" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-envelope-square"></i> Email</a> </li> <li> <a href="http://facebook.com/diogodsFerreira" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-facebook-square"></i> Facebook</a> </li> <li> <a href="http://linkedin.com/in/diogo-ferreira" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-linkedin-square"></i> LinkedIn</a> </li> <li> <a href="http://instagram.com/diogodsferreira" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-instagram"></i> Instagram</a> </li> <li> <a href="http://github.com/diogodanielsoaresferreira" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-github"></i> Github</a> </li> </ul> --> <!-- /.dl-submenu --> </li> <li><a href="http://localhost:4000/about/">About me</a></li> <li> <a href="#">Posts</a> <ul class="dl-submenu"> <li><a href="http://localhost:4000/posts/">All Posts</a></li> <li><a href="http://localhost:4000/tags/">All Tags</a></li> </ul> </li> </ul><!-- /.dl-menu --> </nav><!-- /.dl-menuwrapper --> <!-- Header --> <header class="header" role="banner"> <div class="wrapper animated fadeIn"> <div class="content"> <div class="post-title "> <h1>From Word Embeddings to Sentence Embeddings - Part 1/3</h1> <h4>30 Mar 2020</h4> <p class="reading-time"> <i class="fa fa-clock-o"></i> Reading time ~4 minutes </p><!-- /.entry-reading-time --> <a class="btn zoombtn" href="http://localhost:4000/posts/"> <i class="fa fa-chevron-left"></i> </a> </div> <figure> <a href="/assets/img/sentence-embeddings-part-1/words_header.jpg"><img src="/assets/img/sentence-embeddings-part-1/words_header.jpg" style="max-width: 100%" /></a> <figcaption style="text-align: center">Designed by <a href="https://br.freepik.com/fotos-gratis/letras-diferentes_1330225.htm" target="_blank">Freepik</a></figcaption> </figure> <p>Recently, I wrote two articles in Engineering Talkdesk Blog, about <a href="https://engineering.talkdesk.com/what-are-word-embeddings-and-why-are-they-useful-a45f49edf7ab">Word Embeddings</a> and <a href="https://medium.com/p/53ed370b3f35/">Sentence Embeddings</a>. In this series of three blog posts, I will explain in detail some of the approaches described to obtain Sentence Representations.</p> <p>In this first part, I will explain how to represent a word numerically and how to represent a sentence numerically using the TF-IDF algorithm.</p> <h1 id="obtaining-word-representations">Obtaining Word Representations</h1> <p>How do we represent a word?</p> <p>The simplest way to represent a word is with a <strong>one-hot encoded vector</strong>. Let’s imagine we have a vector with the size of the vocabulary, where each entry corresponds to a word (Figure 1). In that way, the representation of each word is a vector of zeros, with ‘1’ in the position of the word. However, this representation has some disadvantages.</p> <figure> <a href="/assets/img/sentence-embeddings-part-1/one_hot_encoding.png"><img src="/assets/img/sentence-embeddings-part-1/one_hot_encoding.png" style="max-width: 100%" /></a> <figcaption style="text-align: center">Figure 1 - One-hot encoded representation of the words "Rome", "Paris", "Italy" and "France" (Source: <a href="https://speakerdeck.com/marcobonzanini/word-embeddings-for-natural-language-processing-in-python-at-london-python-meetup?slide=14" target="_blank">Marco Bonzanini, Word Embeddings for Natural Language Processing in Python @ London Python meetup</a>)</figcaption> </figure> <p>The representation of each word is <strong>very high-dimensional</strong> (a vector with the size of the vocabulary) but sparse (only one entry has the value ‘1’).</p> <p>This does not provide much information about the word meaning, and it does not reveal any existing relationship between words. The representation of the word “Rome” is as close to the representation of the word “Paris” as any other word in the corpus, because their representations always differ in the same way. All other positions are the same with exception to the position of the word “Rome” and the position of the other word.</p> <p>Another representation currently used is <strong>Word Embeddings</strong> (Figure 2). An embedding is a low-dimensional space that can represent a high-dimensional vector (such as the one-hot encoding of a word) in a compressed vector.</p> <figure> <a href="/assets/img/sentence-embeddings-part-1/word_embeddings.png"><img src="/assets/img/sentence-embeddings-part-1/word_embeddings.png" style="max-width: 100%" /></a> <figcaption style="text-align: center">Figure 2- Word embeddings of the words "Rome", "Paris", "Italy" and "France". We can see that the words "Rome" and "Paris" have similar embeddings, probably because they are both capital cities. (Source: <a href="https://speakerdeck.com/marcobonzanini/word-embeddings-for-natural-language-processing-in-python-at-london-python-meetup?slide=22" target="_blank">Marco Bonzanini, Word Embeddings for Natural Language Processing in Python @ London Python meetup</a>)</figcaption> </figure> <p>Besides the higher density of those vectors, the <strong>advantage of the embeddings is the closeness between similar words</strong>. That means that words such as “Rome” or “Paris” will probably have a similar embedding, different from the embedding of “Internet”, for example. That is very useful for many other Natural Language Processing (NLP) tasks, such as word clustering or topic analysis.</p> <h1 id="obtaining-sentence-representations-with-tf-idf">Obtaining Sentence Representations with TF-IDF</h1> <p>To represent sentences, it is impossible to create a one-hot encoding schema: there is an infinite number of sentences. We have to use other kinds of sentence representations.</p> <p>We are going to explain four different sentence representation algorithms in this blog series. For this post, let’s learn more about TF-IDF!</p> <p><strong><a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">TF-IDF</a></strong> (Term Frequency-Inverse Document Frequency) is a classical information retrieval method, commonly used by search engines, where the goal is to quickly search documents in a large corpus. Those documents can be sentences, dialogues or even long texts.</p> <p>TF-IDF creates a term-document matrix (Figure 3), where each term has associated all the documents where it appears, and a weight for each term-document entry. The weight of a term in a document increases with the number of times that the term appears in that particular document, and decreases with the frequency that the term appears in all documents. In that way, terms such as “a” or “the” in an English corpus will have lower weight because they appear in many documents.</p> <script src="https://gist.github.com/diogodanielsoaresferreira/d50f98f79c76622eca45686d114399df.js"></script> <figcaption style="text-align: center">Figure 3 - Example of the matrix created by TF-IDF, where the documents are dialogues.</figcaption> <p>A training corpus (set of documents) must be used to create the TF-IDF matrix. The dimensions of the matrix will be the number of different terms in the corpus by the number of documents in the corpus.</p> <p>The representation of a document is calculated by comparison with the documents in the training corpus.</p> <p>The document representation will be a row vector with the size of the number of documents in the corpus, where each entry <em>i</em> will have a value that represents the similarity of the input document with the document <em>i</em> in the corpus (Figure 4).</p> <p>That similarity is calculated based on the terms mentioned both in the input document and in each document in the corpus. A higher weight in the the entry <em>i</em> of the document representation means that there is a higher similarity with the document <em>i</em> in the corpus.</p> <figure> <a href="/assets/img/sentence-embeddings-part-1/TF_IDF.png"><img src="/assets/img/sentence-embeddings-part-1/TF_IDF.png" style="max-width: 100%" /></a> <figcaption style="text-align: center">Figure 4 - Calculation of the representation of a document. Using the TF-IDF matrix of Figure 3, is calculated a representation of a document based on the similarity with the dialogues.</figcaption> </figure> <p>Document representations based on TF-IDF have some advantages:</p> <ul> <li>They can be calculated very fast, with a lookup on the TF-IDF matrix and a few simple calculations.</li> <li>They are conceptually simple when compared with other algorithms.</li> <li>Their implementation is transparent and the representation can be easily understood.</li> </ul> <p>Their disadvantages are the following:</p> <ul> <li>The similarity between documents does not take into account the position of each word in the document (also known as a bag-of-words model).</li> <li>It does not capture the semantics of a document, which means that it does not take into account similar words.</li> <li>It creates sparse vectors, which means that it is wasting a lot of memory with zero values.</li> </ul> <p>And that’s it for the first post! Read <a href="/sentence-embeddings-part-2/">part 2</a> to know more about more advanced approaches to create Sentence Embeddings.</p> <p>Thanks for sticking by!</p> <div class="entry-meta"> <br> <hr> <span class="entry-tags"><a href="http://localhost:4000/tags/#word embeddings" title="Pages tagged word embeddings" class="tag"><span class="term">word embeddings</span></a><a href="http://localhost:4000/tags/#sentence embeddings" title="Pages tagged sentence embeddings" class="tag"><span class="term">sentence embeddings</span></a><a href="http://localhost:4000/tags/#TF-IDF" title="Pages tagged TF-IDF" class="tag"><span class="term">TF-IDF</span></a><a href="http://localhost:4000/tags/#NLP" title="Pages tagged NLP" class="tag"><span class="term">NLP</span></a><a href="http://localhost:4000/tags/#data science" title="Pages tagged data science" class="tag"><span class="term">data science</span></a></span> <span class="social-share"> <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/sentence-embeddings-part-1/" title="Share on Facebook" class="tag"> <span class="term"><i class="fa fa-facebook-square"></i> Share</span> </a> <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/sentence-embeddings-part-1/" title="Share on Twitter" class="tag"> <span class="term"><i class="fa fa-twitter-square"></i> Tweet</span> </a> </span> <div style="clear:both"></div> </div> </div> </div> <section id="disqus_thread" class="animated fadeInUp"></section><!-- /#disqus_thread --> </header> <!-- JS --> <script src="http://localhost:4000/assets/js/jquery-1.12.0.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.dlmenu.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.goup.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.magnific-popup.min.js"></script> <script src="http://localhost:4000/assets/js/jquery.fitvid.min.js"></script> <script src="http://localhost:4000/assets/js/scripts.js"></script> <script type="text/javascript"> var disqus_shortname = 'diogo-ferreira-webpage'; (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js'; (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })(); (function () { var s = document.createElement('script'); s.async = true; s.type = 'text/javascript'; s.src = '//' + disqus_shortname + '.disqus.com/count.js'; (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s); }()); </script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript> <!-- MathJax --> <script async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> </body> </html>
