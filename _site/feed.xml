<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-11-19T15:39:49+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Diogo Ferreira webpage</title><subtitle>Diogo Ferreira personal webpage.</subtitle><entry><title type="html">Application Read and Write Path</title><link href="http://localhost:4000/application-read-and-write-path/" rel="alternate" type="text/html" title="Application Read and Write Path" /><published>2023-07-18T00:00:00+02:00</published><updated>2023-07-18T00:00:00+02:00</updated><id>http://localhost:4000/application-read-and-write-path</id><content type="html" xml:base="http://localhost:4000/application-read-and-write-path/"><![CDATA[<figure>
    <a href="/assets/img/read-write-path/map_distributed_systems_landscape.png"><img src="/assets/img/read-write-path/map_distributed_systems_landscape.png" /></a>
    <figcaption style="text-align: center">A map of the distributed data systems landscape, from the book "Designing Data-Intensive Applications", by Martin Kleppmann</figcaption>
</figure>

<p>Hi there! I recently read <a href="https://www.amazon.com/Designing-Data-Intensive-Applications-Reliable-Maintainable/dp/1449373321" target="_blank">“Designing Data-Intensive Applications”, by Martin Kleppmann</a>, and was fascinated with the concept of building applications around the idea of dataflows. In this blog post, I explain what is the read and write path of an application.</p>

<hr />

<p>We want to develop a service that, given a user music playlist, generates a list of similar songs to a given song. The service has two flows: the <strong>song insertion flow</strong> and the <strong>similar songs calculator flow</strong>. The song insertion flow receives the song, computes the song features, and adds the features to a repository. The similar songs calculator flow receives a song name from the user, calculates similar songs based on the song features and the other songs’ features, and returns a list of similar songs.</p>

<p>Let’s call the song insertion flow the write path, and the similar songs calculator flow the read path of the service. A depiction of both paths can be seen in the following Figure.</p>

<figure>
    <a href="/assets/img/read-write-path/path_1.png"><img src="/assets/img/read-write-path/path_1.png" /></a>
</figure>

<p>Now imagine that the service is taking too much time to add songs, and that most users add many songs but never calculate any similarity. We can prevent the service to compute the song features by moving that computation from the write path to the read path, as can be seen in the Figure below. The write path is shorter now, at the cost of the computation being done on-demand in the read path.</p>

<figure>
    <a href="/assets/img/read-write-path/path_2.png"><img src="/assets/img/read-write-path/path_2.png" /></a>
</figure>

<p>Let’s suppose we have the inverse scenario, that users are complaining because it takes too much time to calculate the song similarities. We can solve that by pre-calculating the similar songs in the write path. In the read path, the user only accesses a repository with the song similarities.</p>

<figure>
    <a href="/assets/img/read-write-path/path_3.png"><img src="/assets/img/read-write-path/path_3.png" /></a>
</figure>

<p>We can go beyond that and add a song similarity cache, that maintains a list of the most similar songs for the most popular songs, speeding up the read path at the cost of a possible cache update on the write path.</p>

<figure>
    <a href="/assets/img/read-write-path/path_4.png"><img src="/assets/img/read-write-path/path_4.png" /></a>
</figure>

<hr />

<p>The write path is the pre-computed part of the flow and the read path is the part that is only computed by request. In programming terms, the <strong>write path is similar to eager evaluation</strong>, while the <strong>read path is similar to lazy evaluation</strong>.</p>

<p>The role of the repository, cache, index or any transformed data view can be seen as the boundary between the read and write path. We can shift the boundary according to our use case needs: if we need fast access to data, we can shorten the read path with additional data views; on the other hand, if we need faster write operations, we can shorten the write path and postpone some data processing to the read path, which will only be done when requested.</p>

<p>When seen like that, in a system when a dataset is derived from another, it shortens the read path and extends the write path, for example:</p>

<ul>
  <li>When we create a secondary index in a database;</li>
  <li>When we create a full-text search index;</li>
  <li>When we create a machine learning model;</li>
  <li>When we implement a cache.</li>
</ul>

<hr />

<p>An example of write and read path shifting is explained in the book “Designing Data-Intensive Applications”. In 2012, Twitter main operations were posting a tweet and view tweets in the timeline. When a tweet was posted, it was stored in a repository with all tweets. When a user accessed its timeline, it was needed to make a query for the people they follow, and then fetch the tweets from them. Due to the heavy load of timeline queries, Twitter systems struggled to keep up. The problem was that the read path - to view the timeline - was doing too much work.</p>

<p>To solve that, Twitter decided on a different approach. Each user would have a cache that had the tweets on its timeline. When someone posted a tweet, Twitter would look up its followers and insert the tweet in each follower cache. The request for the timeline was now much easier - just check its timeline cache.</p>

<p>Did that solve the problem? The downside of this approach was that posting a tweet required a lot of extra work - now the write path was too heavy. Specially for celebrities, which had millions of followers, each tweet would need to be inserted in each users’ timeline cache.</p>

<p>In the end, Twitter moved to a hybrid of both approaches: most users’ tweets were inserted in its followers’ timeline cache, but for users with a large number of followers they weren’t. When a user saw their timeline, Twitter would merge the tweets in the user cache with the tweets from people with a large number of followers.</p>

<hr />

<p>There are also some architectural examples where shortening the read path can have a tremendous impact. For example, some mobile applications do as much as possible using a local database on the same device without requiring an internet connection and sync with remote servers in the background whenever there is a connection available, practically extending the write path to the user. These design decisions lead to more resilient and efficient applications.</p>

<p>With the popularity of end-to-end stream processing frameworks and tools, such as reactive frameworks, Kotlin Channels, the project Loom for Java or Flux architectures, it is a great time to start rethinking our architectures in terms of dataflow. Instead of treating a database as a passive component, think more about the interplay of state, state changes, and code that processes them. Application code responds to state changes in one place by triggering state changes in another place.</p>

<hr />

<p>Interesting, right? This is explained thoroughly in the last chapter of the book “Designing Data-Intensive Applications”, by Martin Kleppmann, but I recommend reading the whole book. It is the bible of modern data processing and storage, from the high-level overview to the details of the present databases.</p>

<p>Thanks for reading!</p>]]></content><author><name></name></author><category term="software development" /><category term="software architecture" /><category term="software engineering" /><category term="backend development" /><category term="application development" /><summary type="html"><![CDATA[Start rethinking our software architectures in terms of dataflow]]></summary></entry><entry><title type="html">Good old Unix commands need more love ❤</title><link href="http://localhost:4000/good-old-linux-commands-need-more-love/" rel="alternate" type="text/html" title="Good old Unix commands need more love ❤" /><published>2022-11-11T00:00:00+01:00</published><updated>2022-11-11T00:00:00+01:00</updated><id>http://localhost:4000/good-old-linux-commands-need-more-love</id><content type="html" xml:base="http://localhost:4000/good-old-linux-commands-need-more-love/"><![CDATA[<figure>
    <a href="/assets/img/unix/creators.jpg"><img src="/assets/img/unix/creators.jpg" style="max-width: 80%" /></a>
    <figcaption style="text-align: center">Dennis Ritchie and Ken Thompson, two of the creators of Unix, in 1972. Photo: Alcatel-Lucent</figcaption>
</figure>

<p>Hi there! Every time I need to do batch processing using Unix tools, I am amazed by the simplicity and robustness of Unix commands. But how do they compare with other batch processing tools? <strong>Let’s understand the pros and cons of batch processing using Unix commands.</strong></p>

<hr />

<p>Let’s suppose you have a file with the network traffic flows. <strong>Your goal is to calculate the most common source and destination IP-port combinations.</strong> How would you do that?</p>

<p>We can download from <a href="https://www.kaggle.com/datasets/jsrojas/ip-network-traffic-flows-labeled-with-87-apps">Kaggle a dataset with network traffic flows</a>. <strong>Let’s start by solving the problem using the Pandas library</strong>, in Python, probably the most used library for quick data analysis. There are better ways to solve the problem, but for the purpose of this post, let’s use a naive approach.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/10721f8f24ebcb828f947f7c1d594d5d.js"></script>

<p>Simple, right? We load all data from the file, group by source and destination IP and port, count the repeated combinations, sort values by the count, take the top 20 results, and store them in a file. Try it yourself!</p>

<p><strong>Now let’s solve it using only Unix commands.</strong></p>

<script src="https://gist.github.com/diogodanielsoaresferreira/65cd6c6394607e422a17b7645d01496d.js"></script>

<p>We read the file (except the header), filter only the columns needed (Source IP, Source Port, Destination IP, and Destination Port), sort by that combination, count the repeated combinations, sort again by count, take the first 20 results and store it in a file. Very similar to the Python approach, maybe a little less readable if you’re not used to Unix, but still easy to understand. Let’s compare both approaches.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/fa8b8de9cd2d5c036c1c0b0dac0c74d1.js"></script>

<p>It seems that <strong>the Python approach is faster than the Unix commands!</strong> Interesting, but why is that? Before diving into the question, let’s tweak our input.<strong>Let’s replicate our dataset by a factor of 8</strong> and rerun the scripts. You can easily guess that it should take more time to run, and you would be right. But another things happens…</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/546b0a7a6485944fbdccaff28253d6e3.js"></script>

<p>Wow, <strong>it seems that the python script was terminated by the kernel, but the Unix commands ran successfully.</strong> Let’s take a closer look into what happenned.</p>

<hr />

<figure>
    <a href="/assets/img/unix/Ram Python.png"><img src="/assets/img/unix/Ram Python.png" style="max-width: 80%" /></a>
    <figcaption style="text-align: center">RAM memory while running Python script. RAM memory went up to 100% before crashing.</figcaption>
</figure>

<figure>
    <a href="/assets/img/unix/Ram Unix.png"><img src="/assets/img/unix/Ram Unix.png" style="max-width: 80%" /></a>
    <figcaption style="text-align: center">RAM memory while running Unix commands. RAM memory stayed below 20%.</figcaption>
</figure>

<p>Looking at the RAM memory, it seems that <strong>with the Python script, the memory was insufficient to process the entire dataset.</strong> Comparing with the Unix commands on the other hand, there is no impact on RAM memory whatsoever.</p>

<figure>
    <a href="/assets/img/unix/CPU Python.png"><img src="/assets/img/unix/CPU Python.png" style="max-width: 80%" /></a>
    <figcaption style="text-align: center">CPU usage while running Python script. There was almost always one CPU close to 100% usage before terminating the script.</figcaption>
</figure>

<figure>
    <a href="/assets/img/unix/CPU Unix.png"><img src="/assets/img/unix/CPU Unix.png" style="max-width: 80%" /></a>
    <figcaption style="text-align: center">CPU usage while running Unix commands. CPU usage of every CPU never surpassed 70%.</figcaption>
</figure>

<p>Besides, it looks as <strong>the Python script always uses one CPU core to 100%, while the Unix commands distribute the load across the available CPUs.</strong> How does this happens? Is it automatic?</p>

<p>What happens is that <strong>Pandas processes the entire dataset in-memory.</strong> If the dataset is larger than the memory size, the script will crash. Another downside of Pandas is that it only uses a single CPU core, instead of taking advantage of all CPU cores. For these reasons, <strong>Pandas is better suited for smaller datasets</strong>, where it may be faster than Unix commands due to all in-memory processing. However, for datasets larger than the available RAM memory, Pandas may not be the best approach.</p>

<p>On the other hand, Unix commands are much better suited for larger datasets. <strong>The sort utility automatically handles larger-than-memory datasets, by splitting the data into batches, which are sorted in-memory and then stored in temporary files.</strong> Only then those temporary files are merged together. In this way, you never run out of RAM memory. Besides, the sort utility also parallelizes sorting across multiple CPU cores, making the bottleneck the rate at which disk files are read.</p>

<figure>
    <a href="/assets/img/unix/unix_temp_files.png"><img src="/assets/img/unix/unix_temp_files.png" style="max-width: 80%" /></a>
    <figcaption style="text-align: center">Temporary files created by sort command in my /tmp folder.</figcaption>
</figure>

<p>This is awesome, right? This also resembles another programming model…</p>

<hr />

<figure>
    <a href="/assets/img/unix/mapreduce_diag.png"><img src="/assets/img/unix/mapreduce_diag.png" style="max-width: 80%" /></a>
    <figcaption style="text-align: center">MapReduce Pipeline. In <a href="https://inst.eecs.berkeley.edu/~cs61a/sp13/labs/lab13/lab13.php"> Berkeley CS61A Lab 13</a>.</figcaption>
</figure>

<p>Have you heard about MapReduce? It’s a programming model for batch processing in distributed systems, presented by Google engineers in 2004. Its goal is to distribute the processing of large datasets between servers, by separating all processing steps into two tasks: mappers, which perform mainly mapping, filtering and sorting, and reducers, which perform an aggregation operation. For the exercise above, each mapper would sort a batch of the dataset, and send the sorted batch to another task, which would perform the merge.</p>

<p>We can see that MapReduce took the Unix approach to deal with large datasets and applied it to distributed computation. It’s even more amazing to see the robustness of Unix commands taking into account that MapReduce was presented 35 years later than the creation of Unix, which was created in 1969.</p>

<p>Are there more breakthrough ideas in Unix? Let’s take a look at its philosophy.</p>

<hr />

<h2 id="make-each-program-do-one-thing-well">Make each program do one thing well</h2>

<p>The core of the Unix philosophy is to separate the logic of every processing step. This means that instead of having one monolithic kernel with lots of features, Unix aims for a small kernel with lots of utilities. <em>cat</em>, <em>sort</em>, <em>ls</em> or <em>awk</em> are not in the Unix kernel, but are separate tools that help doing the job needed. This approach is one of the reasons why Unix is still relevant today: even though the world has changed and the technologies have evolved, those simple programs are still useful everyday: users still need to sort content, list their directories, and read text files.</p>

<p>In today’s distributed and complex systems, this principle is still applied today, particularly in the microsservices pattern. <strong>The goal of the microsservices is, instead of having a single service with lots of features, to have multiple services, each focused in doing one job well.</strong> This has many operational benefits, mainly easier code maintenance, better monitoring and better scalability.</p>

<h2 id="expect-the-output-of-every-program-to-become-the-input-to-another">Expect the output of every program to become the input to another</h2>

<p>In Unix every program has a standard way of communicating between themselves. The pipes guarantee that you can easily take the output of a program and use it as input to another, acting as an uniform programming interface. <strong>This has the obvious advantage that it’s easy to use Unix commands in sequence - there is no need to pre-process or post-process the data. This easiness of composability of simple programs makes Unix a powerful tool.</strong></p>

<p>It is interesting to think that most of today’s systems it is not as composable as Unix in 1969. Many time is still spent just trying to solve integration between systems. However, the idea of the output of a service to become the input of another is now widely adopted through the event-driven architecture. Many large enterprises find it the best way to communicate between services - each service consumes from the streams that is interested in, and publishes its output to another stream. If another service is interested in the data, it can subscribe to the output stream. Again, this is very similar to the piping design in Unix: each service does its own job and publishes the result to the output, unaware of any other service that might consume that data. The main difference is that while Unix interface uses text files to communicate between processes, services mainly use message brokers (for example, Apache Kafka or RabbitMQ).</p>

<h2 id="design-and-build-software-to-be-tried-early-ideally-within-weeks">Design and build software to be tried early, ideally within weeks</h2>

<p>In 1969, Unix developers had the philosophy that software had to be tried early. Curiously, in the 70’s, waterfall was born and took the software world by storm. Long were the days were software was tested and shipped early. During that time, software was only tested after all design and coding was done.</p>

<p>Only in 2001, when the Agile manifesto was written, that large software enterprises started following again the Unix principles and designing and building software early (some of them still use the waterfall method, with little success). <strong>It took us 30 years to understand that the waterfall methodology was not very well suited for most software development, and that the Unix philosophy was right all along!</strong></p>

<h2 id="use-tools-in-preference-to-unskilled-help-to-lighten-a-programming-task">Use tools in preference to unskilled help to lighten a programming task</h2>

<p>The last principle is probably the most difficult to understand. When having a problem that can be solved manually, Unix developers would rather build tools to solve it than solve it themselves manually. This principle gave birth to many tools now used in day-to-day life. If those problems were recurrent, then there was already a tool available to solve them.</p>

<p>Many software tools were created as side-projects to solve a specific problem and ended up being used in a much larger scale. Apache Kafka was initially created in Linkedin to ingest lots of data with low-latency into a lambda architecture (<a href="https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying">there is an old but excelent post about it</a>). GraphQL was initially created in Facebook to solve the problem of overfetching and underfetching in Facebook mobile app. Cassandra was initially developed in Facebook, to power the inbox search feature. The bottom line is that the problem we are trying to solve may as well appear in many other scenarios. If we are able to solve it once, we will be able to solve it easily many more times with the same software.</p>

<hr />

<p>Although it was written more than half a century ago, <strong>the Unix philosophy is still a great piece of advice for every software developer. The tools created are still useful, and better than many of the today’s software.</strong> It is not common for a piece of software to remain useful and heavily used around the world more than 50 years after its creation, with its main features remaining the same.</p>

<p>Although sometimes it’s forgotten, when doing data processing with large datasets in a single machine, Unix may be your best tool.</p>

<p>Thanks for reading!</p>

<p>ps: There is a way to run the Python script above and use much less memory. Have you tried loading only the columns you need to memory? 😃</p>

<p>also, you can read an interesting rant about Python, R and Unix <a href="https://www.datafix.com.au/BASHing/2020-10-28.html">here</a>.</p>]]></content><author><name></name></author><category term="unix" /><category term="linux" /><category term="batch processing" /><category term="python" /><category term="data processing" /><summary type="html"><![CDATA[Comparing Unix and Python for batch processing of large datasets]]></summary></entry><entry><title type="html">Enterprise Integration Patterns With Apache Camel</title><link href="http://localhost:4000/enterprise-integration-patterns-with-apache-camel/" rel="alternate" type="text/html" title="Enterprise Integration Patterns With Apache Camel" /><published>2021-06-17T00:00:00+02:00</published><updated>2021-06-17T00:00:00+02:00</updated><id>http://localhost:4000/enterprise-integration-patterns-with-apache-camel</id><content type="html" xml:base="http://localhost:4000/enterprise-integration-patterns-with-apache-camel/"><![CDATA[<figure>
    <a href="/assets/img/camel/camel.jpeg"><img src="/assets/img/camel/camel.jpeg" style="max-width: 80%" /></a>
    <figcaption style="text-align: center">Photo by <a href="https://unsplash.com/@kristianegelund" target="_blank">Kristian Egelund</a> on Unsplash</figcaption>
</figure>

<p>Hi there! I want to tell you about a great open-source tool that is AWESOME and it does not get the love it deserves: <strong><a href="https://camel.apache.org/">Apache Camel</a></strong>.</p>

<p>Apache Camel is an integration framework. What does that mean? Let’s suppose you are working on a project that consumes data from Kafka and RabbitMQ, reads and writes from and to various databases, transforms data, logs everything to files and outputs the processed data to another Kafka topic. You also have to implement the error handling of the service (retries, dead letter channel, etc.) for everything to run flawlessly. It seems hard.</p>

<p>Apache Camel helps you to integrate with many components, such as databases, files, brokers, and much more, while keeping the simplicity and promoting <a href="https://www.enterpriseintegrationpatterns.com/patterns/messaging/">enterprise integration patterns</a>. Let’s see some examples, based on integration patterns. You can find the code in <a href="https://github.com/diogodanielsoaresferreira/apache_camel_demo">this repository</a>.</p>

<p>We will start by consuming events from a Kafka topic and output to another one, taking advantage of the <strong><a href="https://www.enterpriseintegrationpatterns.com/patterns/messaging/EventDrivenConsumer.html">Event-Driven Consumer</a></strong> pattern. The events will be representation of text messages sent by a user.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/0cdbb84d9a038679091c07ae7e5e5387.js"></script>

<script src="https://gist.github.com/diogodanielsoaresferreira/0591c76be64e9b131328ad15e2aa771b.js"></script>

<p>That’s about it! We also added the log for us to see the message body in the logs. The log argument is passed using the Simple language, an Apache Camel language used to evaluate expressions.</p>

<p>Now let’s implement a <strong><a href="https://www.enterpriseintegrationpatterns.com/patterns/messaging/Filter.html">message filter</a></strong>. This pattern filters out the messages that do not match certain conditions. In our case, we will only process those that have the type “chat”.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/e09cdb48d69e76ab1cb10c4af4bc6104.js"></script>

<p>Easy, right? We now unmarshal the message from JSON to the UserMessage POJO to be able to filter by type. We marshal again in JSON before sending it to another Kafka topic.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/0f871fea43680f80ee14406c74e0450e.js"></script>

<p>Now suppose we want to store all messages in a file. Besides, for the messages where the emitter is “John Doe”, we want to store them in a different file, for testing purposes. For that, we can use the <strong><a href="https://www.enterpriseintegrationpatterns.com/patterns/messaging/ContentBasedRouter.html">content-based router</a></strong> pattern.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/35e23fd77e0c7eba5490b3b4b89f95d2.js"></script>

<p>If the file already exists, we will append the events and add a newline at the end of each event. For other emitters, we will do the same, but stores them in another file. It does look like an ‘if’ construct, right?</p>

<p>We can see a list of “devices” in the event, and we want to log them one by one. How can we do that? Using the <strong><a href="https://www.enterpriseintegrationpatterns.com/patterns/messaging/Sequencer.html">Splitter</a></strong> pattern, we can iterate through any list. We can do it sequentially or parallelly. Let’s try to do it sequentially in this example.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/09fa1bef4dfeb39f97fc6ce8258177e8.js"></script>

<p>We can split by any field that is an Iterable. As you can see, we are using again the Simple language to access the content of the event.</p>

<p>Let’s try something harder. We are receiving messages with text from various emitters, but we want to aggregate multiple text messages and create a new message with all messages for an emitter. To do that, we can use the <strong><a href="https://www.enterpriseintegrationpatterns.com/patterns/messaging/Aggregator.html">Aggregator</a></strong> pattern. The aggregator pattern allows events to be buffered and wait for other events. When another event is received, it can be performed a custom aggregation, based on our needs. A new event is sent when a condition is met. That condition can be based on the number of events received, a timeout, or any other custom condition.</p>

<p>In our case, we will create a new POJO that will aggregate the text messages from an emitter. The new event will be sent after 5 seconds of the first event received for the emitter.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/c008156c4f83f1e3c6e7b7aaf90b9546.js"></script>

<p>We are using an in-memory aggregation, but we could use other data stores, such as Postgres or Redis. We are using simple language to aggregate the emitter of the message, and we created a custom aggregation strategy, shown below.</p>

<p>In the custom aggregation strategy, for the first event (oldExchange==null), we create a new CombinedUserMessage with the text of the message. For all other events, we add the text of the message to the combined event.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/718f4cd50a4d534f9cb165d00fae44d1.js"></script>

<p>This is all great, but how do we apply transformations to a field? We now have a combined event, but what was great was if we could somehow process the combined event and turn it into plain text, by combining the multiple elements of the text messages. We can do that using the <strong><a href="https://www.enterpriseintegrationpatterns.com/patterns/messaging/MessageTranslator.html">Message Translator</a></strong> pattern.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/3e1ab2d97d959d852f8585242d2a0448.js"></script>

<script src="https://gist.github.com/diogodanielsoaresferreira/c7a1ed32df2606f554a1a752a228bb76.js"></script>

<p>We can call bean functions directly from a Camel Route and perform all the transformations that we need,using plain Java code. Neat!</p>

<p>We can see that our Camel Routes are becoming bigger. How do we do if we want, for example, to separate them between files? Two in-memory components that allow us to do that: <strong>Direct</strong> and <strong>SEDA</strong>.</p>

<p><strong>Direct</strong> is a synchronous endpoint that works like a call from a route to another route. Let’s use it to separate the route that stores the event in a file.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/a68c674081b169fc5f575a81f846fd19.js"></script>

<p>Great! There is another in-memory component that will be useful for us: <strong>SEDA</strong>. SEDA works like Direct but is asynchronous, which means that puts the message in a queue for other thread to process. Let’s use SEDA to decouple the receiving of the message from Kafka from the routes that consume it.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/09731355e56b2a12378237549b44c583.js"></script>

<p>Now our routes are much simpler. Suppose we need to perform a periodic task, such as a cleanup. We can take advantage of the <strong>Timer</strong> endpoint. Let’s exemplify it by creating a route that runs every 5 seconds.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/3c17f8dbf10065f55fced89e0638c51c.js"></script>

<p>Now that our application is almost ready for production, we have to improve fault tolerance. What happens if, for some reason, a message gets an error while in a route? Let’s implement the <strong><a href="https://www.enterpriseintegrationpatterns.com/patterns/messaging/DeadLetterChannel.html">Dead Letter</a></strong> pattern. When there is an error in the route, the message is sent to another Kafka topic, so that later it can be reprocessed.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/6bc2f0623d14fe37058073d6846d95ff.js"></script>

<p>And that’s it! The error handler configuration applies to all routes in the class. We send the original message to the topic (the one that was first received in the route). We could also configure retry policies, with timeouts and other common fault tolerance configurations, but as we don’t need it, we will leave it as is.</p>

<p>Now that we are reaching the end of this article, I also wanted to show you something: it is possible to configure <strong>REST</strong> endpoints as Camel routes.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/4993e2d298b912e222f586237f5bc783.js"></script>

<p>As simple as that! We just configured a GET for the URL /api/hello, to be answered with “Hello World!”.
As you can see, Apache Camel is a framework that simplifies the integration with other components, supporting the enterprise integration patterns and making it easier to create data pipelines.</p>

<p>I hope you have liked it! Thanks for reading!</p>]]></content><author><name></name></author><category term="apache camel" /><category term="programming" /><category term="java" /><category term="frameworks" /><summary type="html"><![CDATA[Why Apache Camel is awesome when dealing with complex dependencies]]></summary></entry><entry><title type="html">Maximize the potential of your football players with Machine Learning</title><link href="http://localhost:4000/maximize-the-potential-of-your-football/" rel="alternate" type="text/html" title="Maximize the potential of your football players with Machine Learning" /><published>2020-08-27T00:00:00+02:00</published><updated>2020-08-27T00:00:00+02:00</updated><id>http://localhost:4000/maximize-the-potential-of-your-football</id><content type="html" xml:base="http://localhost:4000/maximize-the-potential-of-your-football/"><![CDATA[<figure>
    <a href="/assets/img/football-players/capa.jpeg"><img src="/assets/img/football-players/capa.jpeg" style="max-width: 80%" /></a>
    <figcaption style="text-align: center">Photo by <a href="https://unsplash.com/@jasonrc23" target="_blank">jason charters</a> on Unsplash</figcaption>
</figure>

<p>Hi there! When you are watching your favorite football team, have you ever got that feeling that there is a player that has great potential, but is playing in the wrong position? Do you think that if the manager would put him in a different position he would be so much better? Well, I do! How can we develop a tool that uses <strong>artificial intelligence to help us detect the best-suited positions for players?</strong></p>

<p>In this post I will show how to train a machine learning model to detect the best positions of a player, using a Football Manager dataset. Then, I will analyze some players and compare the predicted positions with the real positions of the players. You can check the Jupyter notebook with the code for this blog post <a href="https://colab.research.google.com/github/diogodanielsoaresferreira/football_machine_learning/blob/master/Predict%20players%20positions.ipynb">here</a>.</p>

<hr />

<p>Several players changed their position successfully in their careers. <strong>Andrea Pirlo</strong> is perhaps one of the most successful cases. He started as an offensive midfielder but failed to impress in Inter Milan in 2001, due to his lack of pace and stamina. During a loan in Brescia, which also had Roberto Baggio as a trequartista, the coach Carlo Mazzone made the impressive decision to deploy Pirlo as a deep-lying playmaker. Due to his technique and passing ability, Pirlo became perhaps the best deep-lying playmaker of all time, inspiring a new generation of defensive midfielders.</p>

<figure>
    <a href="/assets/img/football-players/pirlo.jpg"><img src="/assets/img/football-players/pirlo.jpg" style="max-width: 80%" /></a>
    <figcaption style="text-align: center">Andrea Pirlo (Wikipedia)</figcaption>
</figure>

<p>Another well-known case of switching positions is <strong>Bale</strong>. When he changed from Southampton to Tottenham, he became one of the fastest left-backs that the world has ever seen. However, by the hand of Harry Redknapp in 2012, he turned into a left-winger, making him the most expensive player in the world when he was bought by Real Madrid in 2013.</p>

<figure>
    <a href="/assets/img/football-players/bale.jpg"><img src="/assets/img/football-players/bale.jpg" style="max-width: 80%" /></a>
    <figcaption style="text-align: center">Gareth Bale (Wikipedia)</figcaption>
</figure>

<p>While in those cases the players moved positions while still young, there are also cases when the players change positions to take advantage of their new characteristics as they get old. For many years, <strong>Ryan Giggs</strong> was the left-winger of Man United. In the later years of his career, his pace decreased, while at the same time his passing skills were better than ever. His change to the central midfield benefited both him and Man United, leading them to the Champions League final in 2009 and 2011.</p>

<p>There are many more players that changed positions successfully: Javier Mascherano, Sergio Ramos, Thierry Henry, Fábio Coentrão, Matic, or Vincent Kompany are some of the examples. The goal of this post is to show how to create a model that predicts the best positions of a player, to allow him to reach his potential earlier in his career.</p>

<hr />

<p>To do that, we will use a dataset with player attributes, valued from 1 to 20. We will use <strong>data from the game Football Manager 2017</strong>, available in <a href="https://www.kaggle.com/ajinkyablaze/football-manager-data">Kaggle</a>. Football Manager is widely known as having one of the most reliable and extensive worldwide football players datasets.</p>

<p>We will train a machine learning model that learns to classify the players’ positions based on their attributes. Each player can be classified as having more than one suited position for him to play.</p>

<p>A <strong>disclaimer</strong> about the data must be made. The dataset is obviously biased, since the players’ attributes were hand given, and they were given knowing the position of the player a priori. However, it was my choice to made this analysis based on the attributes given to the players and not based on the player stats (number of passes, number of goals, etc.), since they are affected by the positions in which the players have played in.</p>

<hr />

<p>Enough talking! Let’s <strong>train the model</strong>. The full notebook can be found <a href="https://colab.research.google.com/github/diogodanielsoaresferreira/football_machine_learning/blob/master/Predict%20players%20positions.ipynb">here</a>.</p>

<p>When defining the position for each player, we can see that each player has a score for each position, from 1 to 20. We will classify a player as well suited for a position if its score for that position is 15 or more.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/17160fcecaa26063656d9322d82e79bc.js"></script>

<p>We will train three models: a <strong>K-neighbors classifier, a Random Forest, and a neural network</strong>. I chose those three algorithms because they have native support for multilabel classification. For each model, it will be applied 5-fold cross-validation, and the F1-score will be measured. The predictions for every player will also be stored.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/c91245d139191b01221a11d1d3d196f9.js"></script>

<p>The results of the cross-validation have shown us that the neural network is the worst performer in this task, achieving an F1-score of 48.61%. Both the K-neighbors and the Random Forest algorithms achieve an F1-score near 60%. Because the training time of the Random Forest is lower, I chose the Random Forest model to make predictions about the players. After the hyper-parameters are chosen, I train the model one last time with the entire dataset.</p>

<p>In the end, we get two artifacts that we will use:</p>
<ul>
  <li><strong>the trained model</strong> with all the players in the dataset;</li>
  <li><strong>the prediction of the position of each player</strong>, trained in a 5-fold cross-validation approach.</li>
</ul>

<hr />

<p>After having the model trained, <strong>let’s play with it!</strong> We can manually set each player’s attribute to a numeric value, and analyze the output of the model. With that, we can inspect the most important attributes for each position.</p>

<p>For example, starting with the attributes of <strong>Cristiano Ronaldo</strong>, it predicts the positions of Striker, Left Attacking Midfielder, Right Attacking Midfielder, and Left Midfielder. Let’s try to reduce the finishing attribute value, that is set to 19. Interestingly enough, when the finishing attribute drops below 10, the model only predicts the positions Left and Right Attacking Midfielder. The Striker and Left Midfielder positions are not predicted due to the low finishing skils. We can also see that changing only the age, height or weight does not affect directly the predicted positions.</p>

<figure>
    <a href="/assets/img/football-players/screen.png"><img src="/assets/img/football-players/screen.png" style="max-width: 100%" /></a>
</figure>

<p>If the Freekicks attribute drops below 4, the Left Midfield position is not predicted. Maybe the model learned that left midfielders are good at free-kicks. If the heading attribute drops, not only the Striker and the Left Midfield positions are not predicted, but the attacking central midfielder position is predicted. It makes sense since the heading attribute is rarely needed for an attacking central midfielder.</p>

<p>Anyway, there is a lot to try and explore with the attributes in the model. <strong>Try it yourself with your favorite players!</strong></p>

<hr />

<p>Besides the model, <strong>we also have the predicted position of each player</strong>. We can inspect the player positions that the model predicted and see if it discovered potential positions where the players could achieve its full potential.</p>

<p>Let’s test with 10 players:</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/068133039f46808c4f66afa6c32b827e.js"></script>

<ul>
  <li>
    <p><strong>Cristiano Ronaldo</strong> - the predicted positions are in the central area of the field, which makes sense in this latter part of his career;</p>
  </li>
  <li>
    <p><strong>Lionel Messi</strong> - the predicted positions are central and left attacking midfielder, which does not contain the striker position when compared to the actual positions; it is also understandable, since Messi is everything but a regular striker - its heading or finishing skills are not outstanding;</p>
  </li>
  <li>
    <p><strong>Neymar</strong> - similar to Messi, all the real positions are predicted with exception to the striker position, probably for the same reasons; I would argue that striker is not the best position for any of them, at least as a lone striker;</p>
  </li>
  <li>
    <p><strong>Kevin De Bruyne</strong> - the actual best positions of De Bruyne in FM 2017 are all midfield and attacking midfield positions; our predicted best positions are central attacking midfield and left attacking midfield;</p>
  </li>
  <li>
    <p><strong>Harry Kane</strong> - both the actual and the predicted positions are the same (striker);</p>
  </li>
  <li>
    <p><strong>Luka Modric</strong> - both the actual and the predicted positions are the same (central attacking midfield and central midfield);</p>
  </li>
  <li>
    <p><strong>Manuel Neuer</strong> - both the actual and the predicted positions are the same (Goalkeeper);</p>
  </li>
  <li>
    <p><strong>Phillip Lahm</strong> - Lahm is a challenging player because it can play in several positions; our predicted position is right defender, which is its original position;</p>
  </li>
  <li>
    <p><strong>Andrea Pirlo</strong> - Pirlo is another challenging example, having started its career as a central attacking midfielder but having more success as a defensive midfielder; our prediction is central midfield and central attacking midfield, probably due to his remarkable vision and passing attributes;</p>
  </li>
  <li>
    <p><strong>Gareth Bale</strong> - the predicted positions for Bale are central and left attacking midfield, which was the position that made him the most expensive player in the world in 2013.</p>
  </li>
</ul>

<p>In recap, <strong>it seems that the model can accurately predict the area of the field of a player (goalkeeping/defense/midfield/striker), and it can give some insights to the players of where it can be its best position.</strong></p>

<p>Try it with your favorite players!</p>

<p>Thanks for reading!</p>]]></content><author><name></name></author><category term="football" /><category term="machine learning" /><summary type="html"><![CDATA[Learn to create a model that calculates the best position of your players]]></summary></entry><entry><title type="html">From Word Embeddings to Sentence Embeddings - Part 1/3</title><link href="http://localhost:4000/sentence-embeddings-part-1/" rel="alternate" type="text/html" title="From Word Embeddings to Sentence Embeddings - Part 1/3" /><published>2020-03-30T00:00:00+02:00</published><updated>2020-03-30T00:00:00+02:00</updated><id>http://localhost:4000/sentence-embeddings-part-1</id><content type="html" xml:base="http://localhost:4000/sentence-embeddings-part-1/"><![CDATA[<figure>
    <a href="/assets/img/sentence-embeddings-part-1/words_header.jpg"><img src="/assets/img/sentence-embeddings-part-1/words_header.jpg" style="max-width: 100%" /></a>
    <figcaption style="text-align: center">Designed by <a href="https://br.freepik.com/fotos-gratis/letras-diferentes_1330225.htm" target="_blank">Freepik</a></figcaption>
</figure>

<p>Recently, I wrote two articles in Engineering Talkdesk Blog, about <a href="https://engineering.talkdesk.com/what-are-word-embeddings-and-why-are-they-useful-a45f49edf7ab">Word Embeddings</a> and <a href="https://medium.com/p/53ed370b3f35/">Sentence Embeddings</a>. In this series of three blog posts, I will explain in detail some of the approaches described to obtain Sentence Representations.</p>

<p>In this first part, I will explain how to represent a word numerically and how to represent a sentence numerically using the TF-IDF algorithm.</p>

<h1 id="obtaining-word-representations">Obtaining Word Representations</h1>
<p>How do we represent a word?</p>

<p>The simplest way to represent a word is with a <strong>one-hot encoded vector</strong>. Let’s imagine we have a vector with the size of the vocabulary, where each entry corresponds to a word (Figure 1). In that way, the representation of each word is a vector of zeros, with ‘1’ in the position of the word. However, this representation has some disadvantages.</p>

<figure>
    <a href="/assets/img/sentence-embeddings-part-1/one_hot_encoding.png"><img src="/assets/img/sentence-embeddings-part-1/one_hot_encoding.png" style="max-width: 100%" /></a>
    <figcaption style="text-align: center">Figure 1 - One-hot encoded representation of the words "Rome", "Paris", "Italy" and "France" (Source: <a href="https://speakerdeck.com/marcobonzanini/word-embeddings-for-natural-language-processing-in-python-at-london-python-meetup?slide=14" target="_blank">Marco Bonzanini, Word Embeddings for Natural Language Processing in Python @ London Python meetup</a>)</figcaption>
</figure>

<p>The representation of each word is <strong>very high-dimensional</strong> (a vector with the size of the vocabulary) but sparse (only one entry has the value ‘1’).</p>

<p>This does not provide much information about the word meaning, and it does not reveal any existing relationship between words. The representation of the word “Rome” is as close to the representation of the word “Paris” as any other word in the corpus, because their representations always differ in the same way. All other positions are the same with exception to the position of the word “Rome” and the position of the other word.</p>

<p>Another representation currently used is <strong>Word Embeddings</strong> (Figure 2). An embedding is a low-dimensional space that can represent a high-dimensional vector (such as the one-hot encoding of a word) in a compressed vector.</p>

<figure>
    <a href="/assets/img/sentence-embeddings-part-1/word_embeddings.png"><img src="/assets/img/sentence-embeddings-part-1/word_embeddings.png" style="max-width: 100%" /></a>
    <figcaption style="text-align: center">Figure 2- Word embeddings of the words "Rome", "Paris", "Italy" and "France". We can see that the words "Rome" and "Paris" have similar embeddings, probably because they are both capital cities. (Source: <a href="https://speakerdeck.com/marcobonzanini/word-embeddings-for-natural-language-processing-in-python-at-london-python-meetup?slide=22" target="_blank">Marco Bonzanini, Word Embeddings for Natural Language Processing in Python @ London Python meetup</a>)</figcaption>
</figure>

<p>Besides the higher density of those vectors, the <strong>advantage of the embeddings is the closeness between similar words</strong>. That means that words such as “Rome” or “Paris” will probably have a similar embedding, different from the embedding of “Internet”, for example. That is very useful for many other Natural Language Processing (NLP) tasks, such as word clustering or topic analysis.</p>

<h1 id="obtaining-sentence-representations-with-tf-idf">Obtaining Sentence Representations with TF-IDF</h1>

<p>To represent sentences, it is impossible to create a one-hot encoding schema: there is an infinite number of sentences. We have to use other kinds of sentence representations.</p>

<p>We are going to explain four different sentence representation algorithms in this blog series. For this post, let’s learn more about TF-IDF!</p>

<p><strong><a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">TF-IDF</a></strong> (Term Frequency-Inverse Document Frequency) is a classical information retrieval method, commonly used by search engines, where the goal is to quickly search documents in a large corpus. Those documents can be sentences, dialogues or even long texts.</p>

<p>TF-IDF creates a term-document matrix (Figure 3), where each term has associated all the documents where it appears, and a weight for each term-document entry. The weight of a term in a document increases with the number of times that the term appears in that particular document, and decreases with the frequency that the term appears in all documents. In that way, terms such as “a” or “the” in an English corpus will have lower weight because they appear in many documents.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/d50f98f79c76622eca45686d114399df.js"></script>

<figcaption style="text-align: center">Figure 3 - Example of the matrix created by TF-IDF, where the documents are dialogues.</figcaption>

<p>A training corpus (set of documents) must be used to create the TF-IDF matrix. The dimensions of the matrix will be the number of different terms in the corpus by the number of documents in the corpus.</p>

<p>The representation of a document is calculated by comparison with the documents in the training corpus.</p>

<p>The document representation will be a row vector with the size of the number of documents in the corpus, where each entry <em>i</em> will have a value that represents the similarity of the input document with the document <em>i</em> in the corpus (Figure 4).</p>

<p>That similarity is calculated based on the terms mentioned both in the input document and in each document in the corpus. A higher weight in the the entry <em>i</em> of the document representation means that there is a higher similarity with the document <em>i</em> in the corpus.</p>

<figure>
    <a href="/assets/img/sentence-embeddings-part-1/TF_IDF.png"><img src="/assets/img/sentence-embeddings-part-1/TF_IDF.png" style="max-width: 100%" /></a>
    <figcaption style="text-align: center">Figure 4 - Calculation of the representation of a document. Using the TF-IDF matrix of Figure 3, is calculated a representation of a document based on the similarity with the dialogues.</figcaption>
</figure>

<p>Document representations based on TF-IDF have some advantages:</p>
<ul>
  <li>They can be calculated very fast, with a lookup on the TF-IDF matrix and a few simple calculations.</li>
  <li>They are conceptually simple when compared with other algorithms.</li>
  <li>Their implementation is transparent and the representation can be easily understood.</li>
</ul>

<p>Their disadvantages are the following:</p>
<ul>
  <li>The similarity between documents does not take into account the position of each word in the document (also known as a bag-of-words model).</li>
  <li>It does not capture the semantics of a document, which means that it does not take into account similar words.</li>
  <li>It creates sparse vectors, which means that it is wasting a lot of memory with zero values.</li>
</ul>

<p>And that’s it for the first post! Read <a href="/sentence-embeddings-part-2/">part 2</a> to know more about more advanced approaches to create Sentence Embeddings.</p>

<p>Thanks for sticking by!</p>]]></content><author><name></name></author><category term="word embeddings" /><category term="sentence embeddings" /><category term="TF-IDF" /><category term="NLP" /><category term="data science" /><summary type="html"><![CDATA[What are Sentence Embeddings and explanation of TF-IDF to generate Sentence Representations]]></summary></entry><entry><title type="html">From Word Embeddings to Sentence Embeddings - Part 2/3</title><link href="http://localhost:4000/sentence-embeddings-part-2/" rel="alternate" type="text/html" title="From Word Embeddings to Sentence Embeddings - Part 2/3" /><published>2020-03-30T00:00:00+02:00</published><updated>2020-03-30T00:00:00+02:00</updated><id>http://localhost:4000/sentence-embeddings-part-2</id><content type="html" xml:base="http://localhost:4000/sentence-embeddings-part-2/"><![CDATA[<figure>
    <a href="/assets/img/sentence-embeddings-part-2/header.jpg"><img src="/assets/img/sentence-embeddings-part-2/header.jpg" style="max-width: 100%" /></a>
    <figcaption style="text-align: center">Designed by <a href="https://br.freepik.com/fotos-gratis/letras-formando-a-palavra-pratica_1330193.htm" target="_blank">Freepik</a></figcaption>
</figure>

<p>Hi there! This post is the second in a three-part series about <strong>Sentence Embeddings</strong>. If you didn’t read part 1, you can find it <a href="/sentence-embeddings-part-1/">here</a>.</p>

<p>In this post, I will explain two approaches to create Sentence Embeddings: Doc2vec and InferSent.</p>

<p>To improve the sentence representations from the <a href="/sentence-embeddings-part-1/">TF-IDF representations</a>, we must take into account the semantics of each word and the word order. Sentence embeddings try to encode all of that.</p>

<p>Sentence embeddings are similar to word embeddings. Each embedding is a low-dimensional vector that represents a sentence in a dense format. There are different algorithms to create Sentence Embeddings, with the same goal of creating similar embeddings for similar sentences.</p>

<h1 id="doc2vec">Doc2vec</h1>

<p>The <strong>Doc2vec</strong> algorithm (or Paragraph Vector) was proposed in 2014 by Quoc Le and Tomas Mikolov [1], both Research Scientists at Google at the time. It is based on the Word2vec algorithm, which creates embeddings of words. The algorithm follows the assumption that a word’s meaning is given by the words that appear close-by.</p>

<blockquote>
  <p>You shall know a word by the company it keeps (J. R. Firth 1957)</p>
</blockquote>

<p>The authors present two variations of the algorithm: the <strong>Distributed Memory model (DM)</strong> and the <strong>Distributed Bag-Of-Words (DBOW)</strong>.</p>

<h2 id="distributed-memory-model">Distributed Memory Model</h2>

<figure>
    <a href="/assets/img/sentence-embeddings-part-2/dmm.png"><img src="/assets/img/sentence-embeddings-part-2/dmm.png" style="max-width: 100%" /></a>
    <figcaption style="text-align: center">Figure 1 - Neural Network architecture of the DM model. (Source: [1])</figcaption>
</figure>

<p>In Figure 1, a Neural Network architecture for the DM model is depicted. Let’s start by analyzing the training stage, and then we will see how the model creates an embedding for a sentence.</p>

<p>Each sentence and each word in the training corpus are converted to a one-hot representation. Both will have an embedding, stored in the matrices D and W, respectively. The training is done by passing a sliding window over the sentence, trying to predict the next word based on the previous words in the context and the sentence vector (or Paragraph Matrix in the figure). The classification of the next word is done by passing the concatenation of the sentence and word vectors into a softmax layer. The word vectors are the same for different sentences, while the sentence vectors are different. Both are updated at each step of the training phase.</p>

<p>The prediction phase is also done by passing a sliding window over the sentence, trying to predict the next word given the previous words. All the weights of the model are fixed, with exception to the weights of the sentence vector, that are updated for every step. After all the predictions of the next word are computed for a sentence, the sentence embedding is the resultant sentence vector.</p>

<h2 id="distributed-bag-of-words-model">Distributed Bag-Of-Words Model</h2>

<figure>
    <a href="/assets/img/sentence-embeddings-part-2/dbow.png"><img src="/assets/img/sentence-embeddings-part-2/dbow.png" style="max-width: 100%" /></a>
    <figcaption style="text-align: center">Figure 2 - Neural Network architecture of the DBOW model. (Source: [1])</figcaption>
</figure>

<p>Figure 2 shows the Neural Network architecture for the DBOW model. This model ignores the word order and has a simpler architecture, with fewer weights to be learned.</p>

<p>Each sentence in the training corpus is also converted into a one-hot representation. The training is done by, on each iteration, selecting a random sentence from the corpus and, from that sentence, selecting a random number of words. The model will try to predict those words based only on the sentence ID, and the sentence vector will be updated (in the Figure, Paragraph ID and Paragraph Matrix, respectively).</p>

<p>In the prediction phase, a new sentence ID is trained with random word samples from the sentence, but the softmax layer has its weights fixed. The sentence vector is updated in each step and the resulting sentence vector is the embedding for that sentence.</p>

<h2 id="comparison">Comparison</h2>

<p>Comparing both methods, the <strong>DM model has some technical advantages over the DBOW model</strong>:</p>
<ul>
  <li>the DM model takes into account the word order, while the DBOW model doesn’t.</li>
  <li>the DBOW model does not use word vectors, which means that the semantics of the words are not preserved and it’s harder to detect similarities between words.</li>
  <li>due to the simpler architecture of the DBOW model, it takes many more steps to train to obtain accurate vectors.</li>
</ul>

<p>The main drawback of the DM model is the time and the resources needed to generate an embedding, which are higher than with the DBOW model.</p>

<p>What approach produces better Sentence Embeddings? In the original paper, the authors say that the DM is “consistently better than” DBOW. However, <strong>recent studies reported that the DBOW approach is better for most tasks</strong> [2]. The implementation in Gensim of Doc2Vec [3] has the DBOW approach as the default algorithm, because it was found to have better results than the DM approach.</p>

<h1 id="infersent">InferSent</h1>

<p>InferSent is another Sentence Embedding method, presented by Facebook AI Research in 2018 [4], with an implementation and trained models available in Github [5].</p>

<p>It has some differences from the previous algorithm in the training process: instead of unsupervised learning to train a Language Model (LM) (a model that predicts the next word), it <strong>uses supervised learning to perform Natural Language Inference (NLI)</strong> (a model that predicts if an hypothesis, when compared to a premise, is true (entailment), false (contradiction) or undetermined (neutral)).</p>

<figure>
    <a href="/assets/img/sentence-embeddings-part-2/infersent.png"><img src="/assets/img/sentence-embeddings-part-2/infersent.png" style="max-width: 100%" /></a>
    <figcaption style="text-align: center">Figure 3 - Generic architecture for training embeddings using NLI. (Source: [4])</figcaption>
</figure>

<p>Figure 3 represents a generic training architecture for this approach. The <em>u</em> and <em>v</em> have shared weights, and are the Sentence Embeddings that we will obtain in the end.</p>

<p>In the training phase, the Sentence Embeddings of the premise and the hypothesis are concatenated, along with its element-wise product and its element-wise difference. The resulting vector is fed into multiple fully-connected layers, that finish with a 3-class softmax (the classes are entailment, contradiction or neutral).</p>

<p>What should be the architecture to create Sentence Embeddings? The authors tried different architectures, but here I will only describe the one that had the best results, that is the one implemented in InferSent: a <strong>BiLSTM with max pooling</strong>.</p>

<figure>
    <a href="/assets/img/sentence-embeddings-part-2/bilstm.png"><img src="/assets/img/sentence-embeddings-part-2/bilstm.png" style="max-width: 100%" /></a>
    <figcaption style="text-align: center">Figure 4 - Bi-LSTM with max pooling architecture used in InferSent to generate embeddings. (Source: [4])</figcaption>
</figure>

<p>Figure 4 describes the architecture of the Bi-LSTM with max pooling. I will not explain thoroughly what an LSTM (Long Short-Term Network) is in this post (there’s great blog post about that in [6]).</p>

<p>In short, an LSTM is a neural network with the ability to remember previous inputs and use them in the computation of the next outputs (recurrent neural network). That is done by a hidden vector (<em>h</em> in Figure 8) that represents the memory of the current state of the input. This architecture contains a Bi-directional LSTM network, which means that two LSTM networks are applied: one takes care of the previous inputs to predict the output of the next step (forward LSTM), the other LSTM is reversed: it looks at the inputs from the end to the beginning, and tries to predict in that order (backwards LSTM).</p>

<p>The output vectors of both LSTM networks are then concatenated, and the final embedding is the maximum value over the dimension of the hidden units, as seen in Figure 4.</p>

<p>At the cost using supervised data for training and a complex recurrent neural network (RNN) architecture, this approach creates great Sentence Embeddings.</p>

<p>With the advent of the Transformers and BERT, another architecture became SOTA in 2019 - <strong>Sentence-BERT</strong>. Read <a href="/sentence-embeddings-part-3/">part 3</a> to know more about it!</p>

<p>Thanks for sticking by!</p>

<h1 id="references">References</h1>

<ul>
  <li>[1]: Quoc Le and Tomas Mikolov: “Distributed Representations of Sentences and Documents”, 2014; <a href="https://arxiv.org/abs/1405.4053">arXiv:1405.4053</a>.</li>
  <li>[2]: Jey Han Lau and Timothy Baldwin: “An Empirical Evaluation of doc2vec with Practical Insights into Document Embedding Generation”, 2016, Proceedings of the 1st Workshop on Representation Learning for NLP, Berlin, Germany, pp. 78–86; <a href="https://arxiv.org/abs/1607.05368">arXiv:1607.05368</a>.</li>
  <li>[3]: Gensim - <a href="https://radimrehurek.com/gensim/models/doc2vec.html">Doc2vec paragraph embeddings</a>.</li>
  <li>[4]: Alexis Conneau, Douwe Kiela, Holger Schwenk, Loic Barrault: “Supervised Learning of Universal Sentence Representations from Natural Language Inference Data”, 2017; <a href="https://arxiv.org/abs/1705.02364">arXiv:1705.02364</a>.</li>
  <li>[5]: <a href="https://github.com/facebookresearch/InferSent">InferSent implementation</a>.</li>
  <li>[6]: Christopher Olah, <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a>.</li>
</ul>]]></content><author><name></name></author><category term="sentence embeddings" /><category term="data science" /><category term="NLP" /><category term="Doc2vec" /><category term="InferSent" /><summary type="html"><![CDATA[Explanation of Doc2Vec and InferSent approaches to obtain Sentence Embeddings]]></summary></entry><entry><title type="html">From Word Embeddings to Sentence Embeddings - Part 3/3</title><link href="http://localhost:4000/sentence-embeddings-part-3/" rel="alternate" type="text/html" title="From Word Embeddings to Sentence Embeddings - Part 3/3" /><published>2020-03-30T00:00:00+02:00</published><updated>2020-03-30T00:00:00+02:00</updated><id>http://localhost:4000/sentence-embeddings-part-3</id><content type="html" xml:base="http://localhost:4000/sentence-embeddings-part-3/"><![CDATA[<figure>
    <a href="/assets/img/sentence-embeddings-part-3/header.jpg"><img src="/assets/img/sentence-embeddings-part-3/header.jpg" style="max-width: 100%" /></a>
    <figcaption style="text-align: center">Designed by <a href="https://br.freepik.com/fotos-gratis/letras-formando-as-palavras-progresso-crescimento-e-sucesso_1330222.htm" target="_blank">Freepik</a></figcaption>
</figure>

<p>Hi there! This post is the last one in a three-part series about <strong>Sentence Embeddings</strong>. If you didn’t read part 1 or part 2, you can find them <a href="/sentence-embeddings-part-1/">here</a> and <a href="/sentence-embeddings-part-2/">here</a>.</p>

<p>In this post, I will explain the State-Of-The-Art (SOTA) approach to create Sentence Embeddings.</p>

<h1 id="sentence-bert">Sentence-Bert</h1>
<p>Sentence-Bert is currently (April, 2020) the <strong>SOTA algorithm to create Sentence Embeddings</strong>. It was presented in 2019 by Nils Reimers and Iryna Gurevych [1], and it takes advantage of the BERT model to create even better Sentence Embeddings, taking into account long-term dependencies in the text and the context from many previous timesteps.</p>

<p>To understand the Sentence-BERT architeture, a <strong>few concepts must be explained</strong>.</p>

<h2 id="attention-mechanism">Attention mechanism</h2>

<p>As said in <a href="/sentence-embeddings-part-2/">part 2</a>, the LSTMs have a hidden vector that represents the memory at a current state of the input. However, for long inputs, such as long sentences, a vector does not give all the needed information to predict the next state correctly. The <strong>LSTM can make mistakes because, in practice, it only has information from a limited number of steps back, due to the bottleneck of the size of the hidden vector that represents the state</strong>.</p>

<p>To solve that, the Attention mechanism ([3], [4]) was introduced in 2014. Instead of a single vector, <strong>the model has access to all the previous hidden states before deciding what to predict</strong> (a better explanation can be found in [4]). Attention helped with the long-term dependencies problem.</p>

<h2 id="transformer">Transformer</h2>

<p>Another problem of LSTMs is the <strong>time to train</strong>. Because the output always depends on the previous input, the training is done sequentially, taking too much time. The Transformer architecture, presented by Google Brain and University of Toronto in 2017 [5], <strong>showed how to use the attention mechanism in a neural architecture that could be parallelized, taking less time to train and achieving better results</strong> in Machine Translation tasks.</p>

<figure>
    <a href="/assets/img/sentence-embeddings-part-3/transformer.png"><img src="/assets/img/sentence-embeddings-part-3/transformer.png" style="max-width: 100%" /></a>
    <figcaption style="text-align: center">Figure 1 - Transformer architecture. (Source: [5])</figcaption>
</figure>

<p>Figure 1 shows the complete architecture of the Transformer. A detailed explanation can be found in [6]. The architecture is composed of two parts: an encoder and a decoder. <strong>The encoder encodes the representation of the input, while the decoder tries to output a probability</strong> based on the encoder representation and the previous outputs. The encoder and decoder basic building blocks are feed-forward layers and self-attention layers. Self-attention layers look at the entire input and try to pay attention to the most important parts, instead of relying on a single hidden state representation.</p>

<p>The results of the transformer architecture applied to sentence translation resulted in a big improvement over the previous State-Of-The-Art model. The transformer revolutionized the NLP field, because now it was possible to train large datasets in a reasonable time with a model less vulnerable to long-term dependencies problems. However, why should we stick to using just one transformer? <strong>What happens if we stack many transformers and train them a little bit differently to obtain better performance?</strong></p>

<h2 id="bert">BERT</h2>

<p>BERT was presented in mid-2019 by the Google AI language team [7] and fulfilled the promises of using the Transformers to create a general language understanding model much better than all its predecessors, taking a huge step forward in NLP development. When it was presented, it achieved SOTA results in tasks such as question answering or language inference with minor modifications in its architecture.</p>

<figure>
    <a href="/assets/img/sentence-embeddings-part-3/bert.png"><img src="/assets/img/sentence-embeddings-part-3/bert.png" style="max-width: 100%" /></a>
    <figcaption style="text-align: center">Figure 2 - BERT Architecture for pre-training and fine-tuning. (Source: [7])</figcaption>
</figure>

<p>Figure 2 shows the BERT architecture. It is mainly composed of a <strong>multi-layer bidirectional Transformer encoder</strong> (the large model is composed of 24 layers of Transformer blocks), where the inputs are the Embeddings of each token in the input.</p>

<p>An important aspect of this architecture is the <strong>bidirectionality, that enables BERT to learn forward and backward dependencies</strong>. That is achieved by pre-training BERT with two different objective tasks:</p>

<ul>
  <li>
    <p><strong>Masked Language Model</strong>, also described as Cloze Task, enables BERT to learn bidirectional dependencies. Instead of predicting the next word in a sentence, it masks some percentage of the input tokens at random and predicts those masked tokens. This forces the model to learn not only forward, but also backward dependencies between tokens.</p>
  </li>
  <li>
    <p><strong>Next Sentence Prediction</strong> feeds the model two sentences and predicts if the sentences are next to each other. This task forces the model to learn the relationship between two sentences, which is not directly captured by language modeling.</p>
  </li>
</ul>

<p>After obtaining the pre-trained model with unsupervised data, the fine-tuning part can be adapted to different NLP tasks, just by changing the input and the output of the model. An interesting conclusion from the paper is that <strong>the higher the number of Transformer Layers, the better the results for the downstream tasks</strong>.</p>

<h2 id="sentence-bert-approach">Sentence-BERT approach</h2>
<p>Finally, we reach to Sentence-BERT approach.</p>

<p>To calculate the similarity between two sentences using BERT, it is needed to feed into the network both sentences. Due to BERT complexity, calculating the similarity with 10000 sentences requires approximately 65 hours of computations.</p>

<p><strong>Sentence-BERT is an approach to create semantic meaningful Sentence Embeddings that can be compared with cosine-similarity, maintaining BERT accuracy but reducing the effort for finding the most similar pair from 65 hours to 5 seconds</strong>.</p>

<figure>
    <a href="/assets/img/sentence-embeddings-part-3/sentence-bert.png"><img src="/assets/img/sentence-embeddings-part-3/sentence-bert.png" style="max-width: 100%" /></a>
    <figcaption style="text-align: center">Figure 3 - Sentence-BERT training architecture. (Source:[1])</figcaption>
</figure>

<p>Sentence-BERT architecture is depicted in Figure 3. The training goal (the same used for InferSent) is to classify pairs of sentences according to their similarity: entailment (sentences are related), contradictory (sentences are contradictory) or neutral (sentences are not related). A pair of sentences are fed to BERT, followed by a pooling layer (it can be max pooling, mean pooling or use the CLS token in BERT output), that will generate an embedding for each sentence. Both embeddings are concatenated with their difference and are fed to a 3-way softmax layer. This training schema is often called a Siamese Network [8].</p>

<p>By fine-tuning BERT weights with this architecture, the <strong>embeddings generated are suitable for sentence similarity</strong>, by sending a sentence through Bert and applying a pooling operation.</p>

<h1 id="comparing-the-algorithms">Comparing the algorithms</h1>
<p>Now that we have seen four algorithms for creating sentence representations (check the previous algorithm <a href="/sentence-embeddings-part-1/">here</a> and <a href="/sentence-embeddings-part-2/">here</a>), let’s test them and see the results. This <a href="https://github.com/diogodanielsoaresferreira/document_representations_tests/blob/master/Sentence%20Similarity.ipynb">Jupyter notebook</a> contains a test with the four approaches.</p>

<p>Given a news dataset, creates representations of the description of the news with the four approaches. Given a query inserted by the user, it will generate a representation of that query and it will compare it with all the news representations. That comparison is done using the Cosine Similarity. The top five most similar news descriptions are printed to the notebook. Let’s analyse some results.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/c8228df45d8516fb1bbb727b38c6a223.js"></script>

<p>The query was “Democrats win republicans in election.” All approaches produce good results, but it seems that <strong>InferSent and Sentence-Bert have better matches</strong>. Let’s see another result.</p>

<script src="https://gist.github.com/diogodanielsoaresferreira/e45bbac61a57ca92d3bef89bdb306e1c.js"></script>

<p>This query is particularly difficult for the first three approaches. <strong>Only Sentence-Bert seems to have produced correct results</strong>.</p>

<p>You can see more interesting results in the notebook <a href="https://github.com/diogodanielsoaresferreira/document_representations_tests/blob/master/Sentence%20Similarity.ipynb">here</a>.</p>

<p>There are other algorithms for producing sentence representations that we tested but they were not explored in this post. If you want to know more I suggest you take a look at <strong>Universal Sentence Encoder [9], Skip-thought [10] or FastSent [11]</strong>.</p>

<p>In summary, there are various algorithms to create sentence representations. Besides its performance, it’s also important to take into account their speed and memory requirements.</p>

<p>Sentence embeddings are an open area of research with big advances in the last few years, and they are in growing demand by industry applications, such as Chat Bots and Search Engines. It is important to keep up the pace with the latest developments in the area of research.</p>

<p>Thanks for sticking by until the last part of this series about Sentence Embeddings!</p>

<h1 id="references">References</h1>
<ul>
  <li>[1]: Nils Reimers and Iryna Gurevych: “Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks”, 2019; <a href="https://arxiv.org/abs/1908.10084">arXiv:1908.10084</a>.</li>
  <li>[2]: Dzmitry Bahdanau, Kyunghyun Cho and Yoshua Bengio: “Neural Machine Translation by Jointly Learning to Align and Translate”, 2014; <a href="https://arxiv.org/abs/1409.0473">arXiv:1409.0473</a>.</li>
  <li>[3]: Minh-Thang Luong, Hieu Pham and Christopher D. Manning: “Effective Approaches to Attention-based Neural Machine Translation”, 2015; <a href="https://arxiv.org/abs/1508.04025">arXiv:1508.04025</a>.</li>
  <li>[4] - Jay Alammar, <a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)</a>.</li>
  <li>[5] - Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez andLukasz Kaiser: “Attention Is All You Need”, 2017; <a href="https://arxiv.org/abs/1706.03762">arXiv:1706.03762</a>.</li>
  <li>[6] - Jay Alammar, <a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a>.</li>
  <li>[7] - Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova: “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding”, 2018; <a href="https://arxiv.org/abs/1810.04805">arXiv:1810.04805</a>.</li>
  <li>[8] - Jane Bromley, Isabelle Guyon, Yann LeCun, Eduard Sackinger and Roopak Shah: “<a href="https://papers.nips.cc/paper/769-signature-verification-using-a-siamese-time-delay-neural-network.pdf">Signature Verification using a Siamese Time Dealy Neural Network</a>”, 1994.</li>
  <li>[9] - Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St. John, Noah Constant, Mario Guajardo-Cespedes, Steve Yuan, Chris Tar, Yun-Hsuan Sung, Brian Strope and Rey Kurzweil: “Universal Sentence Encoder”, 2018; <a href="https://arxiv.org/abs/1803.11175">arXiv:1803.11175</a>.</li>
  <li>[10] - Ryan Kiros, Yukun Zhu, Ruslan Salakhutdinov, Richard S. Zemel, Antonio Torralba, Raquel Urtasun and Sanja Fidler: “Skip-Thought Vectors”, 2015; <a href="https://arxiv.org/abs/1506.06726">arXiv:1506.06726</a>.</li>
  <li>[11] - Felix Hill, Kyunghyun Cho and Anna Korhonen: “Learning Distributed Representations of Sentences from Unlabelled Data”, 2016; <a href="https://arxiv.org/abs/1602.03483">arXiv:1602.03483</a>.</li>
</ul>]]></content><author><name></name></author><category term="sentence embeddings" /><category term="data science" /><category term="NLP" /><category term="BERT" /><category term="Transformers" /><category term="Attention" /><category term="Sentence-BERT" /><summary type="html"><![CDATA[Explanation of Sentence-BERT approach to obtain Sentence Embeddings]]></summary></entry><entry><title type="html">What the hell is a Bloom Filter?</title><link href="http://localhost:4000/bloom-filter/" rel="alternate" type="text/html" title="What the hell is a Bloom Filter?" /><published>2019-12-07T00:00:00+01:00</published><updated>2019-12-07T00:00:00+01:00</updated><id>http://localhost:4000/bloom-filter</id><content type="html" xml:base="http://localhost:4000/bloom-filter/"><![CDATA[<p>Hi there!</p>

<p>In this post I will describe what is a Bloom Filter, its purpose and scenarios where it can be useful to use one. I will also implement a Bloom Filter from scratch in Python, for an easier understanding of its internals.</p>

<h2 id="goal-of-a-bloom-filter">Goal of a Bloom Filter</h2>

<p>A Bloom Filter is a data structure with the goal of checking if an element is <strong>NOT</strong> in a set in a fast way (for those who know Big O notation, the complexity of inserting and checking if an element belongs to a set using a Bloom Filter is O(1)). It can be very useful to prevent a computation-intensive task to be done often, simply by verifying if the element is <em>definitely not</em> in a set. It is important to understand that the Bloom Filter is a probabilistic data structure: it can tell you that an element is not in the dataset with 100% probability, but it cannot tell you that an element is in the set with 100% probability (false positives are possible). Let’s talk about scenarios where a Bloom Filter can be used, and later on you will understand why the Bloom Filter has these characteristics, with a detailed explanation of its internals and an implementation in Python!</p>

<figure>
    <a href="/assets/img/bloom_filter.png"><img src="/assets/img/bloom_filter.png" style="max-width: 80%" /></a>
    <figcaption style="text-align: center">A bloom filter is usually used before a search in a set with slower access. The number of searches in the set can be reduced, so as the overall search time.</figcaption>
</figure>

<h2 id="scenarios">Scenarios</h2>

<p>Let’s think of some scenarios where such data structure can be useful to speed up the computation of some tasks. We can start by thinking in a router of a core network (those that you don’t have in your house :) ). It can be required for those routers to have an uplink speed of over 100 Gbit/s. The administrator can add a blacklist of IPs to block their access in the network. That means that everytime that the router receives a packet, at over 100 Gbit/s, it must look at his memory and perform, at best, a logarithmic search (O(log(n))) to check if the IP is blocked, knowing that most IPs are not blocked and that the search will not return any results for most packets. In this case, a Bloom Filter can be placed before the access to memory, to make sure that most packets do not need to wait the time of a search of an IP to be sent to the network.</p>

<p>Another scenario is the database example. When a database has millions of accesses per second, and most of the accesses are searches by a key that is not in the database, it can be important to reduce the impact of the calls on the database, for two reasons: if the number of searches is reduced, the database engine will reply faster to other accesses; if it is possible for a client to not wait for a search on the database and have the result (e.g. not in memory) without needing to access the database, the achieved speedup can be significant.</p>

<p>Finally, to speed up the search for a file in a folder with many files, the Bloom Filter can be used to check if the file is definitely not in the folder.</p>

<p>More typical scenarios of usage of a Bloom Filter can be found <a href="https://en.wikipedia.org/wiki/Bloom_filter#Examples">here</a>.</p>

<h2 id="what-is-a-bloom-filter">What is a bloom filter?</h2>

<p>Let’s use the first scenario to exemplify the construction of a Bloom Filter. Imagine that you blacklist 100 IP’s. The easiest way to mark if an IP was blacklisted or not is to create a list with 100 bits, each bit is one IP. If an IP is blacklisted, we mark the position of the IP as ‘1’, otherwise is ‘0’.</p>

<figure>
    <a href="/assets/img/empty_bloom_filter.png"><img src="/assets/img/empty_bloom_filter.png" style="max-width: 30%" /></a>
    <figcaption style="text-align: center">In this Bloom Filter, the IP number 4 is blacklisted and all other IP's are not.</figcaption>
</figure>

<h3 id="how-many-ips-there-are">How many IP’s there are?</h3>
<p>This implementation works… if only 100 IP’s are used. In reality, each IPv4 address has 32 bits, which means that there are 4 294 967 296 (2<sup>32</sup>) possible addresses (some of them are reserved for private networks, broadcast, multicast and other special networks, but it is still a huge number)! And the number of blacklisted IPs will probably not exceed the hundreds, at maximum. We cannot afford to construct a list so large to use only a reduced number of entries. We have to find a mapping between an IP and an entry of a list. And that’s where hash functions come in!</p>

<h3 id="hash-function">Hash Function</h3>

<p>A hash function is a function that transforms an input of arbitrary length into a fixed-size value. In that way, we can create an array with fixed size and calculate the output of a hash function given an IP, and it will always generate a number smaller or equal to the size of the array. The hash function is not random, which means that for the same input, the output will always be the same.</p>

<figure>
    <a href="/assets/img/hash_function.png"><img src="/assets/img/hash_function.png" style="max-width: 80%" /></a>
    <figcaption style="text-align: center">A hash function receives an input that can be any string (in this case, an IP) and calculates a numerical representation. In this case, the numerical representation will be the position of the Bloom Filter corresponding to the input.</figcaption>
</figure>

<p>But wait… Something is not right. Let’s go back to our scenario. Imagine that we blacklist 100 IP’s. How does the hash function maps our 100 IP’s from a possible 2<sup>32</sup> IP’s to 100 different values without storing any information from them? The truth is that it doesn’t. There will be collisions. The hash function guarantees that each IP will have a unique mapping to a number, but since there can be 4 294 967 296 (2<sup>32</sup>) possible IP’s, it’s impossible to map them all to 100 different values. All the hash function can guarantee is that it scrambles the bits of the input such that the output follows a uniform distribution. This means that if you change the input of the hash function from 192.168.1.1 to 192.168.1.2, the output will probably be totally different, seemingly random (but not truly random, since each input will always map to the same output).</p>

<figure>
    <a href="/assets/img/collision.png"><img src="/assets/img/collision.png" style="max-width: 100%" /></a>
    <figcaption style="text-align: center">Example of a collision. Two different IP's have the same hash, which means that their index in the Bloom Filter will be the same.</figcaption>
</figure>

<p>Alright, now from the beginning: we blacklist 100 IP’s. Each IP will go through the hash function, and the result of the hash function will return a number smaller or equal to the size of the array. That number will be the index of the array that marks if the IP was blacklisted or not. But there will be collisions, so how do we handle that?</p>

<p>Let’s suppose that the IP’s 178.23.12.63 and 112.64.90.12 have the same hash. The first IP was blacklisted, the second was not. When we check if the hash of the second IP is in the Bloom Filter, it is, even though the IP was never blacklisted. Does this mean we have a bug?</p>

<p>Remember that in the beginning I said that the Bloom Filter has the goal of checking if an element is <strong>NOT</strong> in a set. If the position of an element in the Bloom Filter is 0, that element is definitely <strong>NOT</strong> in the set. However, if the position of an element in the Bloom Filter is 1, that element may be in the set, or it may be just a collision. All we can do is to reduce the probability of a collision, to reduce the number of times that the a memory access is needed to check if the IP is really blacklisted.</p>

<h3 id="reducing-the-collision-probability">Reducing the collision probability</h3>

<p>There are two main ways of reducing the probability of a collision, both at a cost. One possibility is to increase the size of the array. If we increase the size of the array (and consequently make the hash function return a number smaller or the same size as the new array size), the possibility of collisions decreases. Specifically, the probability of a false positive (the Bloom Filter return 1 when the element is not in the set) is (1-e<sup>(m/n)</sup>), where m is the number of elements expected to insert in the filter and n is the size of the filter.</p>

<p>Other way to reduce the probability of a collision is to increase the number of hash functions. This means that in our scenario, for one IP, various hash functions will be used to encode that IP, and various locations in the array will be marked with 1. If we use k hash functions, the probability of a false positive is now (1-e<sup>(mk/n)</sup>)<sup>k</sup>, which means that the optimal number of hash functions is (n/m)*ln(2) (more details about the equations <a href="https://en.wikipedia.org/wiki/Bloom_filter#Probability_of_false_positives">here</a>).</p>

<figure>
    <a href="/assets/img/bloom_filter_two_hash_functions.png"><img src="/assets/img/bloom_filter_two_hash_functions.png" style="max-width: 100%" /></a>
    <figcaption style="text-align: center">Example of a bloom filter with two hash functions. There is a collision in one of the hashes of the IP's, but it is possible to check that the IP 112.64.90.12 is not in the set, because one of its Bloom Filter positions is not 1.</figcaption>
</figure>

<p>Let’s implement a Bloom Filter in Python in just around 50 lines of code and see the result!</p>

<p>In the next snippet of code, let’s start by creating a BloomFilter class. The constructor receives the size of the Bloom Filter and, optionally, the number of expected elements that the bloom filter will store. We will use the bitarray library to create an array of bits, and we set them all to zero. Finally, we set the number of hash functions to the equation that returns the optimal number of hash function, given the size of the bloom filter and the number of expected elements.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">bitarray</span> <span class="kn">import</span> <span class="n">bitarray</span>

<span class="k">class</span> <span class="nc">BloomFilter</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">number_expected_elements</span><span class="o">=</span><span class="mi">100000</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">number_expected_elements</span> <span class="o">=</span> <span class="n">number_expected_elements</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">bloom_filter</span> <span class="o">=</span> <span class="n">bitarray</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bloom_filter</span><span class="p">.</span><span class="n">setall</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">number_hash_functions</span> <span class="o">=</span> <span class="nb">round</span><span class="p">((</span><span class="bp">self</span><span class="p">.</span><span class="n">size</span> <span class="o">/</span> <span class="bp">self</span><span class="p">.</span><span class="n">number_expected_elements</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span></code></pre></figure>

<p>Now let’s define a hash function for the Bloom Filter. The implementation used (from <a href="https://gist.github.com/mengzhuo/180cd6be8ba9e2743753">here</a>) implements the DJB2 algorithm. Let’s use it as a black box, since the explanation of the algorithm is beyond the scope of this post.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="k">def</span> <span class="nf">_hash_djb2</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
        <span class="nb">hash</span> <span class="o">=</span> <span class="mi">5381</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">s</span><span class="p">:</span>
            <span class="nb">hash</span> <span class="o">=</span> <span class="p">((</span><span class="nb">hash</span> <span class="o">&lt;&lt;</span> <span class="mi">5</span><span class="p">)</span> <span class="o">+</span> <span class="nb">hash</span><span class="p">)</span> <span class="o">+</span> <span class="nb">ord</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">hash</span> <span class="o">%</span> <span class="bp">self</span><span class="p">.</span><span class="n">size</span></code></pre></figure>

<p>Now we have on hash function, but how do we create K hash functions? We can perform a simple trick that works. Instead of creating different hash functions, we will just append a number for each input in the hash function. The number will represent the hash function number that is being called. Because any small difference in the input of a hash function will result in a totally different hash, the result can be seen as a different hash function. Cool, right?</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="k">def</span> <span class="nf">_hash</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_hash_djb2</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">K</span><span class="p">)</span> <span class="o">+</span> <span class="n">item</span><span class="p">)</span></code></pre></figure>

<p>Now let’s create a function to add an element to the Bloom Filter. For that, let’s iterate through all of the hash functions, calculate the hash for the item and finally put a 1 (or True) in the index of the hash.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="k">def</span> <span class="nf">add_to_filter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">number_hash_functions</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">bloom_filter</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">_hash</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span></code></pre></figure>

<p>The only thing that’s left is to create a function that checks if the element is <em>NOT</em> in the Bloom Filter. For that, let’s iterate again through all the hash functions. If any of the Bloom Filter positions has 0, we can say that the element is definitely not in the set. Otherwise, if all positions have 1, we cannot say that the element is not in the set.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="k">def</span> <span class="nf">check_is_not_in_filter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">number_hash_functions</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">bloom_filter</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">_hash</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">i</span><span class="p">)]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">True</span>
        <span class="k">return</span> <span class="bp">False</span></code></pre></figure>

<p>And that’s it! We have implemented our Bloom Filter. Let’s try it out!</p>

<p>Let’s create a simple test to check if it is working. Let’s create a Bloom Filter with 1 million entries, and then set the expected number of elements to 100 000. We are going to add the element “192.168.1.1” to our Bloom Filter as the blocked IP.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">bloom_filter</span> <span class="o">=</span> <span class="n">BloomFilter</span><span class="p">(</span><span class="mi">1000000</span><span class="p">,</span> <span class="mi">100000</span><span class="p">)</span>
<span class="n">base_ip</span> <span class="o">=</span> <span class="s">"192.168.1."</span>
<span class="n">bloom_filter</span><span class="p">.</span><span class="n">add_to_filter</span><span class="p">(</span><span class="n">base_ip</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span></code></pre></figure>

<p>To test it, we will iterate from 1 to 100 000, and check if the IP 192.168.1.i is in the Bloom Filter (there are no IP’s when i&gt;254, e.g. 192.168.289, but in this case we are just performing a test). We will print the elements that we don’t know if they are in the set; all other elements that will not be printed are definitely not in the set.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100000</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">bloom_filter</span><span class="p">.</span><span class="n">check_is_not_in_filter</span><span class="p">(</span><span class="n">base_ip</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)):</span>
        <span class="k">print</span><span class="p">(</span><span class="n">base_ip</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span></code></pre></figure>

<blockquote>
  <p>192.168.1.1</p>
</blockquote>

<p>Wow! Our Bloom Filter says that, from 100 000 IP’s, the only element that could be blocked is really our blocked IP! It did not produce any False Positive!</p>

<p>Here is the full code of our Bloom Filter:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">bitarray</span> <span class="kn">import</span> <span class="n">bitarray</span>


<span class="k">class</span> <span class="nc">BloomFilter</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">number_expected_elements</span><span class="o">=</span><span class="mi">100000</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">number_expected_elements</span> <span class="o">=</span> <span class="n">number_expected_elements</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">bloom_filter</span> <span class="o">=</span> <span class="n">bitarray</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bloom_filter</span><span class="p">.</span><span class="n">setall</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">number_hash_functions</span> <span class="o">=</span> <span class="nb">round</span><span class="p">((</span><span class="bp">self</span><span class="p">.</span><span class="n">size</span> <span class="o">/</span> <span class="bp">self</span><span class="p">.</span><span class="n">number_expected_elements</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>


    <span class="k">def</span> <span class="nf">_hash_djb2</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
        <span class="nb">hash</span> <span class="o">=</span> <span class="mi">5381</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">s</span><span class="p">:</span>
            <span class="nb">hash</span> <span class="o">=</span> <span class="p">((</span><span class="nb">hash</span> <span class="o">&lt;&lt;</span> <span class="mi">5</span><span class="p">)</span> <span class="o">+</span> <span class="nb">hash</span><span class="p">)</span> <span class="o">+</span> <span class="nb">ord</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">hash</span> <span class="o">%</span> <span class="bp">self</span><span class="p">.</span><span class="n">size</span>


    <span class="k">def</span> <span class="nf">_hash</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_hash_djb2</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">K</span><span class="p">)</span> <span class="o">+</span> <span class="n">item</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">add_to_filter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">number_hash_functions</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">bloom_filter</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">_hash</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>


    <span class="k">def</span> <span class="nf">check_is_not_in_filter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">number_hash_functions</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">bloom_filter</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">_hash</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">i</span><span class="p">)]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">True</span>
        <span class="k">return</span> <span class="bp">False</span>


<span class="n">bloom_filter</span> <span class="o">=</span> <span class="n">BloomFilter</span><span class="p">(</span><span class="mi">1000000</span><span class="p">,</span> <span class="mi">100000</span><span class="p">)</span>
<span class="n">base_ip</span> <span class="o">=</span> <span class="s">"192.168.1."</span>
<span class="n">bloom_filter</span><span class="p">.</span><span class="n">add_to_filter</span><span class="p">(</span><span class="n">base_ip</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100000</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">bloom_filter</span><span class="p">.</span><span class="n">check_is_not_in_filter</span><span class="p">(</span><span class="n">base_ip</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)):</span>
        <span class="k">print</span><span class="p">(</span><span class="n">base_ip</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span></code></pre></figure>

<p>And that’s it for Bloom Filters! I hope that you have learned what a Bloom Filter is in detail and how to implement it.</p>

<p>Thanks for sticking by!</p>]]></content><author><name></name></author><category term="algorithms" /><category term="data structures" /><category term="big data" /><category term="bloom filter" /><summary type="html"><![CDATA[Bloom Filter explanation]]></summary></entry><entry><title type="html">Use agile in your dissertation</title><link href="http://localhost:4000/use-agile-in-your-dissertation/" rel="alternate" type="text/html" title="Use agile in your dissertation" /><published>2019-10-06T00:00:00+02:00</published><updated>2019-10-06T00:00:00+02:00</updated><id>http://localhost:4000/use-agile-in-your-dissertation</id><content type="html" xml:base="http://localhost:4000/use-agile-in-your-dissertation/"><![CDATA[<p>Hi there!</p>

<p>After the previous dissertation posts, I noticed that the agile principles were the basis of some tips that I gave. There are remarking similarities between my tips and some agile principles. However, many people still fail in getting a good experience out of the dissertation because they don’t apply these principles. In this post, I will explain how the 12 Agile principles relate to the dissertation, and how to apply them to achieve a better dissertation.</p>

<p>For all that don’t know what Agile is, here is a quick explanation.</p>

<h2 id="what-is-agile">What is agile?</h2>
<p>The Agile Manifesto was created in January of 2001 in a meeting in a Ski Resort, in Utah, by a restrict group of software development experts, such as Bob Martin (Uncle Bob), Kent Beck and Martin Fowler. The goal was to discuss lightweight practices for software development, to allow for better and faster software development.</p>

<p>The agile manifesto is not a set of rules which you must strictly follow, neither a set of tools that you must use. Instead, it is a set of recommended principles that aim the collaborative development for a software project. It is based on iterative and incremental development methods, introduced many years before the Agile manifesto.</p>

<p>Let’s go through the 12 Agile principles and I will explain how I think that they can be applied - or not - in your dissertation.</p>

<h2 id="1---our-highest-priority-is-to-satisfy-the-customer-through-early-and-continuous-delivery-of-valuable-software">1 - Our highest priority is to satisfy the customer through early and continuous delivery of valuable software.</h2>

<p>This principle must be broken down into parts for better understanding.</p>
<ul>
  <li>
    <p>“Our highest priority is to satisfy the customer” - Who is the customer in a dissertation?
The customer is always the entity that decides if the software is as good as requested. In a dissertation, the customer is the jury. Not only your supervisor, not the whole academia, and certainly not your dissertation presentation audience. Always have this in mind when writing the dissertation. The highest priority is to satisfy the jury to have a good grade.</p>
  </li>
  <li>
    <p>“through early and continuous delivery” - How to approach early and continuous delivery?
Early and continuous delivery in a dissertation means to deliver work at a regular pace, following a defined plan with time-bounded activities. For a student, early and continuous delivery means not to leave all the work for the last week. This avoids unexpected difficulties that delay the work, by working through them and planning them with time. Besides, it avoids the regular last-week-sprint burnout. Most importantly, it gives your supervisor an idea of how your dissertation is going long before it ends and allows to change the requirements to improve your work.</p>
  </li>
  <li>
    <p>“of valuable software” - What is valuable software?
In a dissertation there are two types of “valuable software”:</p>
    <ul>
      <li>the dissertation itself</li>
      <li>additional work (software, data analysis, study, …)</li>
    </ul>
  </li>
</ul>

<p>Both of them should be approached to satisfy the jury through early and continuous delivery.</p>

<h2 id="2---welcome-changing-requirements-even-late-in-development-agile-processes-harness-change-for-the-customers-competitive-advantage">2 - Welcome changing requirements, even late in development. Agile processes harness change for the customer’s competitive advantage.</h2>

<div style="width:100%;height:0;padding-bottom:42%;position:relative;"><iframe src="https://giphy.com/embed/2sfgo6v1ihOGKVptoB" width="100%" height="100%" style="position:absolute" frameborder="0" class="giphy-embed" allowfullscreen=""></iframe></div>
<p><a href="https://giphy.com/gifs/disney-trailer-toy-story-4-2sfgo6v1ihOGKVptoB"></a></p>

<p>In a dissertation, this is a very important difference from enterprise projects. In enterprise projects, we should welcome changing requirements because the client pays for the software, and the software is designed for the client. However, most of the dissertations are individual work, and most of the requirements are defined by the student. Although the vision, scope and main goal can be defined by the supervisor, the main requirements are usually defined by the student; besides, a big advantage of the Agile processes does not happen for the dissertation. In an Agile environment, there are regular meetings between the development team and the client. In a dissertation, the client is the jury, so the meetings will be only with the supervisor. Besides, every time that the supervisor asks to change something, it can change your timings for the dissertation deliveries and presentation. So be careful with changes. If you change the requirements of your dissertation, go ahead and apply that to your work. However, if new requirements are added by the supervisor, think carefully if they make sense, and feel free to discuss with him/her his validity.</p>

<p>With one month left for the delivery of the dissertation, however, I would advise you not to make major changes in requirements, because your delivery can be at risk. Before that, feel free to test and try new things, and add them to your work if they are useful.</p>

<h2 id="3---deliver-working-software-frequently-from-a-couple-of-weeks-to-a-couple-of-months-with-a-preference-to-the-shorter-timescale">3 - Deliver working software frequently, from a couple of weeks to a couple of months, with a preference to the shorter timescale.</h2>

<p>This principle can be adapted from “working software” to “readable pieces of your dissertation”. Yes, the dissertation should be made incrementally, and although sometimes it can be hard to write consistent texts without having all the research and implementation done, leaving all the writing to the end it is usually not a good choice, because when writing you will think about new possibilities that can enhance or change your work. You can even detect flaws that you left unnoticed when implementing your work.</p>

<p>Because of that, you should write everything that you do. Even if later on that part can be deleted because it is out of scope, or it is not used - it doesn’t matter. If you are working for your dissertation, everything that you do is important and needs to be in the document. With that, you will deliver “readable pieces of your dissertation” incrementally, and later on it will be much easier to rewrite (if needed) and organize your dissertation’ chapters based on the text that you already have.</p>

<p>But what is frequent? What should be the time interval to deliver work? Just like in Agile, it depends on your work, of yourself and your supervisor. However, I would argue that a meeting once a week with your supervisor to show him/her what you have done is a good time interval. It gives you time to show the work that you did that week and to discuss what to do in the next one. Two-week meetings are also a reasonable choice, but more than two weeks is too much. You can get lost, do something that is not in the scope of your work, or just don’t know what to do, and it will only be discussed in the next meeting. Prefer short weekly meetings to long monthly meetings.</p>

<h2 id="4---business-people-and-developers-must-work-together-daily-throughout-the-project">4 - Business people and developers must work together daily throughout the project.</h2>

<div style="width:100%;height:0;padding-bottom:100%;position:relative;"><iframe src="https://giphy.com/embed/l0IyokIkZEXvWnXGw" width="100%" height="100%" style="position:absolute" frameborder="0" class="giphy-embed" allowfullscreen=""></iframe></div>
<p><a href="https://giphy.com/gifs/netflix-bill-nye-the-science-guy-l0IyokIkZEXvWnXGw"></a></p>

<p>This principle is simple and logical: you and your supervisor must work together. Working together does not mean that your supervisor should start doing your dissertation - it just means that each one must do his job to reach the desired output. You must do your work and your supervisor must supervise you, advise you, guide you, help you when you need, give you the tools you need and stop you when you do anything wrong - not just give you the requirements and wait for what you will do.</p>

<p>I need to emphasize “throughout the project”. Just like in the last principles, “throughout” implies a consistent work discussed in regular meetings over time.</p>

<h2 id="5---build-projects-around-motivated-individuals-give-them-the-environment-and-support-they-need-and-trust-them-to-get-the-job-done">5 - Build projects around motivated individuals. Give them the environment and support they need, and trust them to get the job done.</h2>

<p>I am going to split this principle into two sub-principles. Firstly, to build projects around motivated individuals is to assure that you and your supervisor have the motivation needed to do your work. Many things will go wrong - they always do - and what separates a great from a median work is your willingness to tackle the problems and to work around them. It is not expected for your work to follow a straight path, and you should explain your difficulties in the dissertation, as well as how you tackled them to achieve your goal. An unmotivated student will just avoid the difficulties and find an easy way out.</p>

<p>The latter part of the principle is about trust and support. Make sure your supervisor trusts you. Be totally honest with him/her, explain regularly your difficulties and don’t be shy to ask anything you need. Do you need a specific GPU, a virtual machine, or anything else, just ask him/her. He/she is there to help you with anything you need that is out of your control. Don’t be afraid of saying that you spent a week and you didn’t understand a topic or a paper. Trust him/her to help you do your dissertation.</p>

<h2 id="6---the-most-efficient-and-effective-method-of-conveying-information-to-and-within-a-development-team-is-face-to-face-conversation">6 - The most efficient and effective method of conveying information to and within a development team is face-to-face conversation.</h2>

<div style="width:100%;height:0;padding-bottom:56%;position:relative;"><iframe src="https://giphy.com/embed/xThuW4sMMCqvaczToI" width="100%" height="100%" style="position:absolute" frameborder="0" class="giphy-embed" allowfullscreen=""></iframe></div>
<p><a href="https://giphy.com/gifs/the-grinder-fox-face-tv-xThuW4sMMCqvaczToI"></a></p>

<p>Regular face-to-face meetings are the most efficient way to adjust your work with your supervisor’s expectations. Sure, e-mails and chat messages do come in handy for quick and small questions that you may have and you need the answer ASAP, but nothing beats a face-to-face conversation. Video-conferencing is another way to hold meetings, but it should not be a common way. It should only be applied when one of the intervenients is temporarily away.</p>

<h2 id="7---working-software-is-the-primary-measure-of-progress">7 - Working software is the primary measure of progress.</h2>

<p>As I said above in 3, “working software” in this case can be adapted to “readable pieces of your dissertation”. Yes, there are other ways to measure your progress, mainly based on your work, and they vary on a case-to-case basis. However, what will be evaluated is your dissertation, so the dissertation is the ultimate measure of progress. Start writing as soon as you start doing some work, even if the work is still not finished. Because if have a lot of work but you do not write about it, your work will not be taken into account and you will end up with a poor dissertation.</p>

<h2 id="8---agile-processes-promote-sustainable-development-the-sponsors-developers-and-users-should-be-able-to-maintain-a-constant-pace-indefinitely">8 - Agile processes promote sustainable development. The sponsors, developers, and users should be able to maintain a constant pace indefinitely.</h2>

<p>This principle is very important for a dissertation if you want to reach the end of your work without feeling burnout. It is very important to keep a constant pace of work. It is Ok to work more than 8 hours a day once a week, but not more than that. It is important to separate your work from your personal life for you to feel accomplished and for not getting obsessed with minor obstacles that may seem like the end of the world. Impose on yourself a 40-hour week schedule for work and follow it. If you don’t do it, you may end up working tirelessly for your dissertation but with very low productivity. It will harm not only yourself but also your dissertation.</p>

<h2 id="9---continuous-attention-to-technical-excellence-and-good-design-enhances-agility">9 - Continuous attention to technical excellence and good design enhances agility.</h2>

<p>This is something you should do not only in your dissertation but also in your future career. If you plan carefully your work and if you work with pride, it will reflect on your dissertation and presentation. Even if you do not notice, experient people in every area acknowledge and know how to differentiate between work done with pride and work just to pass the subject. Technical excellence differentiates the median from the great workers in every area - and that can be the difference between an 18 and a 20 in the dissertation.</p>

<h2 id="10---simplicitythe-art-of-maximizing-the-amount-of-work-not-doneis-essential">10 - Simplicity–the art of maximizing the amount of work not done–is essential.</h2>

<p>I love this principle. Because everyone mistakes “work with pride” with “you must do everything that you have planned for your dissertation”. That’s why you plan things: to prioritize what is important and to do things in importance order. If a specific feature will take two weeks to be done and it will not make much of a difference in your dissertation, then why doing it?</p>

<p>The Pareto Principle, also known as the 80/20 rule, says that approximately 80% of the effects come from 20% of the causes. If you pay attention to your life, this principle applies to many things. In your dissertation, 80% of what you will write will be based on 20% of the work. Besides, 80% of your grade will be based on only 20% of your dissertation. Pay attention to that and focus on what’s important - identify your 80% and make them shine. If you have free time, work on parts of the other 20%, but don’t waste much time with them - they are not that important.</p>

<h2 id="11---the-best-architectures-requirements-and-designs-emerge-from-self-organizing-teams">11 - The best architectures, requirements, and designs emerge from self-organizing teams.</h2>

<p>The dissertation is a one-person work (two with the supervisor), so it may look that this principle does not apply to the dissertation. However, you have to look at yourself as “your team”. Because the work is yours more than anybody else, you will have the last word on deciding the architectures, requirements and designs, so do it wisely. Do not accept architectures that are imposed by anyone if you do not agree with them, because you are the one who will have to answer for them sooner or later. Don’t be afraid of creating your own architectures or requirements if they make sense to you. Self-proposed implementations are much valuable in a dissertation and show that the student has deep knowledge about the topic.</p>

<h2 id="12---at-regular-intervals-the-team-reflects-on-how-to-become-more-effective-then-tunes-and-adjusts-its-behavior-accordingly">12 - At regular intervals, the team reflects on how to become more effective, then tunes and adjusts its behavior accordingly.</h2>

<div style="width:100%;height:0;padding-bottom:43%;position:relative;"><iframe src="https://giphy.com/embed/DfSXiR60W9MVq" width="100%" height="100%" style="position:absolute" frameborder="0" class="giphy-embed" allowfullscreen=""></iframe></div>
<p><a href="https://giphy.com/gifs/alan-DfSXiR60W9MVq"></a></p>

<p>You should use this principle with yourself. Sometimes we work so fast and have so many things to do that we forget of reflecting on what we did well and what we need to improve. Once a week take 10 minutes to think about what you have done in that week, what was correctly done and what can be improved. After a month of retrospectives, you will find it very useful to improve your work habits and you will be amazed when checking your performance improvement simply by thinking on what you did wrong and taking preventive measure to not happen again.</p>

<p>That’s it, thanks for sticking by until the end.</p>

<p>See ya on other posts!</p>]]></content><author><name></name></author><category term="thesis" /><category term="dissertation" /><category term="agile" /><summary type="html"><![CDATA[Take advantage of the 12 Agile principles for a better dissertation]]></summary></entry><entry><title type="html">How to have an A+ dissertation/thesis (IV/IV)</title><link href="http://localhost:4000/how-to-have-a-thesis-part-4/" rel="alternate" type="text/html" title="How to have an A+ dissertation/thesis (IV/IV)" /><published>2019-09-13T00:00:00+02:00</published><updated>2019-09-13T00:00:00+02:00</updated><id>http://localhost:4000/how-to-have-a-thesis-part-4</id><content type="html" xml:base="http://localhost:4000/how-to-have-a-thesis-part-4/"><![CDATA[<p>Hi there, and welcome to the last part of this series!</p>

<p>If you didn’t read the previous post, check it out <a href="/how-to-have-a-thesis-part-3/">here</a>. I am summarizing tips I would give myself before starting the dissertation, explaining my good and bad decisions along the way.</p>

<p>Before, a heads up: the content of this blog post is highly subjective and related to my dissertation experience, so don’t take it as the ground truth. But do think critically about my advice and, whether you agree with them or not, comment on what you think about it</p>

<p>This post is divided into four parts:</p>
<ul>
  <li><a href="/how-to-have-a-thesis-part-1/">I - 3 tips for before starting the writing of the dissertation;</a></li>
  <li><a href="/how-to-have-a-thesis-part-2/">II - 4 tips for during the writing of the dissertation;</a></li>
  <li><a href="/how-to-have-a-thesis-part-3/">III - more 4 tips for during the writing of the dissertation;</a></li>
  <li><strong>IV - 3 tips for after the writing of the dissertation.</strong></li>
</ul>

<p>In this post, I will give pieces of advice on what to do after the writing of the dissertation is done. Let’s start!</p>

<h1 id="after-the-dissertation">After the dissertation</h1>

<h2 id="12---review-it-more-than-once">12 - Review it more than once!</h2>

<p>You have <strong>FINALLY</strong> written your dissertation. It’s finally over! But… is it? Every time you read a paragraph of your dissertation you change something. And now you receive the reviewed version of your supervisor, full of changes, and you have to rewrite everything. How many times do you need to review it until it’s done?</p>

<h3 id="my-experience">My Experience</h3>
<p>After the dissertation was written, I reviewed it once before sending it to my supervisor. In that review, besides syntax changes, the major changes done were to the introductions and conclusions of each chapter, that were changed to reflect the chapters’ content. It was also done many changes in the text to make it more clear and objective. After that, I send it to my supervisor. I got a little worried because the final reviewed version was only delivered to me days before the final date to send the final version, but I had the luck of my supervisor making all the minor changes in the document itself. So, when it was delivered to me, I only needed to perform a quick second revision and to make one or two major changes, mainly in the organization of the chapters.</p>

<h3 id="my-advice">My Advice</h3>
<p>After having everything written, I think you should review it at least two times. The first time is a coherency check. Check if the paragraphs and the chapters are coherent between each other. Check if the references are correct. Check if your introduction chapter mentions correctly all chapters and that it provides an overview of your entire work. Check if the introductions and conclusions of each chapter are coherent with what is in each chapter. And more importantly, check if what you write is what you mean, and make an effort to understand if another person would understand what you have written. After the first review is done, you can send it to your supervisor.</p>

<p>Your supervisor will send you a revised dissertation/thesis (hopefully). Now you’re ready for the second review. In the second review, you will mainly apply the changes that your supervisor advised you to (if you want, obviously; do not forget that it is your work, you have the last word!), and you will perform the grammar and syntax check. I advise you to use Grammarly: it gives you good tips on how to improve your writing.</p>

<p>Overall, leave at least three weeks for this process. One week for your first review, one week for your supervisors’ review and one week for your second review. Further revisions can be made, but you will probably only perform minor changes, and it is not needed to review the whole document since you have already done it two times.</p>

<h2 id="13---save-one-week-for-presentation-training">13 - Save one week for presentation training</h2>

<div style="width:100%;height:0;padding-bottom:69%;position:relative;"><iframe src="https://giphy.com/embed/3o7qDEq2bMbcbPRQ2c" width="100%" height="100%" style="position:absolute" frameborder="0" class="giphy-embed" allowfullscreen=""></iframe></div>
<p><a href="https://giphy.com/gifs/mic-drop-peace-out-obama-3o7qDEq2bMbcbPRQ2c"></a></p>

<p>Let’s face it: your grade will be set because of your dissertation, not because of your presentation. At most, the presentation will be used to decide between two grades, if the jury is uncertain. However, because it is a public presentation, we all get nervous and anxious before it happens. How much should we focus on presentation training? What should we do to prepare ourselves for that moment?</p>

<h3 id="my-experience-1">My Experience</h3>
<p>Before the presentation, I was scared of this moment. What if the jury did not like my work? What if they discovered that the work that I have done was simple, and everyone could do it, and what I had done was of no use? To avoid that, I trained hard for the presentation the week before. I made the first version of the presentation and I asked a lot of people for opinions and improvements. Then, I started focusing on what I was going to say. I trained for more than 20 times. For every training, I would adjust just a little bit the presentation - for me to remember what I was going to say; to explain information in graphical form and more explicitly; to be easier for non-experts to understand, etc.</p>

<p>Because I knew possible flaws, omissions or questions about my work, I wrote them and I also wrote the answer that I would give if they were answered to me. That gave me more confidence about my work because I knew that I was probably not going to be surprised with questions that I did not know how to answer (spoiler: none of the questions that were asked was on the list; all the questions were easier to answer).</p>

<p>On the day of the presentation, I knew everything that I was going to say. Curiously, I was not nervous. I was very confident that my presentation was going to good. And looking back, it went so much better than what I have always expected.</p>

<h3 id="my-advice-1">My Advice</h3>
<p>Leave one week for presentation training. Use the first day for creating the presentation. Then, the technique is the same as the writing of the dissertation/thesis: iterate. Present to your supervisors, friends, family, colleagues, … And train, train, train. Ask them to take notes of things they thought are wrong, things that they do not understand or just things that they do not like. If you make 3 presentations per day on the other days of the week, and you make the changes that were told you to by your audience, you will find yourself with a better presentation and with more confidence in your presentation. In this phase, training is really important for you to memorize what you will say, and to create mechanisms to present better - you will do that almost automatically with more training.</p>

<p>In the end, you will notice that the training is of no use anymore: you always say the same things, take more or less the same time and there not many critiques to improve your presentation. That’s when you know you are ready to present with confidence, with no anxiety whatsoever. You have rehearsed so many times that you just need to present one more and say the same things you did in the presentations before.</p>

<p>If you want, you can write down the questions that you are expecting to hear from the jury. In my case, none of them was asked, but it gave me more confidence in the presentation.</p>

<h2 id="14---you-are-the-master-of-your-own-work">14 - You are the master of your own work!</h2>

<blockquote>
  <p>I have written 11 books but each time I think ‘Uh-oh, they’re going to find out now. I’ve run a game on everybody, and they’re going to find me out.’</p>
</blockquote>

<p>—Maya Angelou</p>

<p>Impostor syndrome. Do you know what it is? It’s that feeling you get when you think that you are not worthy of what you achieved - someone was wrong in choosing you, you are clearly not good enough, and all your success was just a lucky sequence of events. Don’t worry: 70% of people feel this way, according to a study in the International Journal of Behavioral Science.</p>

<p>In that study, it is said that those with imposter syndrome tend to be perfectionists and to spend more time in their work just to make things perfect. Congratulations: if you have the imposter syndrome, you’re probably doing a good job. But it can be hard to deal with imposter syndrome in long-term projects. The motivation starts to decrease and you start questioning yourself and your work. If you’re not confident in your work in the presentation, the jury will notice and it will start to make more technical questions and it will doubt your answers. How do you become confident in your work?</p>

<h3 id="my-experience-2">My Experience</h3>
<p>Thankfully, my supervisor has always reminded me of how good my dissertation was. Because she knew me well, she knew that I would not relax if she said that, it would only give me more motivation to keep working. When I was not motivated (it happened 3 or 4 times), I called a meeting with her and I would explain to her why that was happening. The work was re-scheduled and adapted until I was comfortable and motivated for what I had to do.</p>

<h3 id="my-advice-2">My Advice</h3>
<p>Just like I said in the previous tip, it gives you more confidence to take notes of the downsides of your work, to think about adequate responses if it comes up in the presentation. Even if they do not come up, it gives you more confidence in your work.</p>

<p>No one in the world knows more about your work than yourself. You have been working at least for a year in your dissertation/thesis: no one knows more about the cahracteristics, the difficulties, the pros and the cons of your work. Remember: your goal is not to make the perfect dissertation/thesis. In fact, no dissertation is perfect: there are great dissertations that completely fail their main objective. The most important are the conclusions: if you did all over again, would you change anything? Say it in the conclusions and in the future work. Remember what Einstein said,</p>

<blockquote>
  <p>Failure is success in progress.</p>
</blockquote>

<p>If you totally fail, say why to help someone not to fail. Or to fail better.</p>

<p>Explain what you have failed in your presentation. Be clear and don’t come with excuses. The jury knows when the students are honest.</p>

<h2 id="15---write-a-paper">15 - Write a paper!</h2>

<div style="width:100%;height:0;padding-bottom:56%;position:relative;"><iframe src="https://giphy.com/embed/XIqCQx02E1U9W" width="100%" height="100%" style="position:absolute" frameborder="0" class="giphy-embed" allowfullscreen=""></iframe></div>
<p><a href="https://giphy.com/gifs/XIqCQx02E1U9W"></a></p>

<p>You are at the end of this dissertation (or you have already presented your work) and your supervisor wants you to write a paper (or more) about it. He/she says that your contribution with your dissertation/thesis can help others in the field - and it can also help you to have a higher grade. You get excited, but at the same time writing a paper also means more work. If you are finishing your masters, you probably have never written a paper, and you don’t know where to start. What should you do?</p>

<h3 id="my-experience-3">My Experience</h3>
<p>Months before the dissertation presentation, I submitted a paper to an international conference. The result came back in the day before the dissertation presentation: it was rejected. My supervisors came to me saying that it just needed a few tweaks to be accepted in another conference, that I had nothing to worry about. I relaxed and, as I said before, the dissertation presentation went really well. After the dissertation presentation, besides the rejected article being reviewed to be submitted, I made another conference paper and a journal paper, about different topics approached in the dissertation. I still don’t know if any of them will be accepted, but I know that with the rejection of the first paper, I learned a lot about writing papers and the probability of the other papers being accepted is much higher.</p>

<h3 id="my-advice-3">My Advice</h3>
<p>If you are in doubt about writing a paper, my advice is to go for it. Share your work with others. By my experience, students regularly underestimate the potential of their projects: try to submit a paper and then wait for the feedback. If the feedback is negative (the paper was rejected), don’t worry. Rejections happen. Use it to improve your work with world-class specialists in your topic, even if some reviews seem totally wrong. If that happens, maybe it’s because the supervisors did not understand your work, and you should explain it better.</p>

<p>Writing a paper is different from the work you have done up to this point. You have to use your summarization capabilities for the reader to be able to understand what you did in your work. Writing your first paper can be confusing, due to lack of practice, and very boring, due to the number of hours you will be reviewing it and changing it, with the feedback from your supervisors. Just as in the dissertation/thesis, you have to discuss critically the consequences of your work. Even the cons of your work should be discussed. But do not fear: when the paper is accepted, you know that it was all worth it.</p>

<p>That’s it for our series!</p>

<p>Thanks for sticking by until the end.</p>

<p>See ya on other posts!</p>]]></content><author><name></name></author><category term="thesis" /><category term="dissertation" /><category term="tips" /><summary type="html"><![CDATA[15 tips for your thesis/dissertation - 4/4]]></summary></entry></feed>