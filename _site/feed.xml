<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xml" href="http://localhost:4000/feed.xslt.xml"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="http://jekyllrb.com" version="3.6.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-11-03T00:10:22+00:00</updated><id>http://localhost:4000/</id><title type="html">Diogo Ferreira webpage</title><subtitle>Diogo Ferreira personal webpage.</subtitle><entry><title type="html">Maximize the potential of your football players with Machine Learning</title><link href="http://localhost:4000/maximize-the-potential-of-your-football/" rel="alternate" type="text/html" title="Maximize the potential of your football players with Machine Learning" /><published>2020-08-27T00:00:00+01:00</published><updated>2020-08-27T00:00:00+01:00</updated><id>http://localhost:4000/maximize-the-potential-of-your-football</id><content type="html" xml:base="http://localhost:4000/maximize-the-potential-of-your-football/">&lt;figure&gt;
    &lt;a href=&quot;/assets/img/football-players/capa.jpeg&quot;&gt;&lt;img src=&quot;/assets/img/football-players/capa.jpeg&quot; style=&quot;max-width: 80%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;Photo by &lt;a href=&quot;https://unsplash.com/@jasonrc23&quot; target=&quot;_blank&quot;&gt;jason charters&lt;/a&gt; on Unsplash&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Hi there! When you are watching your favorite football team, have you ever got that feeling that there is a player that has great potential, but is playing in the wrong position? Do you think that if the manager would put him in a different position he would be so much better? Well, I do! How can we develop a tool that uses &lt;strong&gt;artificial intelligence to help us detect the best-suited positions for players?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In this post I will show how to train a machine learning model to detect the best positions of a player, using a Football Manager dataset. Then, I will analyze some players and compare the predicted positions with the real positions of the players. You can check the Jupyter notebook with the code for this blog post &lt;a href=&quot;https://colab.research.google.com/github/diogodanielsoaresferreira/football_machine_learning/blob/master/Predict%20players%20positions.ipynb&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Several players changed their position successfully in their careers. &lt;strong&gt;Andrea Pirlo&lt;/strong&gt; is perhaps one of the most successful cases. He started as an offensive midfielder but failed to impress in Inter Milan in 2001, due to his lack of pace and stamina. During a loan in Brescia, which also had Roberto Baggio as a trequartista, the coach Carlo Mazzone made the impressive decision to deploy Pirlo as a deep-lying playmaker. Due to his technique and passing ability, Pirlo became perhaps the best deep-lying playmaker of all time, inspiring a new generation of defensive midfielders.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/assets/img/football-players/pirlo.jpg&quot;&gt;&lt;img src=&quot;/assets/img/football-players/pirlo.jpg&quot; style=&quot;max-width: 80%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;Andrea Pirlo (Wikipedia)&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Another well-known case of switching positions is &lt;strong&gt;Bale&lt;/strong&gt;. When he changed from Southampton to Tottenham, he became one of the fastest left-backs that the world has ever seen. However, by the hand of Harry Redknapp in 2012, he turned into a left-winger, making him the most expensive player in the world when he was bought by Real Madrid in 2013.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/assets/img/football-players/bale.jpg&quot;&gt;&lt;img src=&quot;/assets/img/football-players/bale.jpg&quot; style=&quot;max-width: 80%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;Gareth Bale (Wikipedia)&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;While in those cases the players moved positions while still young, there are also cases when the players change positions to take advantage of their new characteristics as they get old. For many years, &lt;strong&gt;Ryan Giggs&lt;/strong&gt; was the left-winger of Man United. In the later years of his career, his pace decreased, while at the same time his passing skills were better than ever. His change to the central midfield benefited both him and Man United, leading them to the Champions League final in 2009 and 2011.&lt;/p&gt;

&lt;p&gt;There are many more players that changed positions successfully: Javier Mascherano, Sergio Ramos, Thierry Henry, Fábio Coentrão, Matic, or Vincent Kompany are some of the examples. The goal of this post is to show how to create a model that predicts the best positions of a player, to allow him to reach his potential earlier in his career.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;To do that, we will use a dataset with player attributes, valued from 1 to 20. We will use &lt;strong&gt;data from the game Football Manager 2017&lt;/strong&gt;, available in &lt;a href=&quot;https://www.kaggle.com/ajinkyablaze/football-manager-data&quot;&gt;Kaggle&lt;/a&gt;. Football Manager is widely known as having one of the most reliable and extensive worldwide football players datasets.&lt;/p&gt;

&lt;p&gt;We will train a machine learning model that learns to classify the players’ positions based on their attributes. Each player can be classified as having more than one suited position for him to play.&lt;/p&gt;

&lt;p&gt;A &lt;strong&gt;disclaimer&lt;/strong&gt; about the data must be made. The dataset is obviously biased, since the players’ attributes were hand given, and they were given knowing the position of the player a priori. However, it was my choice to made this analysis based on the attributes given to the players and not based on the player stats (number of passes, number of goals, etc.), since they are affected by the positions in which the players have played in.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Enough talking! Let’s &lt;strong&gt;train the model&lt;/strong&gt;. The full notebook can be found &lt;a href=&quot;https://colab.research.google.com/github/diogodanielsoaresferreira/football_machine_learning/blob/master/Predict%20players%20positions.ipynb&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;When defining the position for each player, we can see that each player has a score for each position, from 1 to 20. We will classify a player as well suited for a position if its score for that position is 15 or more.&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/diogodanielsoaresferreira/17160fcecaa26063656d9322d82e79bc.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;We will train three models: a &lt;strong&gt;K-neighbors classifier, a Random Forest, and a neural network&lt;/strong&gt;. I chose those three algorithms because they have native support for multilabel classification. For each model, it will be applied 5-fold cross-validation, and the F1-score will be measured. The predictions for every player will also be stored.&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/diogodanielsoaresferreira/c91245d139191b01221a11d1d3d196f9.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;The results of the cross-validation have shown us that the neural network is the worst performer in this task, achieving an F1-score of 48.61%. Both the K-neighbors and the Random Forest algorithms achieve an F1-score near 60%. Because the training time of the Random Forest is lower, I chose the Random Forest model to make predictions about the players. After the hyper-parameters are chosen, I train the model one last time with the entire dataset.&lt;/p&gt;

&lt;p&gt;In the end, we get two artifacts that we will use:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;the trained model&lt;/strong&gt; with all the players in the dataset;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;the prediction of the position of each player&lt;/strong&gt;, trained in a 5-fold cross-validation approach.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;After having the model trained, &lt;strong&gt;let’s play with it!&lt;/strong&gt; We can manually set each player’s attribute to a numeric value, and analyze the output of the model. With that, we can inspect the most important attributes for each position.&lt;/p&gt;

&lt;p&gt;For example, starting with the attributes of &lt;strong&gt;Cristiano Ronaldo&lt;/strong&gt;, it predicts the positions of Striker, Left Attacking Midfielder, Right Attacking Midfielder, and Left Midfielder. Let’s try to reduce the finishing attribute value, that is set to 19. Interestingly enough, when the finishing attribute drops below 10, the model only predicts the positions Left and Right Attacking Midfielder. The Striker and Left Midfielder positions are not predicted due to the low finishing skils. We can also see that changing only the age, height or weight does not affect directly the predicted positions.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/assets/img/football-players/screen.png&quot;&gt;&lt;img src=&quot;/assets/img/football-players/screen.png&quot; style=&quot;max-width: 100%&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;If the Freekicks attribute drops below 4, the Left Midfield position is not predicted. Maybe the model learned that left midfielders are good at free-kicks. If the heading attribute drops, not only the Striker and the Left Midfield positions are not predicted, but the attacking central midfielder position is predicted. It makes sense since the heading attribute is rarely needed for an attacking central midfielder.&lt;/p&gt;

&lt;p&gt;Anyway, there is a lot to try and explore with the attributes in the model. &lt;strong&gt;Try it yourself with your favorite players!&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Besides the model, &lt;strong&gt;we also have the predicted position of each player&lt;/strong&gt;. We can inspect the player positions that the model predicted and see if it discovered potential positions where the players could achieve its full potential.&lt;/p&gt;

&lt;p&gt;Let’s test with 10 players:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/diogodanielsoaresferreira/068133039f46808c4f66afa6c32b827e.js&quot;&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Cristiano Ronaldo&lt;/strong&gt; - the predicted positions are in the central area of the field, which makes sense in this latter part of his career;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Lionel Messi&lt;/strong&gt; - the predicted positions are central and left attacking midfielder, which does not contain the striker position when compared to the actual positions; it is also understandable, since Messi is everything but a regular striker - its heading or finishing skills are not outstanding;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Neymar&lt;/strong&gt; - similar to Messi, all the real positions are predicted with exception to the striker position, probably for the same reasons; I would argue that striker is not the best position for any of them, at least as a lone striker;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Kevin De Bruyne&lt;/strong&gt; - the actual best positions of De Bruyne in FM 2017 are all midfield and attacking midfield positions; our predicted best positions are central attacking midfield and left attacking midfield;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Harry Kane&lt;/strong&gt; - both the actual and the predicted positions are the same (striker);&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Luka Modric&lt;/strong&gt; - both the actual and the predicted positions are the same (central attacking midfield and central midfield);&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Manuel Neuer&lt;/strong&gt; - both the actual and the predicted positions are the same (Goalkeeper);&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Phillip Lahm&lt;/strong&gt; - Lahm is a challenging player because it can play in several positions; our predicted position is right defender, which is its original position;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Andrea Pirlo&lt;/strong&gt; - Pirlo is another challenging example, having started its career as a central attacking midfielder but having more success as a defensive midfielder; our prediction is central midfield and central attacking midfield, probably due to his remarkable vision and passing attributes;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Gareth Bale&lt;/strong&gt; - the predicted positions for Bale are central and left attacking midfield, which was the position that made him the most expensive player in the world in 2013.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In recap, &lt;strong&gt;it seems that the model can accurately predict the area of the field of a player (goalkeeping/defense/midfield/striker), and it can give some insights to the players of where it can be its best position.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Try it with your favorite players!&lt;/p&gt;

&lt;p&gt;Thanks for reading!&lt;/p&gt;</content><category term="football" /><category term="machine learning" /><summary type="html">Learn to create a model that calculates the best position of your players</summary></entry><entry><title type="html">From Word Embeddings to Sentence Embeddings - Part 3/3</title><link href="http://localhost:4000/sentence-embeddings-part-3/" rel="alternate" type="text/html" title="From Word Embeddings to Sentence Embeddings - Part 3/3" /><published>2020-03-30T00:00:00+01:00</published><updated>2020-03-30T00:00:00+01:00</updated><id>http://localhost:4000/sentence-embeddings-part-3</id><content type="html" xml:base="http://localhost:4000/sentence-embeddings-part-3/">&lt;figure&gt;
    &lt;a href=&quot;/assets/img/sentence-embeddings-part-3/header.jpg&quot;&gt;&lt;img src=&quot;/assets/img/sentence-embeddings-part-3/header.jpg&quot; style=&quot;max-width: 100%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;Designed by &lt;a href=&quot;https://br.freepik.com/fotos-gratis/letras-formando-as-palavras-progresso-crescimento-e-sucesso_1330222.htm&quot; target=&quot;_blank&quot;&gt;Freepik&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Hi there! This post is the last one in a three-part series about &lt;strong&gt;Sentence Embeddings&lt;/strong&gt;. If you didn’t read part 1 or part 2, you can find them &lt;a href=&quot;/sentence-embeddings-part-1/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;/sentence-embeddings-part-2/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In this post, I will explain the State-Of-The-Art (SOTA) approach to create Sentence Embeddings.&lt;/p&gt;

&lt;h1 id=&quot;sentence-bert&quot;&gt;Sentence-Bert&lt;/h1&gt;
&lt;p&gt;Sentence-Bert is currently (April, 2020) the &lt;strong&gt;SOTA algorithm to create Sentence Embeddings&lt;/strong&gt;. It was presented in 2019 by Nils Reimers and Iryna Gurevych [1], and it takes advantage of the BERT model to create even better Sentence Embeddings, taking into account long-term dependencies in the text and the context from many previous timesteps.&lt;/p&gt;

&lt;p&gt;To understand the Sentence-BERT architeture, a &lt;strong&gt;few concepts must be explained&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;attention-mechanism&quot;&gt;Attention mechanism&lt;/h2&gt;

&lt;p&gt;As said in &lt;a href=&quot;/sentence-embeddings-part-2/&quot;&gt;part 2&lt;/a&gt;, the LSTMs have a hidden vector that represents the memory at a current state of the input. However, for long inputs, such as long sentences, a vector does not give all the needed information to predict the next state correctly. The &lt;strong&gt;LSTM can make mistakes because, in practice, it only has information from a limited number of steps back, due to the bottleneck of the size of the hidden vector that represents the state&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;To solve that, the Attention mechanism ([3], [4]) was introduced in 2014. Instead of a single vector, &lt;strong&gt;the model has access to all the previous hidden states before deciding what to predict&lt;/strong&gt; (a better explanation can be found in [4]). Attention helped with the long-term dependencies problem.&lt;/p&gt;

&lt;h2 id=&quot;transformer&quot;&gt;Transformer&lt;/h2&gt;

&lt;p&gt;Another problem of LSTMs is the &lt;strong&gt;time to train&lt;/strong&gt;. Because the output always depends on the previous input, the training is done sequentially, taking too much time. The Transformer architecture, presented by Google Brain and University of Toronto in 2017 [5], &lt;strong&gt;showed how to use the attention mechanism in a neural architecture that could be parallelized, taking less time to train and achieving better results&lt;/strong&gt; in Machine Translation tasks.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/assets/img/sentence-embeddings-part-3/transformer.png&quot;&gt;&lt;img src=&quot;/assets/img/sentence-embeddings-part-3/transformer.png&quot; style=&quot;max-width: 100%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;Figure 1 - Transformer architecture. (Source: [5])&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Figure 1 shows the complete architecture of the Transformer. A detailed explanation can be found in [6]. The architecture is composed of two parts: an encoder and a decoder. &lt;strong&gt;The encoder encodes the representation of the input, while the decoder tries to output a probability&lt;/strong&gt; based on the encoder representation and the previous outputs. The encoder and decoder basic building blocks are feed-forward layers and self-attention layers. Self-attention layers look at the entire input and try to pay attention to the most important parts, instead of relying on a single hidden state representation.&lt;/p&gt;

&lt;p&gt;The results of the transformer architecture applied to sentence translation resulted in a big improvement over the previous State-Of-The-Art model. The transformer revolutionized the NLP field, because now it was possible to train large datasets in a reasonable time with a model less vulnerable to long-term dependencies problems. However, why should we stick to using just one transformer? &lt;strong&gt;What happens if we stack many transformers and train them a little bit differently to obtain better performance?&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;bert&quot;&gt;BERT&lt;/h2&gt;

&lt;p&gt;BERT was presented in mid-2019 by the Google AI language team [7] and fulfilled the promises of using the Transformers to create a general language understanding model much better than all its predecessors, taking a huge step forward in NLP development. When it was presented, it achieved SOTA results in tasks such as question answering or language inference with minor modifications in its architecture.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/assets/img/sentence-embeddings-part-3/bert.png&quot;&gt;&lt;img src=&quot;/assets/img/sentence-embeddings-part-3/bert.png&quot; style=&quot;max-width: 100%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;Figure 2 - BERT Architecture for pre-training and fine-tuning. (Source: [7])&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Figure 2 shows the BERT architecture. It is mainly composed of a &lt;strong&gt;multi-layer bidirectional Transformer encoder&lt;/strong&gt; (the large model is composed of 24 layers of Transformer blocks), where the inputs are the Embeddings of each token in the input.&lt;/p&gt;

&lt;p&gt;An important aspect of this architecture is the &lt;strong&gt;bidirectionality, that enables BERT to learn forward and backward dependencies&lt;/strong&gt;. That is achieved by pre-training BERT with two different objective tasks:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Masked Language Model&lt;/strong&gt;, also described as Cloze Task, enables BERT to learn bidirectional dependencies. Instead of predicting the next word in a sentence, it masks some percentage of the input tokens at random and predicts those masked tokens. This forces the model to learn not only forward, but also backward dependencies between tokens.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Next Sentence Prediction&lt;/strong&gt; feeds the model two sentences and predicts if the sentences are next to each other. This task forces the model to learn the relationship between two sentences, which is not directly captured by language modeling.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After obtaining the pre-trained model with unsupervised data, the fine-tuning part can be adapted to different NLP tasks, just by changing the input and the output of the model. An interesting conclusion from the paper is that &lt;strong&gt;the higher the number of Transformer Layers, the better the results for the downstream tasks&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;sentence-bert-approach&quot;&gt;Sentence-BERT approach&lt;/h2&gt;
&lt;p&gt;Finally, we reach to Sentence-BERT approach.&lt;/p&gt;

&lt;p&gt;To calculate the similarity between two sentences using BERT, it is needed to feed into the network both sentences. Due to BERT complexity, calculating the similarity with 10000 sentences requires approximately 65 hours of computations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sentence-BERT is an approach to create semantic meaningful Sentence Embeddings that can be compared with cosine-similarity, maintaining BERT accuracy but reducing the effort for finding the most similar pair from 65 hours to 5 seconds&lt;/strong&gt;.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/assets/img/sentence-embeddings-part-3/sentence-bert.png&quot;&gt;&lt;img src=&quot;/assets/img/sentence-embeddings-part-3/sentence-bert.png&quot; style=&quot;max-width: 100%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;Figure 3 - Sentence-BERT training architecture. (Source:[1])&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Sentence-BERT architecture is depicted in Figure 3. The training goal (the same used for InferSent) is to classify pairs of sentences according to their similarity: entailment (sentences are related), contradictory (sentences are contradictory) or neutral (sentences are not related). A pair of sentences are fed to BERT, followed by a pooling layer (it can be max pooling, mean pooling or use the CLS token in BERT output), that will generate an embedding for each sentence. Both embeddings are concatenated with their difference and are fed to a 3-way softmax layer. This training schema is often called a Siamese Network [8].&lt;/p&gt;

&lt;p&gt;By fine-tuning BERT weights with this architecture, the &lt;strong&gt;embeddings generated are suitable for sentence similarity&lt;/strong&gt;, by sending a sentence through Bert and applying a pooling operation.&lt;/p&gt;

&lt;h1 id=&quot;comparing-the-algorithms&quot;&gt;Comparing the algorithms&lt;/h1&gt;
&lt;p&gt;Now that we have seen four algorithms for creating sentence representations (check the previous algorithm &lt;a href=&quot;/sentence-embeddings-part-1/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;/sentence-embeddings-part-2/&quot;&gt;here&lt;/a&gt;), let’s test them and see the results. This &lt;a href=&quot;https://github.com/diogodanielsoaresferreira/document_representations_tests/blob/master/Sentence%20Similarity.ipynb&quot;&gt;Jupyter notebook&lt;/a&gt; contains a test with the four approaches.&lt;/p&gt;

&lt;p&gt;Given a news dataset, creates representations of the description of the news with the four approaches. Given a query inserted by the user, it will generate a representation of that query and it will compare it with all the news representations. That comparison is done using the Cosine Similarity. The top five most similar news descriptions are printed to the notebook. Let’s analyse some results.&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/diogodanielsoaresferreira/c8228df45d8516fb1bbb727b38c6a223.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;The query was “Democrats win republicans in election.” All approaches produce good results, but it seems that &lt;strong&gt;InferSent and Sentence-Bert have better matches&lt;/strong&gt;. Let’s see another result.&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/diogodanielsoaresferreira/e45bbac61a57ca92d3bef89bdb306e1c.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;This query is particularly difficult for the first three approaches. &lt;strong&gt;Only Sentence-Bert seems to have produced correct results&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;You can see more interesting results in the notebook &lt;a href=&quot;https://github.com/diogodanielsoaresferreira/document_representations_tests/blob/master/Sentence%20Similarity.ipynb&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;There are other algorithms for producing sentence representations that we tested but they were not explored in this post. If you want to know more I suggest you take a look at &lt;strong&gt;Universal Sentence Encoder [9], Skip-thought [10] or FastSent [11]&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In summary, there are various algorithms to create sentence representations. Besides its performance, it’s also important to take into account their speed and memory requirements.&lt;/p&gt;

&lt;p&gt;Sentence embeddings are an open area of research with big advances in the last few years, and they are in growing demand by industry applications, such as Chat Bots and Search Engines. It is important to keep up the pace with the latest developments in the area of research.&lt;/p&gt;

&lt;p&gt;Thanks for sticking by until the last part of this series about Sentence Embeddings!&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;[1]: Nils Reimers and Iryna Gurevych: “Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks”, 2019; &lt;a href=&quot;https://arxiv.org/abs/1908.10084&quot;&gt;arXiv:1908.10084&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;[2]: Dzmitry Bahdanau, Kyunghyun Cho and Yoshua Bengio: “Neural Machine Translation by Jointly Learning to Align and Translate”, 2014; &lt;a href=&quot;https://arxiv.org/abs/1409.0473&quot;&gt;arXiv:1409.0473&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;[3]: Minh-Thang Luong, Hieu Pham and Christopher D. Manning: “Effective Approaches to Attention-based Neural Machine Translation”, 2015; &lt;a href=&quot;https://arxiv.org/abs/1508.04025&quot;&gt;arXiv:1508.04025&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;[4] - Jay Alammar, &lt;a href=&quot;https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/&quot;&gt;Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;[5] - Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez andLukasz Kaiser: “Attention Is All You Need”, 2017; &lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;&gt;arXiv:1706.03762&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;[6] - Jay Alammar, &lt;a href=&quot;http://jalammar.github.io/illustrated-transformer/&quot;&gt;The Illustrated Transformer&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;[7] - Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova: “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding”, 2018; &lt;a href=&quot;https://arxiv.org/abs/1810.04805&quot;&gt;arXiv:1810.04805&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;[8] - Jane Bromley, Isabelle Guyon, Yann LeCun, Eduard Sackinger and Roopak Shah: “&lt;a href=&quot;https://papers.nips.cc/paper/769-signature-verification-using-a-siamese-time-delay-neural-network.pdf&quot;&gt;Signature Verification using a Siamese Time Dealy Neural Network&lt;/a&gt;”, 1994.&lt;/li&gt;
  &lt;li&gt;[9] - Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St. John, Noah Constant, Mario Guajardo-Cespedes, Steve Yuan, Chris Tar, Yun-Hsuan Sung, Brian Strope and Rey Kurzweil: “Universal Sentence Encoder”, 2018; &lt;a href=&quot;https://arxiv.org/abs/1803.11175&quot;&gt;arXiv:1803.11175&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;[10] - Ryan Kiros, Yukun Zhu, Ruslan Salakhutdinov, Richard S. Zemel, Antonio Torralba, Raquel Urtasun and Sanja Fidler: “Skip-Thought Vectors”, 2015; &lt;a href=&quot;https://arxiv.org/abs/1506.06726&quot;&gt;arXiv:1506.06726&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;[11] - Felix Hill, Kyunghyun Cho and Anna Korhonen: “Learning Distributed Representations of Sentences from Unlabelled Data”, 2016; &lt;a href=&quot;https://arxiv.org/abs/1602.03483&quot;&gt;arXiv:1602.03483&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;</content><category term="sentence embeddings" /><category term="data science" /><category term="NLP" /><category term="BERT" /><category term="Transformers" /><category term="Attention" /><category term="Sentence-BERT" /><summary type="html">Explanation of Sentence-BERT approach to obtain Sentence Embeddings</summary></entry><entry><title type="html">From Word Embeddings to Sentence Embeddings - Part 2/3</title><link href="http://localhost:4000/sentence-embeddings-part-2/" rel="alternate" type="text/html" title="From Word Embeddings to Sentence Embeddings - Part 2/3" /><published>2020-03-30T00:00:00+01:00</published><updated>2020-03-30T00:00:00+01:00</updated><id>http://localhost:4000/sentence-embeddings-part-2</id><content type="html" xml:base="http://localhost:4000/sentence-embeddings-part-2/">&lt;figure&gt;
    &lt;a href=&quot;/assets/img/sentence-embeddings-part-2/header.jpg&quot;&gt;&lt;img src=&quot;/assets/img/sentence-embeddings-part-2/header.jpg&quot; style=&quot;max-width: 100%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;Designed by &lt;a href=&quot;https://br.freepik.com/fotos-gratis/letras-formando-a-palavra-pratica_1330193.htm&quot; target=&quot;_blank&quot;&gt;Freepik&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Hi there! This post is the second in a three-part series about &lt;strong&gt;Sentence Embeddings&lt;/strong&gt;. If you didn’t read part 1, you can find it &lt;a href=&quot;/sentence-embeddings-part-1/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In this post, I will explain two approaches to create Sentence Embeddings: Doc2vec and InferSent.&lt;/p&gt;

&lt;p&gt;To improve the sentence representations from the &lt;a href=&quot;/sentence-embeddings-part-1/&quot;&gt;TF-IDF representations&lt;/a&gt;, we must take into account the semantics of each word and the word order. Sentence embeddings try to encode all of that.&lt;/p&gt;

&lt;p&gt;Sentence embeddings are similar to word embeddings. Each embedding is a low-dimensional vector that represents a sentence in a dense format. There are different algorithms to create Sentence Embeddings, with the same goal of creating similar embeddings for similar sentences.&lt;/p&gt;

&lt;h1 id=&quot;doc2vec&quot;&gt;Doc2vec&lt;/h1&gt;

&lt;p&gt;The &lt;strong&gt;Doc2vec&lt;/strong&gt; algorithm (or Paragraph Vector) was proposed in 2014 by Quoc Le and Tomas Mikolov [1], both Research Scientists at Google at the time. It is based on the Word2vec algorithm, which creates embeddings of words. The algorithm follows the assumption that a word’s meaning is given by the words that appear close-by.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;You shall know a word by the company it keeps (J. R. Firth 1957)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The authors present two variations of the algorithm: the &lt;strong&gt;Distributed Memory model (DM)&lt;/strong&gt; and the &lt;strong&gt;Distributed Bag-Of-Words (DBOW)&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;distributed-memory-model&quot;&gt;Distributed Memory Model&lt;/h2&gt;

&lt;figure&gt;
    &lt;a href=&quot;/assets/img/sentence-embeddings-part-2/dmm.png&quot;&gt;&lt;img src=&quot;/assets/img/sentence-embeddings-part-2/dmm.png&quot; style=&quot;max-width: 100%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;Figure 1 - Neural Network architecture of the DM model. (Source: [1])&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In Figure 1, a Neural Network architecture for the DM model is depicted. Let’s start by analyzing the training stage, and then we will see how the model creates an embedding for a sentence.&lt;/p&gt;

&lt;p&gt;Each sentence and each word in the training corpus are converted to a one-hot representation. Both will have an embedding, stored in the matrices D and W, respectively. The training is done by passing a sliding window over the sentence, trying to predict the next word based on the previous words in the context and the sentence vector (or Paragraph Matrix in the figure). The classification of the next word is done by passing the concatenation of the sentence and word vectors into a softmax layer. The word vectors are the same for different sentences, while the sentence vectors are different. Both are updated at each step of the training phase.&lt;/p&gt;

&lt;p&gt;The prediction phase is also done by passing a sliding window over the sentence, trying to predict the next word given the previous words. All the weights of the model are fixed, with exception to the weights of the sentence vector, that are updated for every step. After all the predictions of the next word are computed for a sentence, the sentence embedding is the resultant sentence vector.&lt;/p&gt;

&lt;h2 id=&quot;distributed-bag-of-words-model&quot;&gt;Distributed Bag-Of-Words Model&lt;/h2&gt;

&lt;figure&gt;
    &lt;a href=&quot;/assets/img/sentence-embeddings-part-2/dbow.png&quot;&gt;&lt;img src=&quot;/assets/img/sentence-embeddings-part-2/dbow.png&quot; style=&quot;max-width: 100%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;Figure 2 - Neural Network architecture of the DBOW model. (Source: [1])&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Figure 2 shows the Neural Network architecture for the DBOW model. This model ignores the word order and has a simpler architecture, with fewer weights to be learned.&lt;/p&gt;

&lt;p&gt;Each sentence in the training corpus is also converted into a one-hot representation. The training is done by, on each iteration, selecting a random sentence from the corpus and, from that sentence, selecting a random number of words. The model will try to predict those words based only on the sentence ID, and the sentence vector will be updated (in the Figure, Paragraph ID and Paragraph Matrix, respectively).&lt;/p&gt;

&lt;p&gt;In the prediction phase, a new sentence ID is trained with random word samples from the sentence, but the softmax layer has its weights fixed. The sentence vector is updated in each step and the resulting sentence vector is the embedding for that sentence.&lt;/p&gt;

&lt;h2 id=&quot;comparison&quot;&gt;Comparison&lt;/h2&gt;

&lt;p&gt;Comparing both methods, the &lt;strong&gt;DM model has some technical advantages over the DBOW model&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;the DM model takes into account the word order, while the DBOW model doesn’t.&lt;/li&gt;
  &lt;li&gt;the DBOW model does not use word vectors, which means that the semantics of the words are not preserved and it’s harder to detect similarities between words.&lt;/li&gt;
  &lt;li&gt;due to the simpler architecture of the DBOW model, it takes many more steps to train to obtain accurate vectors.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The main drawback of the DM model is the time and the resources needed to generate an embedding, which are higher than with the DBOW model.&lt;/p&gt;

&lt;p&gt;What approach produces better Sentence Embeddings? In the original paper, the authors say that the DM is “consistently better than” DBOW. However, &lt;strong&gt;recent studies reported that the DBOW approach is better for most tasks&lt;/strong&gt; [2]. The implementation in Gensim of Doc2Vec [3] has the DBOW approach as the default algorithm, because it was found to have better results than the DM approach.&lt;/p&gt;

&lt;h1 id=&quot;infersent&quot;&gt;InferSent&lt;/h1&gt;

&lt;p&gt;InferSent is another Sentence Embedding method, presented by Facebook AI Research in 2018 [4], with an implementation and trained models available in Github [5].&lt;/p&gt;

&lt;p&gt;It has some differences from the previous algorithm in the training process: instead of unsupervised learning to train a Language Model (LM) (a model that predicts the next word), it &lt;strong&gt;uses supervised learning to perform Natural Language Inference (NLI)&lt;/strong&gt; (a model that predicts if an hypothesis, when compared to a premise, is true (entailment), false (contradiction) or undetermined (neutral)).&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/assets/img/sentence-embeddings-part-2/infersent.png&quot;&gt;&lt;img src=&quot;/assets/img/sentence-embeddings-part-2/infersent.png&quot; style=&quot;max-width: 100%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;Figure 3 - Generic architecture for training embeddings using NLI. (Source: [4])&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Figure 3 represents a generic training architecture for this approach. The &lt;em&gt;u&lt;/em&gt; and &lt;em&gt;v&lt;/em&gt; have shared weights, and are the Sentence Embeddings that we will obtain in the end.&lt;/p&gt;

&lt;p&gt;In the training phase, the Sentence Embeddings of the premise and the hypothesis are concatenated, along with its element-wise product and its element-wise difference. The resulting vector is fed into multiple fully-connected layers, that finish with a 3-class softmax (the classes are entailment, contradiction or neutral).&lt;/p&gt;

&lt;p&gt;What should be the architecture to create Sentence Embeddings? The authors tried different architectures, but here I will only describe the one that had the best results, that is the one implemented in InferSent: a &lt;strong&gt;BiLSTM with max pooling&lt;/strong&gt;.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/assets/img/sentence-embeddings-part-2/bilstm.png&quot;&gt;&lt;img src=&quot;/assets/img/sentence-embeddings-part-2/bilstm.png&quot; style=&quot;max-width: 100%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;Figure 4 - Bi-LSTM with max pooling architecture used in InferSent to generate embeddings. (Source: [4])&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Figure 4 describes the architecture of the Bi-LSTM with max pooling. I will not explain thoroughly what an LSTM (Long Short-Term Network) is in this post (there’s great blog post about that in [6]).&lt;/p&gt;

&lt;p&gt;In short, an LSTM is a neural network with the ability to remember previous inputs and use them in the computation of the next outputs (recurrent neural network). That is done by a hidden vector (&lt;em&gt;h&lt;/em&gt; in Figure 8) that represents the memory of the current state of the input. This architecture contains a Bi-directional LSTM network, which means that two LSTM networks are applied: one takes care of the previous inputs to predict the output of the next step (forward LSTM), the other LSTM is reversed: it looks at the inputs from the end to the beginning, and tries to predict in that order (backwards LSTM).&lt;/p&gt;

&lt;p&gt;The output vectors of both LSTM networks are then concatenated, and the final embedding is the maximum value over the dimension of the hidden units, as seen in Figure 4.&lt;/p&gt;

&lt;p&gt;At the cost using supervised data for training and a complex recurrent neural network (RNN) architecture, this approach creates great Sentence Embeddings.&lt;/p&gt;

&lt;p&gt;With the advent of the Transformers and BERT, another architecture became SOTA in 2019 - &lt;strong&gt;Sentence-BERT&lt;/strong&gt;. Read &lt;a href=&quot;/sentence-embeddings-part-3/&quot;&gt;part 3&lt;/a&gt; to know more about it!&lt;/p&gt;

&lt;p&gt;Thanks for sticking by!&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;[1]: Quoc Le and Tomas Mikolov: “Distributed Representations of Sentences and Documents”, 2014; &lt;a href=&quot;https://arxiv.org/abs/1405.4053&quot;&gt;arXiv:1405.4053&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;[2]: Jey Han Lau and Timothy Baldwin: “An Empirical Evaluation of doc2vec with Practical Insights into Document Embedding Generation”, 2016, Proceedings of the 1st Workshop on Representation Learning for NLP, Berlin, Germany, pp. 78–86; &lt;a href=&quot;https://arxiv.org/abs/1607.05368&quot;&gt;arXiv:1607.05368&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;[3]: Gensim - &lt;a href=&quot;https://radimrehurek.com/gensim/models/doc2vec.html&quot;&gt;Doc2vec paragraph embeddings&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;[4]: Alexis Conneau, Douwe Kiela, Holger Schwenk, Loic Barrault: “Supervised Learning of Universal Sentence Representations from Natural Language Inference Data”, 2017; &lt;a href=&quot;https://arxiv.org/abs/1705.02364&quot;&gt;arXiv:1705.02364&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;[5]: &lt;a href=&quot;https://github.com/facebookresearch/InferSent&quot;&gt;InferSent implementation&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;[6]: Christopher Olah, &lt;a href=&quot;https://colah.github.io/posts/2015-08-Understanding-LSTMs/&quot;&gt;Understanding LSTM Networks&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;</content><category term="sentence embeddings" /><category term="data science" /><category term="NLP" /><category term="Doc2vec" /><category term="InferSent" /><summary type="html">Explanation of Doc2Vec and InferSent approaches to obtain Sentence Embeddings</summary></entry><entry><title type="html">From Word Embeddings to Sentence Embeddings - Part 1/3</title><link href="http://localhost:4000/sentence-embeddings-part-1/" rel="alternate" type="text/html" title="From Word Embeddings to Sentence Embeddings - Part 1/3" /><published>2020-03-30T00:00:00+01:00</published><updated>2020-03-30T00:00:00+01:00</updated><id>http://localhost:4000/sentence-embeddings-part-1</id><content type="html" xml:base="http://localhost:4000/sentence-embeddings-part-1/">&lt;figure&gt;
    &lt;a href=&quot;/assets/img/sentence-embeddings-part-1/words_header.jpg&quot;&gt;&lt;img src=&quot;/assets/img/sentence-embeddings-part-1/words_header.jpg&quot; style=&quot;max-width: 100%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;Designed by &lt;a href=&quot;https://br.freepik.com/fotos-gratis/letras-diferentes_1330225.htm&quot; target=&quot;_blank&quot;&gt;Freepik&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Recently, I wrote two articles in Engineering Talkdesk Blog, about &lt;a href=&quot;https://engineering.talkdesk.com/what-are-word-embeddings-and-why-are-they-useful-a45f49edf7ab&quot;&gt;Word Embeddings&lt;/a&gt; and &lt;a href=&quot;https://medium.com/p/53ed370b3f35/&quot;&gt;Sentence Embeddings&lt;/a&gt;. In this series of three blog posts, I will explain in detail some of the approaches described to obtain Sentence Representations.&lt;/p&gt;

&lt;p&gt;In this first part, I will explain how to represent a word numerically and how to represent a sentence numerically using the TF-IDF algorithm.&lt;/p&gt;

&lt;h1 id=&quot;obtaining-word-representations&quot;&gt;Obtaining Word Representations&lt;/h1&gt;
&lt;p&gt;How do we represent a word?&lt;/p&gt;

&lt;p&gt;The simplest way to represent a word is with a &lt;strong&gt;one-hot encoded vector&lt;/strong&gt;. Let’s imagine we have a vector with the size of the vocabulary, where each entry corresponds to a word (Figure 1). In that way, the representation of each word is a vector of zeros, with ‘1’ in the position of the word. However, this representation has some disadvantages.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/assets/img/sentence-embeddings-part-1/one_hot_encoding.png&quot;&gt;&lt;img src=&quot;/assets/img/sentence-embeddings-part-1/one_hot_encoding.png&quot; style=&quot;max-width: 100%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;Figure 1 - One-hot encoded representation of the words &quot;Rome&quot;, &quot;Paris&quot;, &quot;Italy&quot; and &quot;France&quot; (Source: &lt;a href=&quot;https://speakerdeck.com/marcobonzanini/word-embeddings-for-natural-language-processing-in-python-at-london-python-meetup?slide=14&quot; target=&quot;_blank&quot;&gt;Marco Bonzanini, Word Embeddings for Natural Language Processing in Python @ London Python meetup&lt;/a&gt;)&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The representation of each word is &lt;strong&gt;very high-dimensional&lt;/strong&gt; (a vector with the size of the vocabulary) but sparse (only one entry has the value ‘1’).&lt;/p&gt;

&lt;p&gt;This does not provide much information about the word meaning, and it does not reveal any existing relationship between words. The representation of the word “Rome” is as close to the representation of the word “Paris” as any other word in the corpus, because their representations always differ in the same way. All other positions are the same with exception to the position of the word “Rome” and the position of the other word.&lt;/p&gt;

&lt;p&gt;Another representation currently used is &lt;strong&gt;Word Embeddings&lt;/strong&gt; (Figure 2). An embedding is a low-dimensional space that can represent a high-dimensional vector (such as the one-hot encoding of a word) in a compressed vector.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/assets/img/sentence-embeddings-part-1/word_embeddings.png&quot;&gt;&lt;img src=&quot;/assets/img/sentence-embeddings-part-1/word_embeddings.png&quot; style=&quot;max-width: 100%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;Figure 2- Word embeddings of the words &quot;Rome&quot;, &quot;Paris&quot;, &quot;Italy&quot; and &quot;France&quot;. We can see that the words &quot;Rome&quot; and &quot;Paris&quot; have similar embeddings, probably because they are both capital cities. (Source: &lt;a href=&quot;https://speakerdeck.com/marcobonzanini/word-embeddings-for-natural-language-processing-in-python-at-london-python-meetup?slide=22&quot; target=&quot;_blank&quot;&gt;Marco Bonzanini, Word Embeddings for Natural Language Processing in Python @ London Python meetup&lt;/a&gt;)&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Besides the higher density of those vectors, the &lt;strong&gt;advantage of the embeddings is the closeness between similar words&lt;/strong&gt;. That means that words such as “Rome” or “Paris” will probably have a similar embedding, different from the embedding of “Internet”, for example. That is very useful for many other Natural Language Processing (NLP) tasks, such as word clustering or topic analysis.&lt;/p&gt;

&lt;h1 id=&quot;obtaining-sentence-representations-with-tf-idf&quot;&gt;Obtaining Sentence Representations with TF-IDF&lt;/h1&gt;

&lt;p&gt;To represent sentences, it is impossible to create a one-hot encoding schema: there is an infinite number of sentences. We have to use other kinds of sentence representations.&lt;/p&gt;

&lt;p&gt;We are going to explain four different sentence representation algorithms in this blog series. For this post, let’s learn more about TF-IDF!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Tf%E2%80%93idf&quot;&gt;TF-IDF&lt;/a&gt;&lt;/strong&gt; (Term Frequency-Inverse Document Frequency) is a classical information retrieval method, commonly used by search engines, where the goal is to quickly search documents in a large corpus. Those documents can be sentences, dialogues or even long texts.&lt;/p&gt;

&lt;p&gt;TF-IDF creates a term-document matrix (Figure 3), where each term has associated all the documents where it appears, and a weight for each term-document entry. The weight of a term in a document increases with the number of times that the term appears in that particular document, and decreases with the frequency that the term appears in all documents. In that way, terms such as “a” or “the” in an English corpus will have lower weight because they appear in many documents.&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/diogodanielsoaresferreira/d50f98f79c76622eca45686d114399df.js&quot;&gt;&lt;/script&gt;

&lt;figcaption style=&quot;text-align: center&quot;&gt;Figure 3 - Example of the matrix created by TF-IDF, where the documents are dialogues.&lt;/figcaption&gt;

&lt;p&gt;A training corpus (set of documents) must be used to create the TF-IDF matrix. The dimensions of the matrix will be the number of different terms in the corpus by the number of documents in the corpus.&lt;/p&gt;

&lt;p&gt;The representation of a document is calculated by comparison with the documents in the training corpus.&lt;/p&gt;

&lt;p&gt;The document representation will be a row vector with the size of the number of documents in the corpus, where each entry &lt;em&gt;i&lt;/em&gt; will have a value that represents the similarity of the input document with the document &lt;em&gt;i&lt;/em&gt; in the corpus (Figure 4).&lt;/p&gt;

&lt;p&gt;That similarity is calculated based on the terms mentioned both in the input document and in each document in the corpus. A higher weight in the the entry &lt;em&gt;i&lt;/em&gt; of the document representation means that there is a higher similarity with the document &lt;em&gt;i&lt;/em&gt; in the corpus.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/assets/img/sentence-embeddings-part-1/TF_IDF.png&quot;&gt;&lt;img src=&quot;/assets/img/sentence-embeddings-part-1/TF_IDF.png&quot; style=&quot;max-width: 100%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;Figure 4 - Calculation of the representation of a document. Using the TF-IDF matrix of Figure 3, is calculated a representation of a document based on the similarity with the dialogues.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Document representations based on TF-IDF have some advantages:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;They can be calculated very fast, with a lookup on the TF-IDF matrix and a few simple calculations.&lt;/li&gt;
  &lt;li&gt;They are conceptually simple when compared with other algorithms.&lt;/li&gt;
  &lt;li&gt;Their implementation is transparent and the representation can be easily understood.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Their disadvantages are the following:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The similarity between documents does not take into account the position of each word in the document (also known as a bag-of-words model).&lt;/li&gt;
  &lt;li&gt;It does not capture the semantics of a document, which means that it does not take into account similar words.&lt;/li&gt;
  &lt;li&gt;It creates sparse vectors, which means that it is wasting a lot of memory with zero values.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And that’s it for the first post! Read &lt;a href=&quot;/sentence-embeddings-part-2/&quot;&gt;part 2&lt;/a&gt; to know more about more advanced approaches to create Sentence Embeddings.&lt;/p&gt;

&lt;p&gt;Thanks for sticking by!&lt;/p&gt;</content><category term="word embeddings" /><category term="sentence embeddings" /><category term="TF-IDF" /><category term="NLP" /><category term="data science" /><summary type="html">What are Sentence Embeddings and explanation of TF-IDF to generate Sentence Representations</summary></entry><entry><title type="html">What the hell is a Bloom Filter?</title><link href="http://localhost:4000/bloom-filter/" rel="alternate" type="text/html" title="What the hell is a Bloom Filter?" /><published>2019-12-07T00:00:00+00:00</published><updated>2019-12-07T00:00:00+00:00</updated><id>http://localhost:4000/bloom-filter</id><content type="html" xml:base="http://localhost:4000/bloom-filter/">&lt;p&gt;Hi there!&lt;/p&gt;

&lt;p&gt;In this post I will describe what is a Bloom Filter, its purpose and scenarios where it can be useful to use one. I will also implement a Bloom Filter from scratch in Python, for an easier understanding of its internals.&lt;/p&gt;

&lt;h2 id=&quot;goal-of-a-bloom-filter&quot;&gt;Goal of a Bloom Filter&lt;/h2&gt;

&lt;p&gt;A Bloom Filter is a data structure with the goal of checking if an element is &lt;strong&gt;NOT&lt;/strong&gt; in a set in a fast way (for those who know Big O notation, the complexity of inserting and checking if an element belongs to a set using a Bloom Filter is O(1)). It can be very useful to prevent a computation-intensive task to be done often, simply by verifying if the element is &lt;em&gt;definitely not&lt;/em&gt; in a set. It is important to understand that the Bloom Filter is a probabilistic data structure: it can tell you that an element is not in the dataset with 100% probability, but it cannot tell you that an element is in the set with 100% probability (false positives are possible). Let’s talk about scenarios where a Bloom Filter can be used, and later on you will understand why the Bloom Filter has these characteristics, with a detailed explanation of its internals and an implementation in Python!&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/assets/img/bloom_filter.png&quot;&gt;&lt;img src=&quot;/assets/img/bloom_filter.png&quot; style=&quot;max-width: 80%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;A bloom filter is usually used before a search in a set with slower access. The number of searches in the set can be reduced, so as the overall search time.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;scenarios&quot;&gt;Scenarios&lt;/h2&gt;

&lt;p&gt;Let’s think of some scenarios where such data structure can be useful to speed up the computation of some tasks. We can start by thinking in a router of a core network (those that you don’t have in your house :) ). It can be required for those routers to have an uplink speed of over 100 Gbit/s. The administrator can add a blacklist of IPs to block their access in the network. That means that everytime that the router receives a packet, at over 100 Gbit/s, it must look at his memory and perform, at best, a logarithmic search (O(log(n))) to check if the IP is blocked, knowing that most IPs are not blocked and that the search will not return any results for most packets. In this case, a Bloom Filter can be placed before the access to memory, to make sure that most packets do not need to wait the time of a search of an IP to be sent to the network.&lt;/p&gt;

&lt;p&gt;Another scenario is the database example. When a database has millions of accesses per second, and most of the accesses are searches by a key that is not in the database, it can be important to reduce the impact of the calls on the database, for two reasons: if the number of searches is reduced, the database engine will reply faster to other accesses; if it is possible for a client to not wait for a search on the database and have the result (e.g. not in memory) without needing to access the database, the achieved speedup can be significant.&lt;/p&gt;

&lt;p&gt;Finally, to speed up the search for a file in a folder with many files, the Bloom Filter can be used to check if the file is definitely not in the folder.&lt;/p&gt;

&lt;p&gt;More typical scenarios of usage of a Bloom Filter can be found &lt;a href=&quot;https://en.wikipedia.org/wiki/Bloom_filter#Examples&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;what-is-a-bloom-filter&quot;&gt;What is a bloom filter?&lt;/h2&gt;

&lt;p&gt;Let’s use the first scenario to exemplify the construction of a Bloom Filter. Imagine that you blacklist 100 IP’s. The easiest way to mark if an IP was blacklisted or not is to create a list with 100 bits, each bit is one IP. If an IP is blacklisted, we mark the position of the IP as ‘1’, otherwise is ‘0’.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/assets/img/empty_bloom_filter.png&quot;&gt;&lt;img src=&quot;/assets/img/empty_bloom_filter.png&quot; style=&quot;max-width: 30%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;In this Bloom Filter, the IP number 4 is blacklisted and all other IP's are not.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;how-many-ips-there-are&quot;&gt;How many IP’s there are?&lt;/h3&gt;
&lt;p&gt;This implementation works… if only 100 IP’s are used. In reality, each IPv4 address has 32 bits, which means that there are 4 294 967 296 (2&lt;sup&gt;32&lt;/sup&gt;) possible addresses (some of them are reserved for private networks, broadcast, multicast and other special networks, but it is still a huge number)! And the number of blacklisted IPs will probably not exceed the hundreds, at maximum. We cannot afford to construct a list so large to use only a reduced number of entries. We have to find a mapping between an IP and an entry of a list. And that’s where hash functions come in!&lt;/p&gt;

&lt;h3 id=&quot;hash-function&quot;&gt;Hash Function&lt;/h3&gt;

&lt;p&gt;A hash function is a function that transforms an input of arbitrary length into a fixed-size value. In that way, we can create an array with fixed size and calculate the output of a hash function given an IP, and it will always generate a number smaller or equal to the size of the array. The hash function is not random, which means that for the same input, the output will always be the same.&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/assets/img/hash_function.png&quot;&gt;&lt;img src=&quot;/assets/img/hash_function.png&quot; style=&quot;max-width: 80%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;A hash function receives an input that can be any string (in this case, an IP) and calculates a numerical representation. In this case, the numerical representation will be the position of the Bloom Filter corresponding to the input.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;But wait… Something is not right. Let’s go back to our scenario. Imagine that we blacklist 100 IP’s. How does the hash function maps our 100 IP’s from a possible 2&lt;sup&gt;32&lt;/sup&gt; IP’s to 100 different values without storing any information from them? The truth is that it doesn’t. There will be collisions. The hash function guarantees that each IP will have a unique mapping to a number, but since there can be 4 294 967 296 (2&lt;sup&gt;32&lt;/sup&gt;) possible IP’s, it’s impossible to map them all to 100 different values. All the hash function can guarantee is that it scrambles the bits of the input such that the output follows a uniform distribution. This means that if you change the input of the hash function from 192.168.1.1 to 192.168.1.2, the output will probably be totally different, seemingly random (but not truly random, since each input will always map to the same output).&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/assets/img/collision.png&quot;&gt;&lt;img src=&quot;/assets/img/collision.png&quot; style=&quot;max-width: 100%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;Example of a collision. Two different IP's have the same hash, which means that their index in the Bloom Filter will be the same.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Alright, now from the beginning: we blacklist 100 IP’s. Each IP will go through the hash function, and the result of the hash function will return a number smaller or equal to the size of the array. That number will be the index of the array that marks if the IP was blacklisted or not. But there will be collisions, so how do we handle that?&lt;/p&gt;

&lt;p&gt;Let’s suppose that the IP’s 178.23.12.63 and 112.64.90.12 have the same hash. The first IP was blacklisted, the second was not. When we check if the hash of the second IP is in the Bloom Filter, it is, even though the IP was never blacklisted. Does this mean we have a bug?&lt;/p&gt;

&lt;p&gt;Remember that in the beginning I said that the Bloom Filter has the goal of checking if an element is &lt;strong&gt;NOT&lt;/strong&gt; in a set. If the position of an element in the Bloom Filter is 0, that element is definitely &lt;strong&gt;NOT&lt;/strong&gt; in the set. However, if the position of an element in the Bloom Filter is 1, that element may be in the set, or it may be just a collision. All we can do is to reduce the probability of a collision, to reduce the number of times that the a memory access is needed to check if the IP is really blacklisted.&lt;/p&gt;

&lt;h3 id=&quot;reducing-the-collision-probability&quot;&gt;Reducing the collision probability&lt;/h3&gt;

&lt;p&gt;There are two main ways of reducing the probability of a collision, both at a cost. One possibility is to increase the size of the array. If we increase the size of the array (and consequently make the hash function return a number smaller or the same size as the new array size), the possibility of collisions decreases. Specifically, the probability of a false positive (the Bloom Filter return 1 when the element is not in the set) is (1-e&lt;sup&gt;(m/n)&lt;/sup&gt;), where m is the number of elements expected to insert in the filter and n is the size of the filter.&lt;/p&gt;

&lt;p&gt;Other way to reduce the probability of a collision is to increase the number of hash functions. This means that in our scenario, for one IP, various hash functions will be used to encode that IP, and various locations in the array will be marked with 1. If we use k hash functions, the probability of a false positive is now (1-e&lt;sup&gt;(mk/n)&lt;/sup&gt;)&lt;sup&gt;k&lt;/sup&gt;, which means that the optimal number of hash functions is (n/m)*ln(2) (more details about the equations &lt;a href=&quot;https://en.wikipedia.org/wiki/Bloom_filter#Probability_of_false_positives&quot;&gt;here&lt;/a&gt;).&lt;/p&gt;

&lt;figure&gt;
    &lt;a href=&quot;/assets/img/bloom_filter_two_hash_functions.png&quot;&gt;&lt;img src=&quot;/assets/img/bloom_filter_two_hash_functions.png&quot; style=&quot;max-width: 100%&quot; /&gt;&lt;/a&gt;
    &lt;figcaption style=&quot;text-align: center&quot;&gt;Example of a bloom filter with two hash functions. There is a collision in one of the hashes of the IP's, but it is possible to check that the IP 112.64.90.12 is not in the set, because one of its Bloom Filter positions is not 1.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Let’s implement a Bloom Filter in Python in just around 50 lines of code and see the result!&lt;/p&gt;

&lt;p&gt;In the next snippet of code, let’s start by creating a BloomFilter class. The constructor receives the size of the Bloom Filter and, optionally, the number of expected elements that the bloom filter will store. We will use the bitarray library to create an array of bits, and we set them all to zero. Finally, we set the number of hash functions to the equation that returns the optimal number of hash function, given the size of the bloom filter and the number of expected elements.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;math&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;bitarray&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bitarray&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BloomFilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;number_expected_elements&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;number_expected_elements&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;number_expected_elements&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bloom_filter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bitarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bloom_filter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;number_hash_functions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;number_expected_elements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now let’s define a hash function for the Bloom Filter. The implementation used (from &lt;a href=&quot;https://gist.github.com/mengzhuo/180cd6be8ba9e2743753&quot;&gt;here&lt;/a&gt;) implements the DJB2 algorithm. Let’s use it as a black box, since the explanation of the algorithm is beyond the scope of this post.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_hash_djb2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;hash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5381&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;nb&quot;&gt;hash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;hash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;hash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now we have on hash function, but how do we create K hash functions? We can perform a simple trick that works. Instead of creating different hash functions, we will just append a number for each input in the hash function. The number will represent the hash function number that is being called. Because any small difference in the input of a hash function will result in a totally different hash, the result can be seen as a different hash function. Cool, right?&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hash_djb2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now let’s create a function to add an element to the Bloom Filter. For that, let’s iterate through all of the hash functions, calculate the hash for the item and finally put a 1 (or True) in the index of the hash.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;add_to_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;number_hash_functions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bloom_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The only thing that’s left is to create a function that checks if the element is &lt;em&gt;NOT&lt;/em&gt; in the Bloom Filter. For that, let’s iterate again through all the hash functions. If any of the Bloom Filter positions has 0, we can say that the element is definitely not in the set. Otherwise, if all positions have 1, we cannot say that the element is not in the set.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;check_is_not_in_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;number_hash_functions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bloom_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;And that’s it! We have implemented our Bloom Filter. Let’s try it out!&lt;/p&gt;

&lt;p&gt;Let’s create a simple test to check if it is working. Let’s create a Bloom Filter with 1 million entries, and then set the expected number of elements to 100 000. We are going to add the element “192.168.1.1” to our Bloom Filter as the blocked IP.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;bloom_filter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BloomFilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;base_ip&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;192.168.1.&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bloom_filter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_to_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_ip&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;To test it, we will iterate from 1 to 100 000, and check if the IP 192.168.1.i is in the Bloom Filter (there are no IP’s when i&amp;gt;254, e.g. 192.168.289, but in this case we are just performing a test). We will print the elements that we don’t know if they are in the set; all other elements that will not be printed are definitely not in the set.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bloom_filter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;check_is_not_in_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_ip&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;blockquote&gt;
  &lt;p&gt;192.168.1.1&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Wow! Our Bloom Filter says that, from 100 000 IP’s, the only element that could be blocked is really our blocked IP! It did not produce any False Positive!&lt;/p&gt;

&lt;p&gt;Here is the full code of our Bloom Filter:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;math&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;bitarray&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bitarray&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BloomFilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;number_expected_elements&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;number_expected_elements&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;number_expected_elements&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bloom_filter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bitarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bloom_filter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;number_hash_functions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;number_expected_elements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_hash_djb2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;hash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5381&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;nb&quot;&gt;hash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;hash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ord&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;hash&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hash_djb2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;add_to_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;number_hash_functions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bloom_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;check_is_not_in_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;number_hash_functions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bloom_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;bloom_filter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BloomFilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;base_ip&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;192.168.1.&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bloom_filter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_to_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_ip&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bloom_filter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;check_is_not_in_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_ip&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;And that’s it for Bloom Filters! I hope that you have learned what a Bloom Filter is in detail and how to implement it.&lt;/p&gt;

&lt;p&gt;Thanks for sticking by!&lt;/p&gt;</content><category term="algorithms" /><category term="data structures" /><category term="big data" /><category term="bloom filter" /><summary type="html">Bloom Filter explanation</summary></entry><entry><title type="html">Use agile in your dissertation</title><link href="http://localhost:4000/use-agile-in-your-dissertation/" rel="alternate" type="text/html" title="Use agile in your dissertation" /><published>2019-10-06T00:00:00+01:00</published><updated>2019-10-06T00:00:00+01:00</updated><id>http://localhost:4000/use-agile-in-your-dissertation</id><content type="html" xml:base="http://localhost:4000/use-agile-in-your-dissertation/">&lt;p&gt;Hi there!&lt;/p&gt;

&lt;p&gt;After the previous dissertation posts, I noticed that the agile principles were the basis of some tips that I gave. There are remarking similarities between my tips and some agile principles. However, many people still fail in getting a good experience out of the dissertation because they don’t apply these principles. In this post, I will explain how the 12 Agile principles relate to the dissertation, and how to apply them to achieve a better dissertation.&lt;/p&gt;

&lt;p&gt;For all that don’t know what Agile is, here is a quick explanation.&lt;/p&gt;

&lt;h2 id=&quot;what-is-agile&quot;&gt;What is agile?&lt;/h2&gt;
&lt;p&gt;The Agile Manifesto was created in January of 2001 in a meeting in a Ski Resort, in Utah, by a restrict group of software development experts, such as Bob Martin (Uncle Bob), Kent Beck and Martin Fowler. The goal was to discuss lightweight practices for software development, to allow for better and faster software development.&lt;/p&gt;

&lt;p&gt;The agile manifesto is not a set of rules which you must strictly follow, neither a set of tools that you must use. Instead, it is a set of recommended principles that aim the collaborative development for a software project. It is based on iterative and incremental development methods, introduced many years before the Agile manifesto.&lt;/p&gt;

&lt;p&gt;Let’s go through the 12 Agile principles and I will explain how I think that they can be applied - or not - in your dissertation.&lt;/p&gt;

&lt;h2 id=&quot;1---our-highest-priority-is-to-satisfy-the-customer-through-early-and-continuous-delivery-of-valuable-software&quot;&gt;1 - Our highest priority is to satisfy the customer through early and continuous delivery of valuable software.&lt;/h2&gt;

&lt;p&gt;This principle must be broken down into parts for better understanding.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;“Our highest priority is to satisfy the customer” - Who is the customer in a dissertation?
The customer is always the entity that decides if the software is as good as requested. In a dissertation, the customer is the jury. Not only your supervisor, not the whole academia, and certainly not your dissertation presentation audience. Always have this in mind when writing the dissertation. The highest priority is to satisfy the jury to have a good grade.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;“through early and continuous delivery” - How to approach early and continuous delivery?
Early and continuous delivery in a dissertation means to deliver work at a regular pace, following a defined plan with time-bounded activities. For a student, early and continuous delivery means not to leave all the work for the last week. This avoids unexpected difficulties that delay the work, by working through them and planning them with time. Besides, it avoids the regular last-week-sprint burnout. Most importantly, it gives your supervisor an idea of how your dissertation is going long before it ends and allows to change the requirements to improve your work.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;“of valuable software” - What is valuable software?
In a dissertation there are two types of “valuable software”:&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;the dissertation itself&lt;/li&gt;
      &lt;li&gt;additional work (software, data analysis, study, …)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Both of them should be approached to satisfy the jury through early and continuous delivery.&lt;/p&gt;

&lt;h2 id=&quot;2---welcome-changing-requirements-even-late-in-development-agile-processes-harness-change-for-the-customers-competitive-advantage&quot;&gt;2 - Welcome changing requirements, even late in development. Agile processes harness change for the customer’s competitive advantage.&lt;/h2&gt;

&lt;div style=&quot;width:100%;height:0;padding-bottom:42%;position:relative;&quot;&gt;&lt;iframe src=&quot;https://giphy.com/embed/2sfgo6v1ihOGKVptoB&quot; width=&quot;100%&quot; height=&quot;100%&quot; style=&quot;position:absolute&quot; frameborder=&quot;0&quot; class=&quot;giphy-embed&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://giphy.com/gifs/disney-trailer-toy-story-4-2sfgo6v1ihOGKVptoB&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In a dissertation, this is a very important difference from enterprise projects. In enterprise projects, we should welcome changing requirements because the client pays for the software, and the software is designed for the client. However, most of the dissertations are individual work, and most of the requirements are defined by the student. Although the vision, scope and main goal can be defined by the supervisor, the main requirements are usually defined by the student; besides, a big advantage of the Agile processes does not happen for the dissertation. In an Agile environment, there are regular meetings between the development team and the client. In a dissertation, the client is the jury, so the meetings will be only with the supervisor. Besides, every time that the supervisor asks to change something, it can change your timings for the dissertation deliveries and presentation. So be careful with changes. If you change the requirements of your dissertation, go ahead and apply that to your work. However, if new requirements are added by the supervisor, think carefully if they make sense, and feel free to discuss with him/her his validity.&lt;/p&gt;

&lt;p&gt;With one month left for the delivery of the dissertation, however, I would advise you not to make major changes in requirements, because your delivery can be at risk. Before that, feel free to test and try new things, and add them to your work if they are useful.&lt;/p&gt;

&lt;h2 id=&quot;3---deliver-working-software-frequently-from-a-couple-of-weeks-to-a-couple-of-months-with-a-preference-to-the-shorter-timescale&quot;&gt;3 - Deliver working software frequently, from a couple of weeks to a couple of months, with a preference to the shorter timescale.&lt;/h2&gt;

&lt;p&gt;This principle can be adapted from “working software” to “readable pieces of your dissertation”. Yes, the dissertation should be made incrementally, and although sometimes it can be hard to write consistent texts without having all the research and implementation done, leaving all the writing to the end it is usually not a good choice, because when writing you will think about new possibilities that can enhance or change your work. You can even detect flaws that you left unnoticed when implementing your work.&lt;/p&gt;

&lt;p&gt;Because of that, you should write everything that you do. Even if later on that part can be deleted because it is out of scope, or it is not used - it doesn’t matter. If you are working for your dissertation, everything that you do is important and needs to be in the document. With that, you will deliver “readable pieces of your dissertation” incrementally, and later on it will be much easier to rewrite (if needed) and organize your dissertation’ chapters based on the text that you already have.&lt;/p&gt;

&lt;p&gt;But what is frequent? What should be the time interval to deliver work? Just like in Agile, it depends on your work, of yourself and your supervisor. However, I would argue that a meeting once a week with your supervisor to show him/her what you have done is a good time interval. It gives you time to show the work that you did that week and to discuss what to do in the next one. Two-week meetings are also a reasonable choice, but more than two weeks is too much. You can get lost, do something that is not in the scope of your work, or just don’t know what to do, and it will only be discussed in the next meeting. Prefer short weekly meetings to long monthly meetings.&lt;/p&gt;

&lt;h2 id=&quot;4---business-people-and-developers-must-work-together-daily-throughout-the-project&quot;&gt;4 - Business people and developers must work together daily throughout the project.&lt;/h2&gt;

&lt;div style=&quot;width:100%;height:0;padding-bottom:100%;position:relative;&quot;&gt;&lt;iframe src=&quot;https://giphy.com/embed/l0IyokIkZEXvWnXGw&quot; width=&quot;100%&quot; height=&quot;100%&quot; style=&quot;position:absolute&quot; frameborder=&quot;0&quot; class=&quot;giphy-embed&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://giphy.com/gifs/netflix-bill-nye-the-science-guy-l0IyokIkZEXvWnXGw&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This principle is simple and logical: you and your supervisor must work together. Working together does not mean that your supervisor should start doing your dissertation - it just means that each one must do his job to reach the desired output. You must do your work and your supervisor must supervise you, advise you, guide you, help you when you need, give you the tools you need and stop you when you do anything wrong - not just give you the requirements and wait for what you will do.&lt;/p&gt;

&lt;p&gt;I need to emphasize “throughout the project”. Just like in the last principles, “throughout” implies a consistent work discussed in regular meetings over time.&lt;/p&gt;

&lt;h2 id=&quot;5---build-projects-around-motivated-individuals-give-them-the-environment-and-support-they-need-and-trust-them-to-get-the-job-done&quot;&gt;5 - Build projects around motivated individuals. Give them the environment and support they need, and trust them to get the job done.&lt;/h2&gt;

&lt;p&gt;I am going to split this principle into two sub-principles. Firstly, to build projects around motivated individuals is to assure that you and your supervisor have the motivation needed to do your work. Many things will go wrong - they always do - and what separates a great from a median work is your willingness to tackle the problems and to work around them. It is not expected for your work to follow a straight path, and you should explain your difficulties in the dissertation, as well as how you tackled them to achieve your goal. An unmotivated student will just avoid the difficulties and find an easy way out.&lt;/p&gt;

&lt;p&gt;The latter part of the principle is about trust and support. Make sure your supervisor trusts you. Be totally honest with him/her, explain regularly your difficulties and don’t be shy to ask anything you need. Do you need a specific GPU, a virtual machine, or anything else, just ask him/her. He/she is there to help you with anything you need that is out of your control. Don’t be afraid of saying that you spent a week and you didn’t understand a topic or a paper. Trust him/her to help you do your dissertation.&lt;/p&gt;

&lt;h2 id=&quot;6---the-most-efficient-and-effective-method-of-conveying-information-to-and-within-a-development-team-is-face-to-face-conversation&quot;&gt;6 - The most efficient and effective method of conveying information to and within a development team is face-to-face conversation.&lt;/h2&gt;

&lt;div style=&quot;width:100%;height:0;padding-bottom:56%;position:relative;&quot;&gt;&lt;iframe src=&quot;https://giphy.com/embed/xThuW4sMMCqvaczToI&quot; width=&quot;100%&quot; height=&quot;100%&quot; style=&quot;position:absolute&quot; frameborder=&quot;0&quot; class=&quot;giphy-embed&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://giphy.com/gifs/the-grinder-fox-face-tv-xThuW4sMMCqvaczToI&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Regular face-to-face meetings are the most efficient way to adjust your work with your supervisor’s expectations. Sure, e-mails and chat messages do come in handy for quick and small questions that you may have and you need the answer ASAP, but nothing beats a face-to-face conversation. Video-conferencing is another way to hold meetings, but it should not be a common way. It should only be applied when one of the intervenients is temporarily away.&lt;/p&gt;

&lt;h2 id=&quot;7---working-software-is-the-primary-measure-of-progress&quot;&gt;7 - Working software is the primary measure of progress.&lt;/h2&gt;

&lt;p&gt;As I said above in 3, “working software” in this case can be adapted to “readable pieces of your dissertation”. Yes, there are other ways to measure your progress, mainly based on your work, and they vary on a case-to-case basis. However, what will be evaluated is your dissertation, so the dissertation is the ultimate measure of progress. Start writing as soon as you start doing some work, even if the work is still not finished. Because if have a lot of work but you do not write about it, your work will not be taken into account and you will end up with a poor dissertation.&lt;/p&gt;

&lt;h2 id=&quot;8---agile-processes-promote-sustainable-development-the-sponsors-developers-and-users-should-be-able-to-maintain-a-constant-pace-indefinitely&quot;&gt;8 - Agile processes promote sustainable development. The sponsors, developers, and users should be able to maintain a constant pace indefinitely.&lt;/h2&gt;

&lt;p&gt;This principle is very important for a dissertation if you want to reach the end of your work without feeling burnout. It is very important to keep a constant pace of work. It is Ok to work more than 8 hours a day once a week, but not more than that. It is important to separate your work from your personal life for you to feel accomplished and for not getting obsessed with minor obstacles that may seem like the end of the world. Impose on yourself a 40-hour week schedule for work and follow it. If you don’t do it, you may end up working tirelessly for your dissertation but with very low productivity. It will harm not only yourself but also your dissertation.&lt;/p&gt;

&lt;h2 id=&quot;9---continuous-attention-to-technical-excellence-and-good-design-enhances-agility&quot;&gt;9 - Continuous attention to technical excellence and good design enhances agility.&lt;/h2&gt;

&lt;p&gt;This is something you should do not only in your dissertation but also in your future career. If you plan carefully your work and if you work with pride, it will reflect on your dissertation and presentation. Even if you do not notice, experient people in every area acknowledge and know how to differentiate between work done with pride and work just to pass the subject. Technical excellence differentiates the median from the great workers in every area - and that can be the difference between an 18 and a 20 in the dissertation.&lt;/p&gt;

&lt;h2 id=&quot;10---simplicitythe-art-of-maximizing-the-amount-of-work-not-doneis-essential&quot;&gt;10 - Simplicity–the art of maximizing the amount of work not done–is essential.&lt;/h2&gt;

&lt;p&gt;I love this principle. Because everyone mistakes “work with pride” with “you must do everything that you have planned for your dissertation”. That’s why you plan things: to prioritize what is important and to do things in importance order. If a specific feature will take two weeks to be done and it will not make much of a difference in your dissertation, then why doing it?&lt;/p&gt;

&lt;p&gt;The Pareto Principle, also known as the 80/20 rule, says that approximately 80% of the effects come from 20% of the causes. If you pay attention to your life, this principle applies to many things. In your dissertation, 80% of what you will write will be based on 20% of the work. Besides, 80% of your grade will be based on only 20% of your dissertation. Pay attention to that and focus on what’s important - identify your 80% and make them shine. If you have free time, work on parts of the other 20%, but don’t waste much time with them - they are not that important.&lt;/p&gt;

&lt;h2 id=&quot;11---the-best-architectures-requirements-and-designs-emerge-from-self-organizing-teams&quot;&gt;11 - The best architectures, requirements, and designs emerge from self-organizing teams.&lt;/h2&gt;

&lt;p&gt;The dissertation is a one-person work (two with the supervisor), so it may look that this principle does not apply to the dissertation. However, you have to look at yourself as “your team”. Because the work is yours more than anybody else, you will have the last word on deciding the architectures, requirements and designs, so do it wisely. Do not accept architectures that are imposed by anyone if you do not agree with them, because you are the one who will have to answer for them sooner or later. Don’t be afraid of creating your own architectures or requirements if they make sense to you. Self-proposed implementations are much valuable in a dissertation and show that the student has deep knowledge about the topic.&lt;/p&gt;

&lt;h2 id=&quot;12---at-regular-intervals-the-team-reflects-on-how-to-become-more-effective-then-tunes-and-adjusts-its-behavior-accordingly&quot;&gt;12 - At regular intervals, the team reflects on how to become more effective, then tunes and adjusts its behavior accordingly.&lt;/h2&gt;

&lt;div style=&quot;width:100%;height:0;padding-bottom:43%;position:relative;&quot;&gt;&lt;iframe src=&quot;https://giphy.com/embed/DfSXiR60W9MVq&quot; width=&quot;100%&quot; height=&quot;100%&quot; style=&quot;position:absolute&quot; frameborder=&quot;0&quot; class=&quot;giphy-embed&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://giphy.com/gifs/alan-DfSXiR60W9MVq&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You should use this principle with yourself. Sometimes we work so fast and have so many things to do that we forget of reflecting on what we did well and what we need to improve. Once a week take 10 minutes to think about what you have done in that week, what was correctly done and what can be improved. After a month of retrospectives, you will find it very useful to improve your work habits and you will be amazed when checking your performance improvement simply by thinking on what you did wrong and taking preventive measure to not happen again.&lt;/p&gt;

&lt;p&gt;That’s it, thanks for sticking by until the end.&lt;/p&gt;

&lt;p&gt;See ya on other posts!&lt;/p&gt;</content><category term="thesis" /><category term="dissertation" /><category term="agile" /><summary type="html">Take advantage of the 12 Agile principles for a better dissertation</summary></entry><entry><title type="html">How to have an A+ dissertation/thesis (IV/IV)</title><link href="http://localhost:4000/how-to-have-a-thesis-part-4/" rel="alternate" type="text/html" title="How to have an A+ dissertation/thesis (IV/IV)" /><published>2019-09-13T00:00:00+01:00</published><updated>2019-09-13T00:00:00+01:00</updated><id>http://localhost:4000/how-to-have-a-thesis-part-4</id><content type="html" xml:base="http://localhost:4000/how-to-have-a-thesis-part-4/">&lt;p&gt;Hi there, and welcome to the last part of this series!&lt;/p&gt;

&lt;p&gt;If you didn’t read the previous post, check it out &lt;a href=&quot;/how-to-have-a-thesis-part-3/&quot;&gt;here&lt;/a&gt;. I am summarizing tips I would give myself before starting the dissertation, explaining my good and bad decisions along the way.&lt;/p&gt;

&lt;p&gt;Before, a heads up: the content of this blog post is highly subjective and related to my dissertation experience, so don’t take it as the ground truth. But do think critically about my advice and, whether you agree with them or not, comment on what you think about it&lt;/p&gt;

&lt;p&gt;This post is divided into four parts:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/how-to-have-a-thesis-part-1/&quot;&gt;I - 3 tips for before starting the writing of the dissertation;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/how-to-have-a-thesis-part-2/&quot;&gt;II - 4 tips for during the writing of the dissertation;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/how-to-have-a-thesis-part-3/&quot;&gt;III - more 4 tips for during the writing of the dissertation;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;IV - 3 tips for after the writing of the dissertation.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this post, I will give pieces of advice on what to do after the writing of the dissertation is done. Let’s start!&lt;/p&gt;

&lt;h1 id=&quot;after-the-dissertation&quot;&gt;After the dissertation&lt;/h1&gt;

&lt;h2 id=&quot;12---review-it-more-than-once&quot;&gt;12 - Review it more than once!&lt;/h2&gt;

&lt;p&gt;You have &lt;strong&gt;FINALLY&lt;/strong&gt; written your dissertation. It’s finally over! But… is it? Every time you read a paragraph of your dissertation you change something. And now you receive the reviewed version of your supervisor, full of changes, and you have to rewrite everything. How many times do you need to review it until it’s done?&lt;/p&gt;

&lt;h3 id=&quot;my-experience&quot;&gt;My Experience&lt;/h3&gt;
&lt;p&gt;After the dissertation was written, I reviewed it once before sending it to my supervisor. In that review, besides syntax changes, the major changes done were to the introductions and conclusions of each chapter, that were changed to reflect the chapters’ content. It was also done many changes in the text to make it more clear and objective. After that, I send it to my supervisor. I got a little worried because the final reviewed version was only delivered to me days before the final date to send the final version, but I had the luck of my supervisor making all the minor changes in the document itself. So, when it was delivered to me, I only needed to perform a quick second revision and to make one or two major changes, mainly in the organization of the chapters.&lt;/p&gt;

&lt;h3 id=&quot;my-advice&quot;&gt;My Advice&lt;/h3&gt;
&lt;p&gt;After having everything written, I think you should review it at least two times. The first time is a coherency check. Check if the paragraphs and the chapters are coherent between each other. Check if the references are correct. Check if your introduction chapter mentions correctly all chapters and that it provides an overview of your entire work. Check if the introductions and conclusions of each chapter are coherent with what is in each chapter. And more importantly, check if what you write is what you mean, and make an effort to understand if another person would understand what you have written. After the first review is done, you can send it to your supervisor.&lt;/p&gt;

&lt;p&gt;Your supervisor will send you a revised dissertation/thesis (hopefully). Now you’re ready for the second review. In the second review, you will mainly apply the changes that your supervisor advised you to (if you want, obviously; do not forget that it is your work, you have the last word!), and you will perform the grammar and syntax check. I advise you to use Grammarly: it gives you good tips on how to improve your writing.&lt;/p&gt;

&lt;p&gt;Overall, leave at least three weeks for this process. One week for your first review, one week for your supervisors’ review and one week for your second review. Further revisions can be made, but you will probably only perform minor changes, and it is not needed to review the whole document since you have already done it two times.&lt;/p&gt;

&lt;h2 id=&quot;13---save-one-week-for-presentation-training&quot;&gt;13 - Save one week for presentation training&lt;/h2&gt;

&lt;div style=&quot;width:100%;height:0;padding-bottom:69%;position:relative;&quot;&gt;&lt;iframe src=&quot;https://giphy.com/embed/3o7qDEq2bMbcbPRQ2c&quot; width=&quot;100%&quot; height=&quot;100%&quot; style=&quot;position:absolute&quot; frameborder=&quot;0&quot; class=&quot;giphy-embed&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://giphy.com/gifs/mic-drop-peace-out-obama-3o7qDEq2bMbcbPRQ2c&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Let’s face it: your grade will be set because of your dissertation, not because of your presentation. At most, the presentation will be used to decide between two grades, if the jury is uncertain. However, because it is a public presentation, we all get nervous and anxious before it happens. How much should we focus on presentation training? What should we do to prepare ourselves for that moment?&lt;/p&gt;

&lt;h3 id=&quot;my-experience-1&quot;&gt;My Experience&lt;/h3&gt;
&lt;p&gt;Before the presentation, I was scared of this moment. What if the jury did not like my work? What if they discovered that the work that I have done was simple, and everyone could do it, and what I had done was of no use? To avoid that, I trained hard for the presentation the week before. I made the first version of the presentation and I asked a lot of people for opinions and improvements. Then, I started focusing on what I was going to say. I trained for more than 20 times. For every training, I would adjust just a little bit the presentation - for me to remember what I was going to say; to explain information in graphical form and more explicitly; to be easier for non-experts to understand, etc.&lt;/p&gt;

&lt;p&gt;Because I knew possible flaws, omissions or questions about my work, I wrote them and I also wrote the answer that I would give if they were answered to me. That gave me more confidence about my work because I knew that I was probably not going to be surprised with questions that I did not know how to answer (spoiler: none of the questions that were asked was on the list; all the questions were easier to answer).&lt;/p&gt;

&lt;p&gt;On the day of the presentation, I knew everything that I was going to say. Curiously, I was not nervous. I was very confident that my presentation was going to good. And looking back, it went so much better than what I have always expected.&lt;/p&gt;

&lt;h3 id=&quot;my-advice-1&quot;&gt;My Advice&lt;/h3&gt;
&lt;p&gt;Leave one week for presentation training. Use the first day for creating the presentation. Then, the technique is the same as the writing of the dissertation/thesis: iterate. Present to your supervisors, friends, family, colleagues, … And train, train, train. Ask them to take notes of things they thought are wrong, things that they do not understand or just things that they do not like. If you make 3 presentations per day on the other days of the week, and you make the changes that were told you to by your audience, you will find yourself with a better presentation and with more confidence in your presentation. In this phase, training is really important for you to memorize what you will say, and to create mechanisms to present better - you will do that almost automatically with more training.&lt;/p&gt;

&lt;p&gt;In the end, you will notice that the training is of no use anymore: you always say the same things, take more or less the same time and there not many critiques to improve your presentation. That’s when you know you are ready to present with confidence, with no anxiety whatsoever. You have rehearsed so many times that you just need to present one more and say the same things you did in the presentations before.&lt;/p&gt;

&lt;p&gt;If you want, you can write down the questions that you are expecting to hear from the jury. In my case, none of them was asked, but it gave me more confidence in the presentation.&lt;/p&gt;

&lt;h2 id=&quot;14---you-are-the-master-of-your-own-work&quot;&gt;14 - You are the master of your own work!&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;I have written 11 books but each time I think ‘Uh-oh, they’re going to find out now. I’ve run a game on everybody, and they’re going to find me out.’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;—Maya Angelou&lt;/p&gt;

&lt;p&gt;Impostor syndrome. Do you know what it is? It’s that feeling you get when you think that you are not worthy of what you achieved - someone was wrong in choosing you, you are clearly not good enough, and all your success was just a lucky sequence of events. Don’t worry: 70% of people feel this way, according to a study in the International Journal of Behavioral Science.&lt;/p&gt;

&lt;p&gt;In that study, it is said that those with imposter syndrome tend to be perfectionists and to spend more time in their work just to make things perfect. Congratulations: if you have the imposter syndrome, you’re probably doing a good job. But it can be hard to deal with imposter syndrome in long-term projects. The motivation starts to decrease and you start questioning yourself and your work. If you’re not confident in your work in the presentation, the jury will notice and it will start to make more technical questions and it will doubt your answers. How do you become confident in your work?&lt;/p&gt;

&lt;h3 id=&quot;my-experience-2&quot;&gt;My Experience&lt;/h3&gt;
&lt;p&gt;Thankfully, my supervisor has always reminded me of how good my dissertation was. Because she knew me well, she knew that I would not relax if she said that, it would only give me more motivation to keep working. When I was not motivated (it happened 3 or 4 times), I called a meeting with her and I would explain to her why that was happening. The work was re-scheduled and adapted until I was comfortable and motivated for what I had to do.&lt;/p&gt;

&lt;h3 id=&quot;my-advice-2&quot;&gt;My Advice&lt;/h3&gt;
&lt;p&gt;Just like I said in the previous tip, it gives you more confidence to take notes of the downsides of your work, to think about adequate responses if it comes up in the presentation. Even if they do not come up, it gives you more confidence in your work.&lt;/p&gt;

&lt;p&gt;No one in the world knows more about your work than yourself. You have been working at least for a year in your dissertation/thesis: no one knows more about the cahracteristics, the difficulties, the pros and the cons of your work. Remember: your goal is not to make the perfect dissertation/thesis. In fact, no dissertation is perfect: there are great dissertations that completely fail their main objective. The most important are the conclusions: if you did all over again, would you change anything? Say it in the conclusions and in the future work. Remember what Einstein said,&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Failure is success in progress.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If you totally fail, say why to help someone not to fail. Or to fail better.&lt;/p&gt;

&lt;p&gt;Explain what you have failed in your presentation. Be clear and don’t come with excuses. The jury knows when the students are honest.&lt;/p&gt;

&lt;h2 id=&quot;15---write-a-paper&quot;&gt;15 - Write a paper!&lt;/h2&gt;

&lt;div style=&quot;width:100%;height:0;padding-bottom:56%;position:relative;&quot;&gt;&lt;iframe src=&quot;https://giphy.com/embed/XIqCQx02E1U9W&quot; width=&quot;100%&quot; height=&quot;100%&quot; style=&quot;position:absolute&quot; frameborder=&quot;0&quot; class=&quot;giphy-embed&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://giphy.com/gifs/XIqCQx02E1U9W&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You are at the end of this dissertation (or you have already presented your work) and your supervisor wants you to write a paper (or more) about it. He/she says that your contribution with your dissertation/thesis can help others in the field - and it can also help you to have a higher grade. You get excited, but at the same time writing a paper also means more work. If you are finishing your masters, you probably have never written a paper, and you don’t know where to start. What should you do?&lt;/p&gt;

&lt;h3 id=&quot;my-experience-3&quot;&gt;My Experience&lt;/h3&gt;
&lt;p&gt;Months before the dissertation presentation, I submitted a paper to an international conference. The result came back in the day before the dissertation presentation: it was rejected. My supervisors came to me saying that it just needed a few tweaks to be accepted in another conference, that I had nothing to worry about. I relaxed and, as I said before, the dissertation presentation went really well. After the dissertation presentation, besides the rejected article being reviewed to be submitted, I made another conference paper and a journal paper, about different topics approached in the dissertation. I still don’t know if any of them will be accepted, but I know that with the rejection of the first paper, I learned a lot about writing papers and the probability of the other papers being accepted is much higher.&lt;/p&gt;

&lt;h3 id=&quot;my-advice-3&quot;&gt;My Advice&lt;/h3&gt;
&lt;p&gt;If you are in doubt about writing a paper, my advice is to go for it. Share your work with others. By my experience, students regularly underestimate the potential of their projects: try to submit a paper and then wait for the feedback. If the feedback is negative (the paper was rejected), don’t worry. Rejections happen. Use it to improve your work with world-class specialists in your topic, even if some reviews seem totally wrong. If that happens, maybe it’s because the supervisors did not understand your work, and you should explain it better.&lt;/p&gt;

&lt;p&gt;Writing a paper is different from the work you have done up to this point. You have to use your summarization capabilities for the reader to be able to understand what you did in your work. Writing your first paper can be confusing, due to lack of practice, and very boring, due to the number of hours you will be reviewing it and changing it, with the feedback from your supervisors. Just as in the dissertation/thesis, you have to discuss critically the consequences of your work. Even the cons of your work should be discussed. But do not fear: when the paper is accepted, you know that it was all worth it.&lt;/p&gt;

&lt;p&gt;That’s it for our series!&lt;/p&gt;

&lt;p&gt;Thanks for sticking by until the end.&lt;/p&gt;

&lt;p&gt;See ya on other posts!&lt;/p&gt;</content><category term="thesis" /><category term="dissertation" /><category term="tips" /><summary type="html">15 tips for your thesis/dissertation - 4/4</summary></entry><entry><title type="html">How to have an A+ dissertation/thesis (III/IV)</title><link href="http://localhost:4000/how-to-have-a-thesis-part-3/" rel="alternate" type="text/html" title="How to have an A+ dissertation/thesis (III/IV)" /><published>2019-09-06T00:00:00+01:00</published><updated>2019-09-06T00:00:00+01:00</updated><id>http://localhost:4000/how-to-have-a-thesis-part-3</id><content type="html" xml:base="http://localhost:4000/how-to-have-a-thesis-part-3/">&lt;p&gt;Hi there!&lt;/p&gt;

&lt;p&gt;If you didn’t read the previous post, check it out &lt;a href=&quot;/how-to-have-a-thesis-part-2/&quot;&gt;here&lt;/a&gt;. I am summarizing tips I would give myself before starting the dissertation, explaining my good and bad decisions along the way.&lt;/p&gt;

&lt;p&gt;Before, a heads up: the content of this blog post is highly subjective and related to my dissertation experience, so don’t take it as the ground truth. But do think critically about my advice and, whether you agree with them or not, comment on what you think about it&lt;/p&gt;

&lt;p&gt;This post is divided into four parts:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/how-to-have-a-thesis-part-1/&quot;&gt;I - 3 tips for before starting the writing of the dissertation;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/how-to-have-a-thesis-part-2/&quot;&gt;II - 4 tips for during the writing of the dissertation;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;III - more 4 tips for during the writing of the dissertation;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/how-to-have-a-thesis-part-4/&quot;&gt;IV - 3 tips for after the writing of the dissertation.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;8---the-dissertation-is-a-marathon-not-a-sprint&quot;&gt;8 - The dissertation is a marathon, not a sprint!&lt;/h2&gt;

&lt;div style=&quot;width:100%;height:0;padding-bottom:100%;position:relative;&quot;&gt;&lt;iframe src=&quot;https://giphy.com/embed/sRKg9r2YWeCTG5JTTo&quot; width=&quot;100%&quot; height=&quot;100%&quot; style=&quot;position:absolute&quot; frameborder=&quot;0&quot; class=&quot;giphy-embed&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://giphy.com/gifs/running-run-runs-sRKg9r2YWeCTG5JTTo&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This advice is not about your dissertation work, or about your writing. Is just about you. And your time. In a dissertation work, everyone has moments when they thought everything is lost. That there is nothing valuable in your work. That it is so frustrating that you can’t wait for it to be finished. This piece of advice is not about how to deal with those times (sorry, I am not a motivational speaker). It is about how to avoid them.&lt;/p&gt;

&lt;h3 id=&quot;my-experience&quot;&gt;My Experience&lt;/h3&gt;
&lt;p&gt;I tend to get overanxious about the work that I need to do. I tend to work a lot in the beginning. And that’s what I did. So much that before the half of the schedule of my work, I had already written the equivalent of a “regular” dissertation. After I understood that I didn’t need to overwork to finish my dissertation (if I wanted, it was already done), I rarely spent after hours working on my dissertation as I did previously. I played a &lt;strong&gt;LOT&lt;/strong&gt; of Football Manager. I played the guitar. I spent more time in Scouts. I saw many Youtube videos about random and uninteresting things. Curiously, I did not stop being productive. I did as much work as before, but with a lot more fun.&lt;/p&gt;

&lt;h3 id=&quot;my-advice&quot;&gt;My Advice&lt;/h3&gt;
&lt;p&gt;Relax. I learned that it is important to shut down when you get out of the office and distract yourself with other things. It helps you avoid burnout and it is clinically proved that it improves your productivity the next day. Whether you want to play a game, or see a movie, or just do nothing (doing nothing is also important!), do it.&lt;/p&gt;

&lt;p&gt;Besides, time is really important if you want to be productive. Create a schedule of what you propose yourself to do the next day, even if you don’t stick to it. Consider what are the next things to do and how long will take you to get them done. Everything will be easier if you keep a steady pace with your work. If you have done less than what you have scheduled for a day, do not overcompensate. All-nighters are clearly not worth it, and roadblocks are inevitable. Just adjust your schedule for the next day and try it again. If you do that, the dissertation work will be &lt;strong&gt;SO&lt;/strong&gt; much easier. Because the dissertation is a marathon, not a sprint, and you must be mentally ready for the long run.&lt;/p&gt;

&lt;h2 id=&quot;9---when-to-pivot-your-work&quot;&gt;9 - When to pivot your work?&lt;/h2&gt;

&lt;p&gt;It is not so uncommon to find supervisors that are constantly shifting the objective of the dissertation. There are several reasons for it:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;they saw a new paper with interesting results;&lt;/li&gt;
  &lt;li&gt;they do not understand in depth the area you are working in;&lt;/li&gt;
  &lt;li&gt;the results you have are useless;&lt;/li&gt;
  &lt;li&gt;you are not being productive/you are not motivated.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When and why should you accept to pivot your work in the middle of a dissertation?&lt;/p&gt;

&lt;h3 id=&quot;my-experience-1&quot;&gt;My Experience&lt;/h3&gt;
&lt;p&gt;I did not completely pivot my work, but it has evolved over the year. In the beginning, the goal was to use machine learning to forecast network metrics. After that was done, we focused on some specific forecasting scenarios interesting for the network operator. After that, we thought that it was interesting to create a real-time distributed architecture to test the forecast - the focus of my work changed from machine learning to software engineering. In the end, two scenarios were tested with the forecasts implemented in the architecture to improve the network - again, the focus changed from software engineering to solving a real network problem.&lt;/p&gt;

&lt;p&gt;Althought I did the work I had planned to do, I did much more than that. My dissertation was not only a machine learning problem: it had grown over time. It solved real scenarios in a 5G network with the help of machine learning and a dedicated architecture for forecasting. It is comprehensible and even natural that the dissertation work evolves over time. However, many of my friends reached mid-year with a totally different dissertation from what they were expecting. They became bored, unmotivated and unconfident about their work. They did not like what they were doing, because that’s not what they signed up for (or at least what they thought they signed for). What did they do differently from me? It was their fault? It was their supervisors’ fault?&lt;/p&gt;

&lt;h3 id=&quot;my-advice-1&quot;&gt;My Advice&lt;/h3&gt;
&lt;p&gt;It is hard to determine who’s fault it is without looking at it on a case-by-case basis. However, there is some advice I can give.&lt;/p&gt;

&lt;p&gt;Take a look at tip &lt;em&gt;Understand the basics before diving in!&lt;/em&gt; (part 1). This is the least you can do to not being caught up in the same situation that my friends were in. Talk with your supervisor and discuss what is the schedule for your work. Then, learn more about what you will do. That will help you to save some time and to have something done early. Having work done in an earlier phase is essential to discuss the scope of your work and validate our hypothesis. If you have to pivot, the earlier you do it the better.&lt;/p&gt;

&lt;p&gt;Another essential trick is to have a personal schedule for the dissertation. Be realistic. It helps you to understand which foot you are in, and how many hours do you still need to put in to get the job done. It will also help you to list upfront all the problems you think you may find in your implementation. Do you need license X and your University does not have it? Do you need a computer with special requirements? The earlier you ask for it, the better.&lt;/p&gt;

&lt;p&gt;If you really have to pivot your work, do it because of you. Do not pivot if your supervisor thinks that what you are doing is uninteresting and it will not produce any results. Yes, you should hear him and take his/her advice, but sometimes you really have to stand up for yourself. If you have done fruitful work, why give up? If you are on a later stage of the dissertation work, maybe pivoting will not produce any good results. You will take more time to understand and to redo everything you had done until then, and you will probably miss your personal deadlines.&lt;/p&gt;

&lt;p&gt;But when should you pivot then? For my experience, the main reason you should pivot is if you are not motivated and you have found a new problem that you want to solve and that you think you can do it. Obviously, this involves knowledge about the area you are pivoting. Otherwise, you may end up in the same situation as before. The interesting results are a secondary reason and they are closely related to your motivation. If you are motivated is because you think you think you can get interesting results, and vice-versa.&lt;/p&gt;

&lt;h2 id=&quot;10---how-much-time-should-i-work-per-day&quot;&gt;10 - How much time should I work per day?&lt;/h2&gt;

&lt;p&gt;Surely some students work more than 12 hours a day to get their dissertation done. Some students work around 4 hours a day and also get their dissertation done at the same time. How much time should you work per day?&lt;/p&gt;

&lt;h3 id=&quot;my-experience-2&quot;&gt;My Experience&lt;/h3&gt;
&lt;p&gt;When I began my dissertation work, I worked endlessly. Sometimes more than 12 hours every day. &lt;strong&gt;Every day&lt;/strong&gt;. Looking back, it was a bad decision. Some months after, I realized that I was only productive for around 6 hours of that 12, and I changed my working habits. I worked only on workdays, 8 hours a day, just as if I worked for a company. Surprisingly, I started being even more productive than before.&lt;/p&gt;

&lt;h3 id=&quot;my-advice-2&quot;&gt;My Advice&lt;/h3&gt;
&lt;p&gt;This is not a hard question. Around 8 hours at workdays. That’s it. It’s the mean number of hours that a “regular” worker works in a job. It is also proved to be effective. If we worked for more than that, we became unproductive, tired and unmotivated. Of course, there are exceptions. If you like to work 12 hours a day in three days of the week and rest the other four, you can do it if it suits you. However, it is not what has proven to be successful for most people.&lt;/p&gt;

&lt;p&gt;Don’t feel pressured by the ones that say that you should work more than that - it is unrealistic to expect more and better work just because you work more hours. Mainly in a dissertation, where critical thinking is key.&lt;/p&gt;

&lt;p&gt;Maybe sometimes you will feel that you are procrastinating your work, and all you ever want to do is to see Youtube videos or read a book. When that happens, try to enforce yourself a time management rule, such as the Pomodoro technique: 25 minutes of work followed by 5 minutes of a break. The rule is adjustable: if you are feeling productive, there is nothing wrong in duplicating the work and break time (50/10). After you do it for some time, it will become natural to you the work-&amp;gt;break cycle.&lt;/p&gt;

&lt;p&gt;Oh, I almost forgot one thing. It is OK to take breaks. Actually, it is essential to take breaks. It helps you and your body to focus. A longer break in the morning and another in the evening (15 minutes) to eat a snack will help you boost your productivity. When you are writing, it is common to feel the writer’s block - the feeling that you don’t know what to write or where to start writing. Take a break. Go chat with someone. Get up and go for a walk. It will help you clear your mind. When you come back it will be easier to end up writing.&lt;/p&gt;

&lt;h2 id=&quot;11---the-first-goal-is-to-get-a-draft-not-to-get-it-written&quot;&gt;11 - The first goal is to get a draft, not to get it written&lt;/h2&gt;

&lt;figure&gt;
	&lt;a href=&quot;/assets/img/thesis-5.jpeg&quot;&gt;&lt;img src=&quot;/assets/img/thesis-5.jpeg&quot; style=&quot;width:70%&quot; /&gt;&lt;/a&gt;
	&lt;figcaption style=&quot;text-align: center&quot;&gt;Don't worry if the first version is a mess. Rewrite it. It will be better the second time.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This is the last piece of advice during the dissertation. Many students are very concerned about their writing from the very first moment. So much concerned that for every line they write, they spend an hour looking at it and thinking about how they can improve it, to be no less than perfect. This is common to happen in the first moments where the students start to write their dissertation.&lt;/p&gt;

&lt;h3 id=&quot;my-experience-3&quot;&gt;My Experience&lt;/h3&gt;
&lt;p&gt;The first chapter I wrote for my dissertation was the state of the art. I started by writing it by topics; then, it evolved for sentences with little connection with each other. Finally, in later revisions, some paragraphs were reviewed to make connections between them. Reading it after the delivery, I understood the importance of iterations in the writing, and why I couldn’t do that the first time I wrote it. Some references in the text could only be made after I knew everything that I was going to say later. If I would have been obsessed with perfection at first try, I would probably not have written so much and with so high quality.&lt;/p&gt;

&lt;h3 id=&quot;my-advice-3&quot;&gt;My Advice&lt;/h3&gt;
&lt;p&gt;To write a dissertation is just like building a product - first, you have to build the Minimum Viable Product (MVP). Don’t expect to do everything right for the first time you write it. You will review your document and change it many times until it is finally ready to be delivered and presented.&lt;/p&gt;

&lt;p&gt;The first goal of the writing is to explain what you did, what are your thoughts and what conclusion you can take from your work. Style is important, but it is only regarded if what you are writing is interesting. Before wasting too much time rephrasing everything you did, write what you did in a quick and dirty way. After the first version is completed, it will be much easier for you to have the big picture of your work and to rephrase paragraphs making the connection with what you will say later.&lt;/p&gt;

&lt;p&gt;That’s it for today!&lt;/p&gt;

&lt;p&gt;Thanks for sticking by. Click &lt;a href=&quot;/how-to-have-a-thesis-part-4/&quot;&gt;here&lt;/a&gt; for part IV.&lt;/p&gt;

&lt;p&gt;See ya!&lt;/p&gt;</content><category term="thesis" /><category term="dissertation" /><category term="tips" /><summary type="html">15 tips for your thesis/dissertation - 3/4</summary></entry><entry><title type="html">How to have an A+ dissertation/thesis (II/IV)</title><link href="http://localhost:4000/how-to-have-a-thesis-part-2/" rel="alternate" type="text/html" title="How to have an A+ dissertation/thesis (II/IV)" /><published>2019-08-30T00:00:00+01:00</published><updated>2019-08-30T00:00:00+01:00</updated><id>http://localhost:4000/how-to-have-a-thesis-part-2</id><content type="html" xml:base="http://localhost:4000/how-to-have-a-thesis-part-2/">&lt;p&gt;Hi there!&lt;/p&gt;

&lt;p&gt;If you didn’t read the previous post, check it out &lt;a href=&quot;/how-to-have-a-thesis-part-1/&quot;&gt;here&lt;/a&gt;. I am summarizing tips I would give myself before starting the dissertation, explaining my good and bad decisions along the way.&lt;/p&gt;

&lt;p&gt;Before, a heads up: the content of this blog post is highly subjective and related to my dissertation experience, so don’t take it as the ground truth. But do think critically about my advice and, whether you agree with them or not, comment on what you think about it&lt;/p&gt;

&lt;p&gt;This post is divided into four parts:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/how-to-have-a-thesis-part-1/&quot;&gt;I - 3 tips for before starting the writing of the dissertation;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;II - 4 tips for during the writing of the dissertation;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/how-to-have-a-thesis-part-3/&quot;&gt;III - more 4 tips for during the writing of the dissertation;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/how-to-have-a-thesis-part-4/&quot;&gt;IV - 3 tips for after the writing of the dissertation.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;during-the-dissertation&quot;&gt;During the dissertation&lt;/h1&gt;

&lt;h2 id=&quot;4---when-to-research-and-write-the-state-of-the-art-of-your-work&quot;&gt;4 - When to research and write the state of the art of your work?&lt;/h2&gt;

&lt;figure&gt;
	&lt;a href=&quot;/assets/img/thesis-2.jpg&quot;&gt;&lt;img src=&quot;/assets/img/thesis-2.jpg&quot; /&gt;&lt;/a&gt;
	&lt;figcaption style=&quot;text-align: center&quot;&gt;It can be important to search for articles in the beginning of the thesis&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;A state of the art is a survey about the recent advances in the area you are working on. It shows the newer techniques for solving the problem you are trying to solve. In a dissertation, the state of the art chapter is usually about 10%-20% of the size of the whole document. A good state of the art shows not only the proposed techniques, but also that the writer has knowledge about the area he/she is working with. The goal is to identify the flaws in the work done previously to justify your approach to the problem. Otherwise, you will be solving a problem that is already solved.&lt;/p&gt;

&lt;p&gt;This question comes up frequently at the beginning of the dissertation work. Should you write the state of the art before you start trying to solve the problem? Or do you start writing the state of the art after having a deep knowledge about your work, and you can easily identify similar research reports?&lt;/p&gt;

&lt;p&gt;Both approaches have pros and cons. If you start to write the state of the art before start working on the dissertation, you understand better the proposed approaches to solve your problem and the recent techniques used before starting the dissertation work, and it can influence you (in a good way) to follow a certain approach. However, after the development of your work, you may have to adjust your state of the art to address the unexpected problems you may have encountered.&lt;/p&gt;

&lt;p&gt;If you write the state of the art after the dissertation work is done, you will have more in-depth knowledge about your work at the time you are writing it, and your state of the art will probably be more focused on your problem. However, there is always the risk (and it is a &lt;strong&gt;BIG&lt;/strong&gt; risk!) of finding out that the problem you have solved was already solved by someone else.&lt;/p&gt;

&lt;h3 id=&quot;my-experience&quot;&gt;My Experience&lt;/h3&gt;
&lt;p&gt;I initially wrote the state of the art before starting the dissertation work. It took two weeks. And it was beautiful &amp;lt;3. By the end of it, I was certain of what I was going to do next, and I knew everything about the approach to follow. When I started the dissertation work, nothing went as I expected. The data that I was told I would have was totally different from what I had thought; the approaches I thought would work did not work; even the scope of the dissertation slightly changed. As a result, by the end of it, I had to erase 60% of the state of the art previously done and start all over again; the other 40% need to be reviewed to be according to the scope of the work.&lt;/p&gt;

&lt;h3 id=&quot;my-advice&quot;&gt;My Advice&lt;/h3&gt;
&lt;p&gt;Well, I’m sorry. If you want to have a great state of the art, you will have to write it two times (at least…). You can start by making a state of the art before you start the dissertation work. This version will be used to explore the recent approaches to solve your problem and to start to develop your own approach to the problem. I advise you to not spend much time with syntax and grammar corrections in this version. You can even write it in bullets. After the dissertation work, you will see that this version is outdated: it contains topics that were not approached and/or is missing other topics. Do not panic! It is expected that, after the dissertation work, your understanding of the problem is different. You will have to iterate over the previous version of the state of the art and delete/write/rewrite everything until it is according to your work. After two, three or more passes on this chapter, the state of the art will be ready.&lt;/p&gt;

&lt;p&gt;In summary, the writing of the state of the art is a continuous loop. It must be done before and after the dissertation work, to be consistent with the entire dissertation.&lt;/p&gt;

&lt;h2 id=&quot;5---when-should-i-write-my-work&quot;&gt;5 - When should I write my work?&lt;/h2&gt;

&lt;figure&gt;
	&lt;a href=&quot;/assets/img/thesis-3.jpg&quot;&gt;&lt;img src=&quot;/assets/img/thesis-3.jpg&quot; /&gt;&lt;/a&gt;
	&lt;figcaption style=&quot;text-align:center&quot;&gt;When you start writing your thesis, you start to understand better the topic you are working in.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Alright, we should write the state of the art before and after the dissertation work. But when should we write the content of the dissertation work? It is important to split the dissertation work into two parts: the implementation and the writing. The implementation loosely involves the approach description and the results obtained; the writing about the implementation is another part. In which order they must be done? Obviously, you can’t write everything before the implementation is done, but do you write as you implement or do you implement everything first and then write after?&lt;/p&gt;

&lt;h3 id=&quot;my-experience-1&quot;&gt;My Experience&lt;/h3&gt;
&lt;p&gt;I have to admit that I am a &lt;em&gt;little&lt;/em&gt; anxious. Whenever I did anything of the work, I would write it down quickly so I would not forget what I had done. Looking back, I think it helped me. Allowed me to always be focused on the work to be done, and I could forget what was done previously: if I needed to go back to remember it, I would only need to read the chapter that was already previously written.&lt;/p&gt;

&lt;h3 id=&quot;my-advice-1&quot;&gt;My Advice&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Write!&lt;/strong&gt; Even if you are doing just quick tests. &lt;strong&gt;Write!&lt;/strong&gt; Even if you just need to write a description of a part of your work. &lt;strong&gt;Write!&lt;/strong&gt; The journey of the writing of a dissertation can be long, and our ability to remember everything we have done is clearly overrated. I can assure you that at the end of the dissertation you will not remember all the implementation details of the work. The only way to build a complete dissertation is to write everything as you do it. And don’t be a perfectionist: the writing does not need to be perfect, you will review it later. You only need to write to remember what you have done.&lt;/p&gt;

&lt;h2 id=&quot;6---when-to-meet-with-my-supervisor&quot;&gt;6 - When to meet with my supervisor?&lt;/h2&gt;

&lt;figure&gt;
	&lt;a href=&quot;/assets/img/thesis-4.jpg&quot;&gt;&lt;img src=&quot;/assets/img/thesis-4.jpg&quot; /&gt;&lt;/a&gt;
	&lt;figcaption style=&quot;text-align:center&quot;&gt;Meetings with your supervisor should be weekly at most.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This is one of the most important questions. How often should you meet with your supervisor? If you meet him/her rarely, chances are that he/she will not understand the work you are doing, making it harder to receive relevant feedback. This could totally ruin your work, especially if the dissertation objective is a little blurred. In the worst possible scenario, you can end up working for nothing, since what you have done is not what your supervisor wants you to do.&lt;/p&gt;

&lt;p&gt;On the other hand, meetings are tiring for all intervenients. If you regularly set up long meetings to discuss details about your work, you and your supervisor will get tired quickly, and frustration will start to grow on both. Your supervisor will start to wonder if you have enough autonomy to make progress alone, without his/her input.&lt;/p&gt;

&lt;h3 id=&quot;my-experience-2&quot;&gt;My Experience&lt;/h3&gt;
&lt;p&gt;From the beginning of the work, we had a weekly meeting of about half an hour (extendable to one hour when needed) on the same day and hour of every week. At that meeting, we discussed mainly two things: what was done in the previous week and what was proposed to be done in the next. In that way, my supervisor was always following my work, and at any week we could discuss the results obtained and propose a different approach for the next week, or give me some criticism about anything I could do better before I move on.&lt;/p&gt;

&lt;h3 id=&quot;my-advice-2&quot;&gt;My Advice&lt;/h3&gt;
&lt;p&gt;I &lt;strong&gt;REALLY&lt;/strong&gt; suggest you schedule weekly meetings to talk to your supervisor about your work. Besides receiving important feedback and understand if you are on the right track, it also helps to keep up the pace week after week - if there is a week where you didn’t do anything, you will have to say it to your supervisor. Just by saying it, you will be putting (good) pressure on yourself to get the job done in the next week. It also implicitly puts pressure on your supervisor to help you when you have problems and to split the responsibilities of your work. You can often ask: should I do X or Y? Whatever the answer of your supervisor is, he/she is responsible for that choice and you do not have to answer for it.&lt;/p&gt;

&lt;p&gt;Not all supervisors are able and willing to schedule weekly half-an-hour meetings. Maybe it’s because they think that they should only interfere in your work when you have doubts or problems; maybe it’s because they think that a monthly meeting is enough; maybe it’s because their schedule is flexible and they rather schedule meetings the week before; maybe it’s just because they are lazy (yes, it happens and it is quite common, unfortunately). Whatever it is the reason, understand it and try at all costs to schedule regular meetings. The supervisor is not at the university? You can talk to him/her with a video call. You don’t have anything to say to him? Tell him about your work in the previous week and see if he/she agrees with the approach and the results. But try to meet him/her weekly.&lt;/p&gt;

&lt;p&gt;Do not schedule long meetings when they are not needed. Choose regular short meetings over monthly long meetings. Long meetings are tedious and boring - no one likes them. Besides, if you did anything wrong in the first week of the month, the work of the whole month is wasted. The key here is to have continuous and short iteration loops where your work can be evaluated, discussed and improved (have you heard of agile sprints? It follows the same principle). It improves the quality of your work and it helps you to stay focused and motivated in the task. Meetings of half-an-hour are perfect (for me). Do not make meetings of more than one hour - after the first hour, you will be much less productive. In those cases, don’t be afraid of scheduling more than one meeting.&lt;/p&gt;

&lt;p&gt;Finally, but equally important, meet with your supervisor outside the meeting schedule whenever needed. During your work, there will be times when you will be stuck. You need immediate feedback to continue or you do not have a clue on what to do next in your work. In those times, do not wait for the next meeting: you can and should talk to your supervisor ASAP. There are supervisors more available than others. Independently of that, you have the right to discuss your problems with your supervisor in a short period of time. Do not be afraid of being annoying: their job is to help you when you have problems.&lt;/p&gt;

&lt;h2 id=&quot;7---how-to-prepare-your-meetings&quot;&gt;7 - How to prepare your meetings?&lt;/h2&gt;

&lt;p&gt;When you go to the meetings you have to be prepared. And to be prepared not only for what you are going to say but also for the possible answers from your supervisor. You have to be aware that it must be &lt;strong&gt;YOU&lt;/strong&gt; to set up an agenda for the meeting and control it if it goes wrong. But how can you do that, if you have never learned anything about it in university?&lt;/p&gt;

&lt;h3 id=&quot;my-experience-3&quot;&gt;My Experience&lt;/h3&gt;
&lt;p&gt;Before the dissertation, I was already in a research group, with a research grant. I had the experience of being in many meetings before the dissertation and with the experience, I learned to manage meetings for them to go according to what I had planned to. Before the meeting, I made a list of everything I had to discuss. It usually started with the work of the previous week, followed by what I had in mind for the next week.&lt;/p&gt;

&lt;p&gt;During that time, I gathered a few pieces of advice that were useful for me to know at the beginning of the work. The 5 pieces of advice most important are below.&lt;/p&gt;

&lt;h3 id=&quot;my-advice-3&quot;&gt;My Advice&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Make a list of everything you have to discuss in a meeting. It will be easier for you to not forget anything of what you want to discuss.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Do not wait for your supervisor to tell you what to do. Remember that you are the person that knows more about your work. You are the person that knows exactly what to do next to reach the proposed goal of your dissertation. Obviously, you can and should hear the advice from your supervisor. But you should ALWAYS propose what you should do in the next week. I can assure you that your supervisor has a different vision from yours on what’s left of your dissertation. Always be critical about what you hear and don’t be afraid to criticize your supervisor when you think he/she is wrong.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If there is any graphical form to show the results you have, show it. Whether it is in a powerpoint, excel or code, show it. It helps the viewers to understand what you are saying and the work that you have done.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Common discussion in a meeting&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Student&lt;/strong&gt;: I have the following problem. What should I do?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Student&lt;/strong&gt;: &amp;lt;Secretely wanting to use approach A&amp;gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Supervisor&lt;/strong&gt;: &amp;lt;15 minutes of discussion and searching the web about possible approaches&amp;gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Supervisor&lt;/strong&gt;: You know what? Let’s try the approaches A, B and C. At the end we will choose the best one!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Student&lt;/strong&gt;: But approaches B and C will not work…&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Supervisor&lt;/strong&gt;: Well, let’s try it!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Student&lt;/strong&gt;: &amp;lt;Wants to die&amp;gt;&lt;/p&gt;

&lt;p&gt;Whenever you make a question in a meeting, try to give two or three answer possibilities. If the question is about your work and you have a preference for an answer (e.g. you would like to use approach A, but the approaches B and C are also options), do not ask any question and go straight to the point: tell that you will use approach A, but B and C were also options. If your supervisor stops you and proves you wrong, follow his advice. Otherwise, just continue. In a dissertation, it is supposed for you to be autonomous. If you have a problem and you have a preferred approach to solve it, why to ask what approach should you do? If the approach is clearly wrong, your supervisor will tell you. Otherwise, you will avoid a discussion that can take a few minutes of your meeting and it will inevitably end up with you following your approach, whatever the advice of your supervisor.&lt;/p&gt;

&lt;p&gt;How it could have been:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Student&lt;/strong&gt;: For solving the problem, there are approaches A, B and C. I will use A, because it gives best results on the papers I read.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Supervisor&lt;/strong&gt;: It seems OK to me.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Know the personalities of the people that will be in the meeting: the meeting course will be heavily influenced by them. Be careful with the chitchatters! If you let them talk too much, you will realize that the meeting will not go as planned: you will start talking about anything else but your work. Whenever that happens, you MUST re-focus the discussion in your work. Also, be careful with advice from outsiders that do not follow your work since the beginning: they can give you advice that goes in the wrong direction just because they do not understand the whole scope of your work.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are many more pieces of advice to prepare your meetings, but I consider these to be the five most important ones.&lt;/p&gt;

&lt;p&gt;That’s it for today!&lt;/p&gt;

&lt;p&gt;Thanks for sticking by. Click &lt;a href=&quot;/how-to-have-a-thesis-part-3/&quot;&gt;here&lt;/a&gt; for part III.&lt;/p&gt;

&lt;p&gt;See ya!&lt;/p&gt;</content><category term="thesis" /><category term="dissertation" /><category term="tips" /><summary type="html">15 tips for your thesis/dissertation - 2/4</summary></entry><entry><title type="html">How to have an A+ dissertation/thesis (I/IV)</title><link href="http://localhost:4000/how-to-have-a-thesis-part-1/" rel="alternate" type="text/html" title="How to have an A+ dissertation/thesis (I/IV)" /><published>2019-08-23T00:00:00+01:00</published><updated>2019-08-23T00:00:00+01:00</updated><id>http://localhost:4000/how-to-have-a-thesis-part-1</id><content type="html" xml:base="http://localhost:4000/how-to-have-a-thesis-part-1/">&lt;p&gt;Hi there!&lt;/p&gt;

&lt;p&gt;I have recently concluded my Masters Dissertation about Control and Management Mechanisms for 5G Networks, with a 20/20 grade :) (in Portugal, the grading system goes from 1 (F) to 20 (A+) ) &lt;img src=&quot;/assets/img/emojis/grinning-face-facebook.png&quot; alt=&quot;grinning-face&quot; class=&quot;emojis&quot; /&gt;). While for me it was a smooth ride, for many of my colleagues it was/is really challenging to do their dissertation (or thesis, depending on the country you are studying). In this blog post, I will summarize the tips I would give myself before starting the dissertation, explaining my good and bad decisions along the way.&lt;/p&gt;

&lt;p&gt;Obviously, the content of this blog post is highly subjective and related to my dissertation experience, so don’t take it as the ground truth. But do think critically about my advice and, whether you agree with them or not, comment on what you think about it (I will number the tips for easy reference). Although this post is about a Masters Dissertation, it can also be (loosely) applied to a PhD work. But do note that I did not do a PhD: think critically whether this applies to you or not.&lt;/p&gt;

&lt;p&gt;This post will be divided into four parts: &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;I - 3 tips for before starting the writing of the dissertation;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/how-to-have-a-thesis-part-2/&quot;&gt;II - 4 tips for during the writing of the dissertation;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/how-to-have-a-thesis-part-3/&quot;&gt;III - more 4 tips for during the writing of the dissertation;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/how-to-have-a-thesis-part-4/&quot;&gt;IV - 3 tips for after the writing of the dissertation.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let’s start?&lt;/p&gt;

&lt;h1 id=&quot;before&quot;&gt;Before&lt;/h1&gt;

&lt;h2 id=&quot;1---choose-the-dissertation-because-of-the-supervisor-or-because-of-the-dissertation-topic&quot;&gt;1 - Choose the dissertation because of the supervisor or because of the dissertation topic?&lt;/h2&gt;

&lt;figure&gt;
	&lt;a href=&quot;/assets/img/thesis-1.jpg&quot;&gt;&lt;img src=&quot;/assets/img/thesis-1.jpg&quot; /&gt;&lt;/a&gt;
&lt;/figure&gt;

&lt;p&gt;Ush, this is a hot topic. Usually, some months (or weeks) before the beginning of your work, you have the chance to talk with your university Professors, to pick a topic for your dissertation. Do you start by choosing a dissertation topic and then talk to supervisors that understand that research area, or do you start by choosing a supervisor and then choose what he has to offer you?&lt;/p&gt;

&lt;p&gt;This is a hard question. Ideally, you would like to have both: a supervisor that you get along with and a dissertation topic that you love. That is possible more times than not.&lt;/p&gt;

&lt;h3 id=&quot;my-experience&quot;&gt;My Experience&lt;/h3&gt;
&lt;p&gt;I was already in a research group before starting the dissertation, with a research grant. To choose a dissertation topic, I just went talk to my supervisor, explained to her what I had in mind, and we came to an agreement. No, it wasn’t exactly her area of research (Machine Learning/Deep Learning), but it was of both parties’ interest to make a dissertation about that. We agreed that Machine Learning techniques were going to be used to analyze and improve 5G Networks. The supervisor could give me work revision and discussion about 5G Networks, but I was on my own on how to apply the Machine Learning techniques.&lt;/p&gt;

&lt;p&gt;While during the writing of the dissertation sometimes I felt a little “lost” in what my approach should be, it has inspired me to learn online about the area, and to understand it better. Due to the freedom that I had and the confidence that I always felt by my supervisor on me, any setback in my work was quickly discussed, besides the usual weekly meetings. In the end, I felt that although another supervisor could have given me more technical insights, I had much more freedom, encouragement and logistical support that was essential to my great grade in the dissertation.&lt;/p&gt;

&lt;h3 id=&quot;my-advice&quot;&gt;My Advice&lt;/h3&gt;
&lt;p&gt;I suggest going with your gut on this one. To give you an objective answer, I would say 70/30. For me, a great supervisor is more important than a great dissertation topic. A great supervisor will guarantee you 70% of your grade on your dissertation. Remember that your supervisor will be guiding you for one year (at least). You will have many meetings with him/her about the direction of your work. If you are not comfortable with him/her, or if you just don’t get along, then things can become really hard, independently of the topic of the work. What is a good supervisor? Well, that’s a topic for another post, but if you keep reading, I will give you some guidelines of what your supervisor should and shouldn’t do.&lt;/p&gt;

&lt;p&gt;Being in love with a dissertation topic is important because you will spend a lot of time researching that topic. If you find a supervisor that you like and that accepts your dissertation topic, go for it! Otherwise, you will have to make a trade-off. But don’t forget: 70% of the importance to the supervisor, 30% to the dissertation topic.&lt;/p&gt;

&lt;p&gt;For the PhD thesis I would &lt;strong&gt;NOT&lt;/strong&gt; recommend following this approach! The PhD is a hard road for everyone, and it involves a LOT more research and background work than a Masters dissertation. You will only be able to make it to the end if you &lt;strong&gt;really&lt;/strong&gt; like the topic that you’re working in. Besides, because you will spend much more time than one year working on that topic, it is expected that you become a world expert about that. If you don’t like that topic… why you’re doing a PhD anyway?&lt;/p&gt;

&lt;p&gt;In this case, I would recommend to, before starting the dissertation, search for the world experts about the topic that you are in love with. Make a short-list: 2 or 3 supervisors. Then, get in touch with them to understand if they are interested and, more importantly, if they are the right supervisor for you. If you find one that you like, go for it! Otherwise, keep searching. And don’t be afraid of changing supervisors while you’re still in the first year. It is better to change in the first year than spend 3, 4 or more years regretting that decision.&lt;/p&gt;

&lt;h2 id=&quot;2---understand-the-basics-before-diving-in&quot;&gt;2 - Understand the basics before diving in!&lt;/h2&gt;

&lt;p&gt;Before closing the deal with a supervisor about your dissertation, you should understand the basics of the dissertation work, mainly the objective and the techniques used to solve the proposed problem. A common problem in dissertation students is that they choose a topic just by the dissertations’ name. Beware of the “hot trends” in the industry (eg. AI, 5G, Cloud, …): a cool name does not mean a cool dissertation!&lt;/p&gt;

&lt;h3 id=&quot;my-experience-1&quot;&gt;My Experience&lt;/h3&gt;
&lt;p&gt;Well, let’s say I was lucky with this one… Before the dissertation deal, I really wanted to learn more about machine learning, but I didn’t know much about it. I knew the basics about it, but I knew nothing about the internals of the algorithms used, or about model tuning. In summer holidays (after accepting the dissertation deal and before starting to work on the dissertation), I learned &lt;strong&gt;a lot&lt;/strong&gt; about machine learning in three ways: free online courses, blog posts and books. Those 2 months were a crash course about machine learning algorithms and its utilization in the real world, as well as in the Deep Learning state of the art techniques. Fortunately, I loved it! At the beginning of the dissertation work, I felt a lot more confident about what to do to solve the problem, and about general knowledge about machine learning.&lt;/p&gt;

&lt;h3 id=&quot;my-advice-1&quot;&gt;My Advice&lt;/h3&gt;
&lt;p&gt;Before accepting the dissertation, take an hour of conversation with the supervisor. Try to understand what are the objectives of the dissertations’ work, and what are the current techniques used (or expected to be used by the supervisor). If you think that those techniques are obsolete, discuss that with the supervisor to make sure that you will not reinvent the wheel just because your supervisor finds that interesting! If you don’t understand what are the techniques that your supervisor wants you to use, take a week to learn about them (not in-depth, at least to have a grasp and understand what type of work you will be doing). If you don’t like the techniques used, feel free to reject the dissertation work (it is better to reject than to spend a year working on something you don’t like!). After accepting the dissertation, take a more in-depth look at the techniques you will be using to solve the problem, and research for the state of the art approaches. After this (sometimes boring and time-consuming) work, you will feel much more comfortable and able to do the job.&lt;/p&gt;

&lt;h2 id=&quot;3---take-a-break-after-accepting-the-dissertation&quot;&gt;3 - Take a break after accepting the dissertation!&lt;/h2&gt;

&lt;div style=&quot;width:100%;height:0;padding-bottom:72%;position:relative;&quot;&gt;&lt;iframe src=&quot;https://giphy.com/embed/5ocAtoAPhIDcI&quot; width=&quot;100%&quot; height=&quot;100%&quot; style=&quot;position:absolute&quot; frameborder=&quot;0&quot; class=&quot;giphy-embed&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://giphy.com/gifs/homer-official-poster-5ocAtoAPhIDcI&quot;&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Why take a break after accepting the dissertation? Shouldn’t we all start working furiously to do the work as quickly as possible? Well… &lt;strong&gt;NO!&lt;/strong&gt; &lt;img src=&quot;/assets/img/emojis/pouting-face.png&quot; alt=&quot;pouting-face&quot; class=&quot;emojis&quot; /&gt; The dissertation &lt;em&gt;is not a sprint, it’s a marathon&lt;/em&gt; (more on that later). After accepting the dissertation (you usually accept it before the summer holidays), take a week to relax and think about the work you will need to do. It will require a lot of mental preparation to work a whole year in a project, especially when things go wrong. This week is not only to take in the dissertation goals and to think about them, but also to mentalize yourself that you can do it, even if things go wrong from time to time (trust me, in such a long-term work, many things &lt;strong&gt;will&lt;/strong&gt; go wrong!). It is important to mentalize yourself about the task you are facing.&lt;/p&gt;

&lt;h3 id=&quot;my-experience-2&quot;&gt;My Experience&lt;/h3&gt;
&lt;p&gt;Before big steps in my life, I like to take a week to think about the step I am taking, to think about the future consequences of my decision and to understand how am I going to fulfill my goals. I did it before entering in my college course, and I did it before the starting of the dissertation work. Before the dissertation, I took a week to go to the Taizé Community: an ecumenical Christian monastic fraternity in France. I left my laptop, smartphone and electronic devices turned off to focus in nature. Besides, Taizé is known for its meditations and reflections, which allowed me to think deeply about why I was doing a dissertation, and it helped me to not give up in the hardest times.&lt;/p&gt;

&lt;h3 id=&quot;my-advice-2&quot;&gt;My Advice&lt;/h3&gt;
&lt;p&gt;No, you don’t &lt;em&gt;necessarily&lt;/em&gt; need to go to Taizé to take a break. But I would recommend going away from distractions, from electronic devices and from your routine. A week camping in the forest is also a good option. If you can’t be unavailable for a week, at least do it for a weekend. If you can’t or don’t like camping, you can go to a bungalow and take walks in the forest, for example. The key here is to go away from your routine. Only when you disconnect from the world you can really think deeply about what you want and how to reach it.&lt;/p&gt;

&lt;p&gt;That’s it for today!&lt;/p&gt;

&lt;p&gt;Thanks for sticking by. Click &lt;a href=&quot;/how-to-have-a-thesis-part-2/&quot;&gt;here&lt;/a&gt; for part II.&lt;/p&gt;

&lt;p&gt;See ya!&lt;/p&gt;</content><category term="thesis" /><category term="dissertation" /><category term="tips" /><summary type="html">15 tips for your thesis/dissertation - 1/4</summary></entry></feed>
